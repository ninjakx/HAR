{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Temporal_CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "oxGCfQEujLqz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "48448070-0c00-4164-e290-6e7581ad6344"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4HANMA7-CNqI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cBpNDO0QCVVT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c58766be-35dd-4ad8-f1da-86d734d6361a"
      },
      "cell_type": "code",
      "source": [
        "%cd drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uWy-1CGgCVcW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "c6b10d2a-2cee-46f6-b811-96c9c6c66988"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torchvision\n",
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torch\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\r\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.3.0.post4)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.5)\r\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision) (3.13)\n",
            "Requirement already satisfied: torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.3.0.post4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.14.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.3.0.post4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.14.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fy0ZfV4q-E_C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5865
        },
        "outputId": "ca181a2b-2680-46b2-def7-fd5c56a20468"
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import numpy as np\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, nb_classes=7, channel=20):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1_custom = nn.Conv2d(channel, 64, kernel_size=7, stride=2, padding=3,   \n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7)\n",
        "        self.fc_custom = nn.Linear(512 * block.expansion, nb_classes)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1_custom(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        out = self.fc_custom(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, channel= 20, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], nb_classes=101, channel=channel, **kwargs)\n",
        "    if pretrained:\n",
        "       pretrain_dict = model_zoo.load_url(model_urls['resnet18'])                  # modify pretrain code\n",
        "       model_dict = model.state_dict()\n",
        "       model_dict=weight_transform(model_dict, pretrain_dict, channel)\n",
        "       model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet34(pretrained=False, channel= 20, **kwargs):\n",
        "\n",
        "    model = ResNet(BasicBlock, [3, 4, 6, 3], nb_classes=7, channel=channel, **kwargs)\n",
        "    if pretrained:\n",
        "       pretrain_dict = model_zoo.load_url(model_urls['resnet34'])                  # modify pretrain code\n",
        "       model_dict = model.state_dict()\n",
        "       model_dict=weight_transform(model_dict, pretrain_dict, channel)\n",
        "       model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet50(pretrained=False, channel= 20, **kwargs):\n",
        "\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], nb_classes=7, channel=channel, **kwargs)\n",
        "    if pretrained:\n",
        "       pretrain_dict = model_zoo.load_url(model_urls['resnet50'])                  # modify pretrain code\n",
        "       model_dict = model.state_dict()\n",
        "       model_dict=weight_transform(model_dict, pretrain_dict, channel)\n",
        "       model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet101(pretrained=False, channel= 20, **kwargs):\n",
        "\n",
        "    model = ResNet(Bottleneck, [3, 4, 23, 3],nb_classes=7, channel=channel, **kwargs)\n",
        "    if pretrained:\n",
        "       pretrain_dict = model_zoo.load_url(model_urls['resnet101'])                  # modify pretrain code\n",
        "       model_dict = model.state_dict()\n",
        "       model_dict=weight_transform(model_dict, pretrain_dict, channel)\n",
        "       model.load_state_dict(model_dict)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet152(pretrained=False, **kwargs):\n",
        "\n",
        "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
        "    return model\n",
        "\n",
        "def cross_modality_pretrain(conv1_weight, channel):\n",
        "    # transform the original 3 channel weight to \"channel\" channel\n",
        "    S=0\n",
        "    for i in range(3):\n",
        "        S += conv1_weight[:,i,:,:]\n",
        "    avg = S/3.\n",
        "    new_conv1_weight = torch.FloatTensor(64,channel,7,7)\n",
        "    #print type(avg),type(new_conv1_weight)\n",
        "    for i in range(channel):\n",
        "        new_conv1_weight[:,i,:,:] = avg.data\n",
        "    return new_conv1_weight\n",
        "\n",
        "def weight_transform(model_dict, pretrain_dict, channel):\n",
        "    weight_dict  = {k:v for k, v in pretrain_dict.items() if k in model_dict}\n",
        "    #print pretrain_dict.keys()\n",
        "    w3 = pretrain_dict['conv1.weight']\n",
        "    #print type(w3)\n",
        "    if channel == 3:\n",
        "        wt = w3\n",
        "    else:\n",
        "        wt = cross_modality_pretrain(w3,channel)\n",
        "\n",
        "    weight_dict['conv1_custom.weight'] = wt\n",
        "    model_dict.update(weight_dict)\n",
        "    return model_dict\n",
        "\n",
        "#Test network\n",
        "if __name__ == '__main__':\n",
        "    model = resnet101(pretrained= True, channel=20)\n",
        "    print(model)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1_custom): Conv2d (20, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
            "  (relu): ReLU(inplace)\n",
            "  (maxpool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d (64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d (64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d (256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d (256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d (256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d (256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d (512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d (512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d (512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d (512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d (512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (6): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (7): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (8): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (9): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (10): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (11): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (12): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (13): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (14): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (15): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (16): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (17): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (18): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (19): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (20): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (21): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (22): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d (1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d (1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d (2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d (2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (conv3): Conv2d (512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0, ceil_mode=False, count_include_pad=True)\n",
            "  (fc_custom): Linear(in_features=2048, out_features=7)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_JHQUPO9sfhe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "d874e595-db9f-4eee-a93e-3f3378d10c17"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CIFAR-10\t dig_mnist\t\t   MURA-v1.1\r\n",
            "CIFAR.ipynb\t dog-breed-identification  MURA-v1.1(dataset)\r\n",
            "Colab Notebooks  Getting started\t   predict-future-sale\r\n",
            "cycleGAN.ipynb\t HAR\t\t\t   sop(kriti).odt\r\n",
            "CycleGAN-master  HAR1\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ywsBlEhUshQN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "8b8243fd-f57d-4efd-a059-ed8e9ffcdfc2"
      },
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "!pip install visdom\n",
        "!pip install git+https://github.com/pytorch/tnt.git@master\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.24.0)\n",
            "Requirement already satisfied: visdom in /usr/local/lib/python3.6/dist-packages (0.1.8.5)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from visdom) (1.14.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from visdom) (1.11.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.6/dist-packages (from visdom) (0.49.0)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom) (16.0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom) (0.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom) (2.18.4)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom) (4.5.3)\n",
            "Requirement already satisfied: torchfile in /usr/local/lib/python3.6/dist-packages (from visdom) (0.1.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from visdom) (5.2.0)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom) (2018.8.13)\n",
            "Collecting git+https://github.com/pytorch/tnt.git@master\n",
            "  Cloning https://github.com/pytorch/tnt.git (to revision master) to /tmp/pip-req-build-sqbw58rh\n",
            "Requirement already satisfied (use --upgrade to upgrade): torchnet==0.0.4 from git+https://github.com/pytorch/tnt.git@master in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchnet==0.0.4) (0.3.0.post4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchnet==0.0.4) (1.11.0)\n",
            "Requirement already satisfied: visdom in /usr/local/lib/python3.6/dist-packages (from torchnet==0.0.4) (0.1.8.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchnet==0.0.4) (1.14.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchnet==0.0.4) (3.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4) (5.2.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4) (0.49.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4) (4.5.3)\n",
            "Requirement already satisfied: torchfile in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4) (0.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4) (2.18.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4) (0.19.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4) (16.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4) (2018.8.13)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4) (2.6)\n",
            "Building wheels for collected packages: torchnet\n",
            "  Running setup.py bdist_wheel for torchnet ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-o7mdhryk/wheels/17/05/ec/d05d051a225871af52bf504f5e8daf57704811b3c1850d0012\n",
            "Successfully built torchnet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QeqHOMLlhdi-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06633a94-60d9-49bc-8c94-e2e33c6010dd"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from PIL import Image\n",
        "import time\n",
        "import tqdm\n",
        "import shutil\n",
        "from random import randint\n",
        "import keras\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torchvision.transforms.functional as F\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gXe1V34OuR1Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a282332a-9cf9-4d48-c4cf-4840cad9002d"
      },
      "cell_type": "code",
      "source": [
        "%cd HAR1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/HAR1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yT-XQa_uu4wl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "labels = pd.read_csv('train.csv',index_col = 0)\n",
        "#sample_submission = pd.read_csv(path + 'sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ztlySm5bu4sj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c74dfc39-d66b-443f-a030-121d82dca03b"
      },
      "cell_type": "code",
      "source": [
        "selected_labels = labels\n",
        "selected_labels['label'] = selected_labels['label'].astype(int)\n",
        "selected_labels['label'].dtype"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "W_Q1-mwiu4l-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_labels, valid_labels = train_test_split(selected_labels, test_size=0.3,shuffle=True) #test_split = 0.3\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RbG0Fpykx-mB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import FileLink\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "import torch.optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yQLoGBZrwixa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(), # data augmentation: random horizontal flip\n",
        "            #transforms.Scale(256),\n",
        "            #transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kAiT4uayu4h7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torchvision.transforms.functional as F\n",
        "\n",
        "class activityDataset(Dataset):\n",
        "    def __init__(self, root_dir, labels, transform):\n",
        "        self.labels = labels\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = self.labels.iloc[idx]\n",
        "        #print(item)\n",
        "        path = self.root_dir + '/' + item['id']\n",
        "        #print(item['id'])\n",
        "        image = np.load(path)\n",
        "        #print(image)\n",
        "\n",
        "        if self.transform:\n",
        "            image = F.to_pil_image(np.uint8(image))\n",
        "            image = self.transform(image)\n",
        "            \n",
        "       \n",
        "        #print(image,item['class'])\n",
        "        \n",
        "        return image, item['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mRcDh5JdI9pn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t1 = activityDataset('data', train_labels, transform)\n",
        "#t1[11]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MlRDjMaUu4Un",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5865
        },
        "outputId": "d118e01d-868a-4d43-ece7-e69d7c0b30a9"
      },
      "cell_type": "code",
      "source": [
        "modelres = model\n",
        "modelres"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1_custom): Conv2d (20, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
              "  (relu): ReLU(inplace)\n",
              "  (maxpool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d (64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d (64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d (256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d (256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d (256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d (256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d (512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d (512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d (512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d (512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d (512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (8): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (9): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (10): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (11): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (12): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (13): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (14): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (15): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (16): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (17): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (18): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (19): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (20): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (21): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (22): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d (1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d (1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d (2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d (2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (conv3): Conv2d (512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0, ceil_mode=False, count_include_pad=True)\n",
              "  (fc_custom): Linear(in_features=2048, out_features=7)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "metadata": {
        "id": "1L470BLvC0fS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "e2bd9bd3-1385-4afc-cb5d-19426a87ebee"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorboard_logger"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard_logger in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (0.19.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (1.14.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (1.11.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (5.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->tensorboard_logger) (39.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ai7BZmB6Jq3m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_dataset = activityDataset('data', train_labels, transform)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_dataset = activityDataset('data', valid_labels, transform)\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        "\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "61LgD7HWccCw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "9a0d1307-de33-4be2-a7a6-4778ac984c19"
      },
      "cell_type": "code",
      "source": [
        "! npm install -g localtunnel"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/client\n",
            "+ localtunnel@1.9.0\n",
            "updated 1 package in 2.912s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IRJ_kC9HbqSP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('/usr/local/bin/python -m pip install visdom')\n",
        "get_ipython().system_raw('/usr/local/bin/python -m visdom.server -port 6007 >> visdomlog.txt 2>&1 &')\n",
        "get_ipython().system_raw('lt --port 6007 >> url.txt 2>&1 &')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4PoGGbmLhNNo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import visdom\n",
        "#visdom.Visdom(port='6009')\n",
        "#! cat visdomlog.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EhQm-xsiz6sp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import visdom\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "class Visualizer(object):\n",
        "    '''\n",
        "    orginal visdom API - self.vis.function\n",
        "    '''\n",
        "\n",
        "    def __init__(self, env='main', **kwargs):\n",
        "        self.vis = visdom.Visdom(port='6007')\n",
        "        \n",
        "        # save（’loss',23）\n",
        "        self.index = {} \n",
        "        self.log_text = ''\n",
        "    \n",
        "    def check_connection(self):\n",
        "        return self.vis.check_connection()\n",
        "\n",
        "    def plot(self, name, value,step=1,**kwargs):\n",
        "        '''\n",
        "        self.plot('loss',1.00)\n",
        "        '''\n",
        "        x = self.index.get(name, 0)\n",
        "        self.vis.line(Y=np.array([value]), X=np.array([x]),\n",
        "                      win=name,\n",
        "                      opts=dict(title=name),\n",
        "                      update=None if x == 0 else 'append',\n",
        "                      **kwargs\n",
        "                      )\n",
        "        self.index[name] = x + step\n",
        "        \n",
        "    def plot_all(self, dict, step=1):\n",
        "        '''\n",
        "        plot multiple graphs\n",
        "        @params d: dict (name,value) i.e. ('loss',0.11)\n",
        "        '''\n",
        "        for k, v in dict.items():\n",
        "            self.plot(k, v, step)\n",
        "            \n",
        "    def plot_combine(self, name, d, step=1):\n",
        "        #multiple plots in one single graph\n",
        "        x = self.index.get(name, 0)\n",
        "        X = []\n",
        "        Y = []\n",
        "        legend = []\n",
        "        for k, v in sorted(d.items()):\n",
        "            Y.append(v)\n",
        "            X.append(x)\n",
        "            legend.append(k)\n",
        "        Y = np.array([Y])\n",
        "        X = np.array([X])\n",
        "        self.vis.line(\n",
        "            Y=Y, \n",
        "            X=X,\n",
        "            win=name,\n",
        "            opts=dict(\n",
        "                title=name,\n",
        "                legend=legend\n",
        "            ),\n",
        "            update=None if x == 0 else 'append',\n",
        "        )\n",
        "        self.index[name] = x + step\n",
        "\n",
        "    def img(self, name, img_,**kwargs):\n",
        "        '''\n",
        "        self.img('input_img',t.Tensor(64,64))\n",
        "        self.img('input_imgs',t.Tensor(3,64,64))\n",
        "        self.img('input_imgs',t.Tensor(100,1,64,64))\n",
        "        self.img('input_imgs',t.Tensor(100,3,64,64),nrow=10)\n",
        "        ！！！don‘t ~~self.img('input_imgs',t.Tensor(100,64,64),nrow=10)~~！！！\n",
        "        '''\n",
        "        self.vis.images(img_.cpu().numpy(),\n",
        "                       win=name,\n",
        "                       opts=dict(title=name),\n",
        "                       **kwargs\n",
        "                       )\n",
        "                       \n",
        "    def img_all(self, d):\n",
        "        for k, v in d.iteritems():\n",
        "            self.img(k, v)\n",
        "\n",
        "\n",
        "    def log(self,info,name='log'):\n",
        "        '''\n",
        "        self.log({'loss':1,'lr':0.0001})\n",
        "        '''\n",
        "\n",
        "        self.log_text += ('[{time}] {info} <br>'.format(\n",
        "                            time=time.strftime('%m%d_%H%M%S'),\\\n",
        "                            info=info)) \n",
        "        self.vis.text(self.log_text,name)   \n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        return getattr(self.vis, name)\n",
        "      \n",
        "    def make_grid(I, ncols=8):\n",
        "      assert isinstance(I, np.ndarray), 'plugin error, should pass numpy array here'\n",
        "      assert I.ndim == 4 and I.shape[1] == 3\n",
        "      nimg = I.shape[0]\n",
        "      H = I.shape[2]\n",
        "      W = I.shape[3]\n",
        "      ncols = min(nimg, ncols)\n",
        "      nrows = int(np.ceil(float(nimg) / ncols))\n",
        "      canvas = np.zeros((3, H * nrows, W * ncols))\n",
        "      i = 0\n",
        "      for y in range(nrows):\n",
        "        for x in range(ncols):\n",
        "            if i >= nimg:\n",
        "                break\n",
        "            canvas[:, y * H:(y + 1) * H, x * W:(x + 1) * W] = I[i]\n",
        "            i = i + 1\n",
        "      return canvas\n",
        "\n",
        "\n",
        "    def _prepare_image(I):\n",
        "      # convert [N]CHW image to HWC\n",
        "      assert isinstance(I, np.ndarray), 'plugin error, should pass numpy array here'\n",
        "      assert I.ndim == 2 or I.ndim == 3 or I.ndim == 4\n",
        "      if I.ndim == 4:  # NCHW\n",
        "        if I.shape[1] == 1:  # N1HW\n",
        "            I = np.concatenate((I, I, I), 1)  # N3HW\n",
        "        assert I.shape[1] == 3\n",
        "        I = make_grid(I)  # 3xHxW\n",
        "      if I.ndim == 3 and I.shape[0] == 1:  # 1xHxW\n",
        "        I = np.concatenate((I, I, I), 0)  # 3xHxW\n",
        "      if I.ndim == 2:  # HxW\n",
        "        I = np.expand_dims(I, 0)  # 1xHxW\n",
        "        I = np.concatenate((I, I, I), 0)  # 3xHxW\n",
        "      I = I.transpose(1, 2, 0)\n",
        "\n",
        "      return I\n",
        "\n",
        "      \n",
        "    def prepare_numpy(x, modality):\n",
        "      if modality == 'IMG':\n",
        "        if x.dtype == np.uint8:\n",
        "            x = x.astype(np.float32) / 255.0\n",
        "        x = _prepare_image(x)\n",
        "      if modality == 'VID':\n",
        "        x = _prepare_video(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "    def prepare_pytorch(x, modality):\n",
        "      if isinstance(x, torch.autograd.Variable):\n",
        "        x = x.data\n",
        "      x = x.cpu().numpy()\n",
        "      if modality == 'IMG':\n",
        "        x = _prepare_image(x)\n",
        "      if modality == 'VID':\n",
        "        x = _prepare_video(x)\n",
        "      return x\n",
        "      \n",
        "    def compute_curve(labels, predictions, num_thresholds=None, weights=None):\n",
        "      _MINIMUM_COUNT = 1e-7\n",
        "\n",
        "      if weights is None:\n",
        "        weights = 1.0\n",
        "\n",
        "      # Compute bins of true positives and false positives.\n",
        "      bucket_indices = np.int32(np.floor(predictions * (num_thresholds - 1)))\n",
        "      float_labels = labels.astype(np.float)\n",
        "      histogram_range = (0, num_thresholds - 1)\n",
        "      tp_buckets, _ = np.histogram(\n",
        "        bucket_indices,\n",
        "        bins=num_thresholds,\n",
        "        range=histogram_range,\n",
        "        weights=float_labels * weights)\n",
        "      fp_buckets, _ = np.histogram(\n",
        "        bucket_indices,\n",
        "        bins=num_thresholds,\n",
        "        range=histogram_range,\n",
        "        weights=(1.0 - float_labels) * weights)\n",
        "\n",
        "      # Obtain the reverse cumulative sum.\n",
        "      tp = np.cumsum(tp_buckets[::-1])[::-1]\n",
        "      fp = np.cumsum(fp_buckets[::-1])[::-1]\n",
        "      tn = fp[0] - fp\n",
        "      fn = tp[0] - tp\n",
        "      precision = tp / np.maximum(_MINIMUM_COUNT, tp + fp)\n",
        "      recall = tp / np.maximum(_MINIMUM_COUNT, tp + fn)\n",
        "      return np.stack((tp, fp, tn, fn, precision, recall))\n",
        "\n",
        "    def make_np(x, modality=None):\n",
        "      if isinstance(x, np.ndarray):\n",
        "        return prepare_numpy(x, modality)\n",
        "      if isinstance(x, six.string_types):  # Caffe2 will pass name of blob(s) to fetch\n",
        "        return prepare_caffe2(x, modality)\n",
        "      if np.isscalar(x):\n",
        "        return np.array([x])\n",
        "      if 'torch' in str(type(x)):\n",
        "        return prepare_pytorch(x, modality)\n",
        "      if 'chainer' in str(type(x)):\n",
        "        return prepare_chainer(x, modality)\n",
        "      if 'mxnet' in str(type(x)):\n",
        "        return prepare_mxnet(x, modality)\n",
        "\n",
        "      \n",
        "    def add_pr_curve(self, tag, labels, predictions, global_step=None, num_thresholds=127, weights=None):\n",
        "        \"\"\"Adds precision recall curve.\n",
        "        Args:\n",
        "        tag (string): Data identifier\n",
        "            labels (torch.Tensor, numpy.array, or string/blobname): Ground truth data. Binary label for each element.\n",
        "            predictions (torch.Tensor, numpy.array, or string/blobname):\n",
        "            The probability that an element be classified as true. Value should in [0, 1]\n",
        "            global_step (int): Global step value to record\n",
        "            num_thresholds (int): Number of thresholds used to draw the curve.\n",
        "        \"\"\"\n",
        "        labels, predictions = make_np(labels), make_np(predictions)\n",
        "        raw_data = compute_curve(labels, predictions, num_thresholds, weights)\n",
        "\n",
        "        # compute_curve returns np.stack((tp, fp, tn, fn, precision, recall))\n",
        "        # We want to access 'precision' and 'recall'\n",
        "        precision, recall = raw_data[4, :], raw_data[5, :]\n",
        "\n",
        "        self.vis.line(\n",
        "            X=recall,\n",
        "            Y=precision,\n",
        "            name=tag,\n",
        "            opts={\n",
        "                'title': 'PR Curve for {}'.format(tag),\n",
        "                'xlabel': 'recall',\n",
        "                'ylabel': 'precision',\n",
        "            },\n",
        "        )\n",
        "\n",
        "    #@_check_connection\n",
        "    def add_pr_curve_raw(self, tag, true_positive_counts,\n",
        "                         false_positive_counts,\n",
        "                         true_negative_counts,\n",
        "                         false_negative_counts,\n",
        "                         precision,\n",
        "                         recall, global_step=None, num_thresholds=127, weights=None):\n",
        "        \"\"\"Adds precision recall curve with raw data.\n",
        "        Args:\n",
        "            tag (string): Data identifier\n",
        "            true_positive_counts (torch.Tensor, numpy.array, or string/blobname): true positive counts\n",
        "            false_positive_counts (torch.Tensor, numpy.array, or string/blobname): false positive counts\n",
        "            true_negative_counts (torch.Tensor, numpy.array, or string/blobname): true negative counts\n",
        "            false_negative_counts (torch.Tensor, numpy.array, or string/blobname): false negative counts\n",
        "            precision (torch.Tensor, numpy.array, or string/blobname): precision\n",
        "            recall (torch.Tensor, numpy.array, or string/blobname): recall\n",
        "            global_step (int): Global step value to record\n",
        "            num_thresholds (int): Number of thresholds used to draw the curve.\n",
        "            see: https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/README.md\n",
        "        \"\"\"\n",
        "        precision, recall = make_np(precision), make_np(recall)\n",
        "        self.vis.line(\n",
        "            X=recall,\n",
        "            Y=precision,\n",
        "            name=tag,\n",
        "            opts={\n",
        "                'title': 'PR Curve for {}'.format(tag),\n",
        "                'xlabel': 'recall',\n",
        "                'ylabel': 'precision',\n",
        "            },\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wbBqnQu2-69w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 25581
        },
        "outputId": "bc139af0-99a6-4cf3-c322-2a605a9612fb"
      },
      "cell_type": "code",
      "source": [
        "! cat visdomlog.txt"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1159, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1155, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1150, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1088, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.84ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.64ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1159, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1155, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1150, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1088, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:root:Application Started\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1159, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1155, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1150, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1088, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 GET / (127.0.0.1) 12.53ms\r\n",
            "INFO:tornado.access:200 GET /static/css/bootstrap.min.css?v=ec3bb52a00e176a7181d454dffaea219 (127.0.0.1) 2.68ms\r\n",
            "INFO:tornado.access:200 GET /static/js/jquery.min.js?v=e071abda8fe61194711cfc2ab99fe104 (127.0.0.1) 1.03ms\r\n",
            "INFO:tornado.access:200 GET /static/css/style.css?v=7e45c3fff51fb67db56c3231b7614bc2 (127.0.0.1) 0.88ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-grid-layout-styles.css?v=7dc8934d2f9ac5303b8f0bb1148152a0 (127.0.0.1) 0.86ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-resizable-styles.css?v=9f91a8dbf4d8f7ef1399e625660405f4 (127.0.0.1) 0.86ms\r\n",
            "INFO:tornado.access:200 GET /static/js/bootstrap.min.js?v=5869c96cc8f19086aee625d670d741f9 (127.0.0.1) 0.93ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/layout_bin_packer?v=6c46683ed70fbb1443caf3531243836d (127.0.0.1) 0.88ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-dom.min.js?v=950495cc51ccb90612cf0fe0bb44f8f3 (127.0.0.1) 0.93ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-react.min.js?v=bca103da5b5404d93783ccf73e0e9d1e (127.0.0.1) 0.87ms\r\n",
            "INFO:tornado.access:200 GET /static/js/plotly-plotly.min.js?v=321426a3fa74680623478bd02a171587 (127.0.0.1) 4.49ms\r\n",
            "INFO:tornado.access:200 GET /static/js/main.js?v=883944086f3d7f2369c5c0a17e0b7268 (127.0.0.1) 1.71ms\r\n",
            "INFO:tornado.access:200 GET /static/js/mathjax-MathJax.js?v=49565b9ce89c64da075a5a39969b366e (127.0.0.1) 1.03ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/glyphicons-halflings-regular.woff2 (127.0.0.1) 1.00ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.77ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 2.78ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 0.71ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 0.77ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathMenu.js?V=2.7.1 (127.0.0.1) 2.54ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathZoom.js?V=2.7.1 (127.0.0.1) 2.57ms\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.66ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.96ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.61ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 0.81ms\r\n",
            "INFO:tornado.access:200 GET /env/main (127.0.0.1) 2.56ms\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.50ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.46ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.95ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.61ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 0.95ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.61ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 0.87ms\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1159, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1155, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1150, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1088, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 GET / (127.0.0.1) 2.64ms\r\n",
            "INFO:tornado.access:200 GET /static/css/bootstrap.min.css?v=ec3bb52a00e176a7181d454dffaea219 (127.0.0.1) 1.08ms\r\n",
            "INFO:tornado.access:200 GET /static/js/jquery.min.js?v=e071abda8fe61194711cfc2ab99fe104 (127.0.0.1) 0.94ms\r\n",
            "INFO:tornado.access:200 GET /static/js/bootstrap.min.js?v=5869c96cc8f19086aee625d670d741f9 (127.0.0.1) 0.96ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-resizable-styles.css?v=9f91a8dbf4d8f7ef1399e625660405f4 (127.0.0.1) 0.95ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-grid-layout-styles.css?v=7dc8934d2f9ac5303b8f0bb1148152a0 (127.0.0.1) 0.78ms\r\n",
            "INFO:tornado.access:200 GET /static/css/style.css?v=7e45c3fff51fb67db56c3231b7614bc2 (127.0.0.1) 0.83ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-react.min.js?v=bca103da5b5404d93783ccf73e0e9d1e (127.0.0.1) 0.94ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-dom.min.js?v=950495cc51ccb90612cf0fe0bb44f8f3 (127.0.0.1) 1.01ms\r\n",
            "INFO:tornado.access:200 GET /static/js/plotly-plotly.min.js?v=321426a3fa74680623478bd02a171587 (127.0.0.1) 4.30ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/layout_bin_packer?v=6c46683ed70fbb1443caf3531243836d (127.0.0.1) 1.17ms\r\n",
            "INFO:tornado.access:200 GET /static/js/main.js?v=883944086f3d7f2369c5c0a17e0b7268 (127.0.0.1) 1.80ms\r\n",
            "INFO:tornado.access:200 GET /static/js/mathjax-MathJax.js?v=49565b9ce89c64da075a5a39969b366e (127.0.0.1) 0.93ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/glyphicons-halflings-regular.woff2 (127.0.0.1) 0.89ms\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 2.58ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.59ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 GET /extensions/MathMenu.js?V=2.7.1 (127.0.0.1) 2.54ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathZoom.js?V=2.7.1 (127.0.0.1) 3.09ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 0.94ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 1.21ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.58ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.51ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.59ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 0.62ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 1.13ms\r\n",
            "INFO:tornado.access:200 GET /env/main (127.0.0.1) 2.84ms\r\n",
            "INFO:tornado.access:200 GET / (127.0.0.1) 2.52ms\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1159, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1155, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1150, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1088, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.50ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.46ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:tornado.access:200 GET / (127.0.0.1) 2.65ms\r\n",
            "INFO:tornado.access:200 GET /static/css/bootstrap.min.css?v=ec3bb52a00e176a7181d454dffaea219 (127.0.0.1) 1.10ms\r\n",
            "INFO:tornado.access:200 GET /static/js/jquery.min.js?v=e071abda8fe61194711cfc2ab99fe104 (127.0.0.1) 0.97ms\r\n",
            "INFO:tornado.access:200 GET /static/js/bootstrap.min.js?v=5869c96cc8f19086aee625d670d741f9 (127.0.0.1) 0.89ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-resizable-styles.css?v=9f91a8dbf4d8f7ef1399e625660405f4 (127.0.0.1) 0.95ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-grid-layout-styles.css?v=7dc8934d2f9ac5303b8f0bb1148152a0 (127.0.0.1) 0.88ms\r\n",
            "INFO:tornado.access:200 GET /static/css/style.css?v=7e45c3fff51fb67db56c3231b7614bc2 (127.0.0.1) 0.81ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-react.min.js?v=bca103da5b5404d93783ccf73e0e9d1e (127.0.0.1) 0.91ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/layout_bin_packer?v=6c46683ed70fbb1443caf3531243836d (127.0.0.1) 0.93ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-dom.min.js?v=950495cc51ccb90612cf0fe0bb44f8f3 (127.0.0.1) 0.97ms\r\n",
            "INFO:tornado.access:200 GET /static/js/plotly-plotly.min.js?v=321426a3fa74680623478bd02a171587 (127.0.0.1) 4.40ms\r\n",
            "INFO:tornado.access:200 GET /static/js/main.js?v=883944086f3d7f2369c5c0a17e0b7268 (127.0.0.1) 1.82ms\r\n",
            "INFO:tornado.access:200 GET /static/js/mathjax-MathJax.js?v=49565b9ce89c64da075a5a39969b366e (127.0.0.1) 0.96ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/glyphicons-halflings-regular.woff2 (127.0.0.1) 0.85ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.60ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 2.49ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 1.08ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 1.33ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathMenu.js?V=2.7.1 (127.0.0.1) 2.59ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathZoom.js?V=2.7.1 (127.0.0.1) 3.01ms\r\n",
            "INFO:root:from web client: {\"cmd\":\"close\",\"data\":\"Val_Loss\",\"eid\":\"main\"}\r\n",
            "INFO:root:closing window Val_Loss\r\n",
            "INFO:root:from web client: {\"cmd\":\"close\",\"data\":\"PR curve\",\"eid\":\"main\"}\r\n",
            "INFO:root:closing window PR curve\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.82ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.87ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.75ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.89ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.71ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.88ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.71ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.86ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.88ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.69ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.88ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.74ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.91ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.70ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.91ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.93ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.75ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.59ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.58ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.61ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.59ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.65ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.54ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.58ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.90ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.84ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.91ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.78ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.90ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.71ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.90ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.72ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.92ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.75ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.94ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.74ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.95ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.77ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.00ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.76ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.97ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.69ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.95ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.97ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.74ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.97ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.76ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.01ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.74ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.05ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.76ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.97ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.81ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.04ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.76ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.02ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.76ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.60ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.51ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 0.83ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.79ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.85ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.69ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.15ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.89ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.69ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.89ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.90ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.65ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.87ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.69ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.92ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.67ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.93ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.70ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.95ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.72ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.95ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.55ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.57ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.67ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.45ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.72ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.72ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.64ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.62ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.71ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.72ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.68ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.74ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.65ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.71ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.70ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.75ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.74ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.67ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.71ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.62ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.94ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.75ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.71ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.71ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.59ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.74ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.67ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.72ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.66ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.74ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.65ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.82ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.72ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.78ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.92ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.75ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.67ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.77ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.68ms\r\n",
            "INFO:tornado.access:200 GET / (127.0.0.1) 3.97ms\r\n",
            "INFO:tornado.access:200 GET /static/css/bootstrap.min.css?v=ec3bb52a00e176a7181d454dffaea219 (127.0.0.1) 1.19ms\r\n",
            "INFO:tornado.access:200 GET /static/js/jquery.min.js?v=e071abda8fe61194711cfc2ab99fe104 (127.0.0.1) 1.26ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.75ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.60ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-resizable-styles.css?v=9f91a8dbf4d8f7ef1399e625660405f4 (127.0.0.1) 3.32ms\r\n",
            "INFO:tornado.access:200 GET /static/js/bootstrap.min.js?v=5869c96cc8f19086aee625d670d741f9 (127.0.0.1) 1.14ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-dom.min.js?v=950495cc51ccb90612cf0fe0bb44f8f3 (127.0.0.1) 1.30ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-react.min.js?v=bca103da5b5404d93783ccf73e0e9d1e (127.0.0.1) 1.05ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-grid-layout-styles.css?v=7dc8934d2f9ac5303b8f0bb1148152a0 (127.0.0.1) 1.11ms\r\n",
            "INFO:tornado.access:200 GET /static/js/mathjax-MathJax.js?v=49565b9ce89c64da075a5a39969b366e (127.0.0.1) 1.02ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/layout_bin_packer?v=6c46683ed70fbb1443caf3531243836d (127.0.0.1) 1.15ms\r\n",
            "INFO:tornado.access:200 GET /static/js/plotly-plotly.min.js?v=321426a3fa74680623478bd02a171587 (127.0.0.1) 5.20ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.74ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.62ms\r\n",
            "INFO:tornado.access:200 GET /static/css/style.css?v=7e45c3fff51fb67db56c3231b7614bc2 (127.0.0.1) 1.14ms\r\n",
            "INFO:tornado.access:200 GET /static/css/style.css?v=7e45c3fff51fb67db56c3231b7614bc2 (127.0.0.1) 1.13ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.68ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.76ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.69ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.75ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.65ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.75ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.65ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.76ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.69ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.65ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.66ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.75ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.62ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.97ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.67ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.77ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.64ms\r\n",
            "INFO:tornado.access:200 GET /static/js/main.js?v=883944086f3d7f2369c5c0a17e0b7268 (127.0.0.1) 2.69ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.77ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.68ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/glyphicons-halflings-regular.woff2 (127.0.0.1) 1.16ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.68ms\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 4.30ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.74ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 GET /extensions/MathMenu.js?V=2.7.1 (127.0.0.1) 3.63ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathZoom.js?V=2.7.1 (127.0.0.1) 5.65ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.50ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.99ms\r\n",
            "INFO:tornado.access:304 GET / (127.0.0.1) 3.99ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.76ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.65ms\r\n",
            "INFO:tornado.access:304 GET /static/fonts/glyphicons-halflings-regular.woff2 (127.0.0.1) 0.99ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.81ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:304 GET /favicon.png (127.0.0.1) 3.13ms\r\n",
            "INFO:tornado.access:304 GET /extensions/MathMenu.js?V=2.7.1 (127.0.0.1) 4.02ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 1.91ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.55ms\r\n",
            "INFO:tornado.access:304 GET /extensions/MathZoom.js?V=2.7.1 (127.0.0.1) 4.96ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.92ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.78ms\r\n",
            "INFO:tornado.access:304 GET / (127.0.0.1) 4.48ms\r\n",
            "INFO:tornado.access:304 GET /favicon.png (127.0.0.1) 4.30ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.82ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.58ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 3.76ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.92ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.79ms\r\n",
            "INFO:tornado.access:304 GET /extensions/MathMenu.js?V=2.7.1 (127.0.0.1) 4.55ms\r\n",
            "INFO:tornado.access:304 GET /extensions/MathZoom.js?V=2.7.1 (127.0.0.1) 4.31ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.53ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.82ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.93ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.77ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.92ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.79ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.93ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.80ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.95ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.74ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.98ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.76ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.95ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.83ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.95ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.77ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.98ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.81ms\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1159, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1155, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1150, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1088, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 GET / (127.0.0.1) 2.55ms\r\n",
            "INFO:tornado.access:200 GET /static/css/bootstrap.min.css?v=ec3bb52a00e176a7181d454dffaea219 (127.0.0.1) 1.00ms\r\n",
            "INFO:tornado.access:200 GET /static/js/jquery.min.js?v=e071abda8fe61194711cfc2ab99fe104 (127.0.0.1) 1.16ms\r\n",
            "INFO:tornado.access:200 GET /static/js/bootstrap.min.js?v=5869c96cc8f19086aee625d670d741f9 (127.0.0.1) 1.09ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-resizable-styles.css?v=9f91a8dbf4d8f7ef1399e625660405f4 (127.0.0.1) 0.87ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-dom.min.js?v=950495cc51ccb90612cf0fe0bb44f8f3 (127.0.0.1) 1.03ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-grid-layout-styles.css?v=7dc8934d2f9ac5303b8f0bb1148152a0 (127.0.0.1) 0.86ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-react.min.js?v=bca103da5b5404d93783ccf73e0e9d1e (127.0.0.1) 0.92ms\r\n",
            "INFO:tornado.access:200 GET /static/js/plotly-plotly.min.js?v=321426a3fa74680623478bd02a171587 (127.0.0.1) 4.40ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/layout_bin_packer?v=6c46683ed70fbb1443caf3531243836d (127.0.0.1) 0.90ms\r\n",
            "INFO:tornado.access:200 GET /static/css/style.css?v=7e45c3fff51fb67db56c3231b7614bc2 (127.0.0.1) 0.72ms\r\n",
            "INFO:tornado.access:200 GET /static/js/mathjax-MathJax.js?v=49565b9ce89c64da075a5a39969b366e (127.0.0.1) 0.96ms\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 2.39ms\r\n",
            "INFO:tornado.access:200 GET /static/js/main.js?v=883944086f3d7f2369c5c0a17e0b7268 (127.0.0.1) 1.67ms\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 2.91ms\r\n",
            "INFO:tornado.access:200 GET /static/js/mathjax-MathJax.js?v=49565b9ce89c64da075a5a39969b366e (127.0.0.1) 0.95ms\r\n",
            "INFO:tornado.access:200 GET /static/js/main.js?v=883944086f3d7f2369c5c0a17e0b7268 (127.0.0.1) 1.73ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.59ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 2.60ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.57ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.51ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.62ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.52ms\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1159, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1155, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1150, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1088, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 GET / (127.0.0.1) 2.55ms\r\n",
            "INFO:tornado.access:200 GET /static/js/jquery.min.js?v=e071abda8fe61194711cfc2ab99fe104 (127.0.0.1) 0.99ms\r\n",
            "INFO:tornado.access:200 GET /static/js/bootstrap.min.js?v=5869c96cc8f19086aee625d670d741f9 (127.0.0.1) 0.85ms\r\n",
            "INFO:tornado.access:200 GET /static/css/bootstrap.min.css?v=ec3bb52a00e176a7181d454dffaea219 (127.0.0.1) 0.91ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-grid-layout-styles.css?v=7dc8934d2f9ac5303b8f0bb1148152a0 (127.0.0.1) 0.85ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-react.min.js?v=bca103da5b5404d93783ccf73e0e9d1e (127.0.0.1) 0.87ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-dom.min.js?v=950495cc51ccb90612cf0fe0bb44f8f3 (127.0.0.1) 1.06ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/layout_bin_packer?v=6c46683ed70fbb1443caf3531243836d (127.0.0.1) 0.94ms\r\n",
            "INFO:tornado.access:200 GET /static/js/plotly-plotly.min.js?v=321426a3fa74680623478bd02a171587 (127.0.0.1) 4.88ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-resizable-styles.css?v=9f91a8dbf4d8f7ef1399e625660405f4 (127.0.0.1) 0.84ms\r\n",
            "INFO:tornado.access:200 GET /static/css/style.css?v=7e45c3fff51fb67db56c3231b7614bc2 (127.0.0.1) 0.85ms\r\n",
            "INFO:tornado.access:200 GET /static/js/main.js?v=883944086f3d7f2369c5c0a17e0b7268 (127.0.0.1) 1.63ms\r\n",
            "INFO:tornado.access:200 GET /static/js/mathjax-MathJax.js?v=49565b9ce89c64da075a5a39969b366e (127.0.0.1) 0.99ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/glyphicons-halflings-regular.woff2 (127.0.0.1) 0.84ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/glyphicons-halflings-regular.woff2 (127.0.0.1) 0.74ms\r\n",
            "INFO:tornado.access:200 GET / (127.0.0.1) 5.50ms\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 2.35ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathZoom.js?V=2.7.1 (127.0.0.1) 3.08ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathMenu.js?V=2.7.1 (127.0.0.1) 2.36ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.55ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 1.90ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 1.65ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.05ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.88ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.71ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.96ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.87ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.67ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.77ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.86ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.68ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.81ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.86ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.67ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.80ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.90ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.69ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.83ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.89ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.71ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.81ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.89ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.68ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.82ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.93ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.72ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.86ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.92ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 1.20ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.81ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.93ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.69ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.84ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.00ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.74ms\r\n",
            "INFO:tornado.access:200 GET / (127.0.0.1) 4.17ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.86ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.94ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.67ms\r\n",
            "INFO:tornado.access:200 GET /static/css/bootstrap.min.css?v=ec3bb52a00e176a7181d454dffaea219 (127.0.0.1) 1.24ms\r\n",
            "INFO:tornado.access:200 GET /static/js/jquery.min.js?v=e071abda8fe61194711cfc2ab99fe104 (127.0.0.1) 1.13ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-resizable-styles.css?v=9f91a8dbf4d8f7ef1399e625660405f4 (127.0.0.1) 1.11ms\r\n",
            "INFO:tornado.access:200 GET /static/js/bootstrap.min.js?v=5869c96cc8f19086aee625d670d741f9 (127.0.0.1) 1.21ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-dom.min.js?v=950495cc51ccb90612cf0fe0bb44f8f3 (127.0.0.1) 1.14ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-grid-layout-styles.css?v=7dc8934d2f9ac5303b8f0bb1148152a0 (127.0.0.1) 0.93ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-react.min.js?v=bca103da5b5404d93783ccf73e0e9d1e (127.0.0.1) 1.03ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/layout_bin_packer?v=6c46683ed70fbb1443caf3531243836d (127.0.0.1) 1.21ms\r\n",
            "INFO:tornado.access:200 GET /static/js/mathjax-MathJax.js?v=49565b9ce89c64da075a5a39969b366e (127.0.0.1) 1.50ms\r\n",
            "INFO:tornado.access:200 GET /static/js/plotly-plotly.min.js?v=321426a3fa74680623478bd02a171587 (127.0.0.1) 6.57ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.80ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.96ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.72ms\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 2.44ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.82ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.96ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.69ms\r\n",
            "INFO:tornado.access:200 GET /static/css/style.css?v=7e45c3fff51fb67db56c3231b7614bc2 (127.0.0.1) 1.22ms\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 3.94ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.78ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.95ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.71ms\r\n",
            "INFO:tornado.access:200 GET /static/js/main.js?v=883944086f3d7f2369c5c0a17e0b7268 (127.0.0.1) 2.41ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.83ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.98ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.67ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.82ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.00ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.70ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.81ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.04ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.85ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.02ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.82ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.01ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.67ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.71ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 GET /static/fonts/glyphicons-halflings-regular.woff2 (127.0.0.1) 0.84ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.66ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.03ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathZoom.js?V=2.7.1 (127.0.0.1) 2.74ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathMenu.js?V=2.7.1 (127.0.0.1) 2.77ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.88ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.79ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.88ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.04ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.79ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.85ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.06ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.69ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.81ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.04ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.66ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.82ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.03ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.68ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.82ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.04ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.69ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.84ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.04ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.70ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.82ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.11ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.67ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.84ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.05ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.74ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.86ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.09ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.65ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.81ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.13ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.67ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.86ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.09ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.66ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.84ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.05ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.68ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.81ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.08ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.70ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.83ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.18ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.77ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.81ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.16ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.71ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.82ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.11ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.68ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.07ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.10ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.70ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.82ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.15ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.70ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.84ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.14ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.68ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.86ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 1.13ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.68ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.55ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.60ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.77ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.28ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.55ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.54ms\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1159, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1155, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1150, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1088, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.50ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.46ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:tornado.access:200 GET / (127.0.0.1) 2.76ms\r\n",
            "INFO:tornado.access:200 GET /static/css/bootstrap.min.css?v=ec3bb52a00e176a7181d454dffaea219 (127.0.0.1) 1.04ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-resizable-styles.css?v=9f91a8dbf4d8f7ef1399e625660405f4 (127.0.0.1) 0.86ms\r\n",
            "INFO:tornado.access:200 GET /static/js/jquery.min.js?v=e071abda8fe61194711cfc2ab99fe104 (127.0.0.1) 0.94ms\r\n",
            "INFO:tornado.access:200 GET /static/js/bootstrap.min.js?v=5869c96cc8f19086aee625d670d741f9 (127.0.0.1) 0.91ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-react.min.js?v=bca103da5b5404d93783ccf73e0e9d1e (127.0.0.1) 0.90ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-dom.min.js?v=950495cc51ccb90612cf0fe0bb44f8f3 (127.0.0.1) 1.02ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/layout_bin_packer?v=6c46683ed70fbb1443caf3531243836d (127.0.0.1) 0.84ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-grid-layout-styles.css?v=7dc8934d2f9ac5303b8f0bb1148152a0 (127.0.0.1) 0.89ms\r\n",
            "INFO:tornado.access:200 GET /static/css/style.css?v=7e45c3fff51fb67db56c3231b7614bc2 (127.0.0.1) 0.84ms\r\n",
            "INFO:tornado.access:200 GET /static/js/mathjax-MathJax.js?v=49565b9ce89c64da075a5a39969b366e (127.0.0.1) 0.91ms\r\n",
            "INFO:tornado.access:200 GET /static/js/plotly-plotly.min.js?v=321426a3fa74680623478bd02a171587 (127.0.0.1) 4.38ms\r\n",
            "INFO:tornado.access:200 GET /static/js/main.js?v=883944086f3d7f2369c5c0a17e0b7268 (127.0.0.1) 1.61ms\r\n",
            "INFO:tornado.access:200 GET /static/js/main.js?v=883944086f3d7f2369c5c0a17e0b7268 (127.0.0.1) 1.90ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathZoom.js?V=2.7.1 (127.0.0.1) 2.82ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/glyphicons-halflings-regular.woff (127.0.0.1) 1.01ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathMenu.js?V=2.7.1 (127.0.0.1) 2.74ms\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 3.30ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.58ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.55ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.61ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.26ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.10ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.69ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.88ms\r\n",
            "INFO:tornado.access:304 GET / (127.0.0.1) 2.59ms\r\n",
            "INFO:tornado.access:206 GET /static/js/plotly-plotly.min.js?v=321426a3fa74680623478bd02a171587 (127.0.0.1) 3.21ms\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 2.65ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/glyphicons-halflings-regular.woff2 (127.0.0.1) 0.82ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.58ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:304 GET /extensions/MathMenu.js?V=2.7.1 (127.0.0.1) 2.65ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.26ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.34ms\r\n",
            "INFO:tornado.access:304 GET /extensions/MathZoom.js?V=2.7.1 (127.0.0.1) 3.76ms\r\n",
            "INFO:tornado.access:200 GET / (127.0.0.1) 2.57ms\r\n",
            "INFO:tornado.access:200 GET /static/css/style.css?v=7e45c3fff51fb67db56c3231b7614bc2 (127.0.0.1) 0.78ms\r\n",
            "INFO:tornado.access:200 GET /static/js/jquery.min.js?v=e071abda8fe61194711cfc2ab99fe104 (127.0.0.1) 1.12ms\r\n",
            "INFO:tornado.access:200 GET /static/css/bootstrap.min.css?v=ec3bb52a00e176a7181d454dffaea219 (127.0.0.1) 1.10ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-resizable-styles.css?v=9f91a8dbf4d8f7ef1399e625660405f4 (127.0.0.1) 0.86ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-grid-layout-styles.css?v=7dc8934d2f9ac5303b8f0bb1148152a0 (127.0.0.1) 0.84ms\r\n",
            "INFO:tornado.access:200 GET /static/js/bootstrap.min.js?v=5869c96cc8f19086aee625d670d741f9 (127.0.0.1) 0.90ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-dom.min.js?v=950495cc51ccb90612cf0fe0bb44f8f3 (127.0.0.1) 1.04ms\r\n",
            "INFO:tornado.access:200 GET /static/js/plotly-plotly.min.js?v=321426a3fa74680623478bd02a171587 (127.0.0.1) 4.97ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-react.min.js?v=bca103da5b5404d93783ccf73e0e9d1e (127.0.0.1) 0.90ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/layout_bin_packer?v=6c46683ed70fbb1443caf3531243836d (127.0.0.1) 0.92ms\r\n",
            "INFO:tornado.access:200 GET /static/js/main.js?v=883944086f3d7f2369c5c0a17e0b7268 (127.0.0.1) 2.17ms\r\n",
            "INFO:tornado.access:200 GET /static/js/mathjax-MathJax.js?v=49565b9ce89c64da075a5a39969b366e (127.0.0.1) 1.26ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/glyphicons-halflings-regular.woff2 (127.0.0.1) 1.14ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/glyphicons-halflings-regular.woff2 (127.0.0.1) 1.03ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.62ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 4.18ms\r\n",
            "INFO:tornado.access:200 GET / (127.0.0.1) 3.98ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathMenu.js?V=2.7.1 (127.0.0.1) 4.27ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.48ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 3.03ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathZoom.js?V=2.7.1 (127.0.0.1) 3.41ms\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1159, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1155, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1150, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1088, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.54ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.46ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1159, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1155, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1150, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1088, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 GET / (127.0.0.1) 2.57ms\r\n",
            "INFO:tornado.access:200 GET /static/css/bootstrap.min.css?v=ec3bb52a00e176a7181d454dffaea219 (127.0.0.1) 1.11ms\r\n",
            "INFO:tornado.access:200 GET /static/js/bootstrap.min.js?v=5869c96cc8f19086aee625d670d741f9 (127.0.0.1) 0.91ms\r\n",
            "INFO:tornado.access:200 GET /static/js/jquery.min.js?v=e071abda8fe61194711cfc2ab99fe104 (127.0.0.1) 1.03ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-resizable-styles.css?v=9f91a8dbf4d8f7ef1399e625660405f4 (127.0.0.1) 1.21ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-react.min.js?v=bca103da5b5404d93783ccf73e0e9d1e (127.0.0.1) 0.93ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-dom.min.js?v=950495cc51ccb90612cf0fe0bb44f8f3 (127.0.0.1) 1.00ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-grid-layout-styles.css?v=7dc8934d2f9ac5303b8f0bb1148152a0 (127.0.0.1) 0.85ms\r\n",
            "INFO:tornado.access:200 GET /static/js/mathjax-MathJax.js?v=49565b9ce89c64da075a5a39969b366e (127.0.0.1) 0.94ms\r\n",
            "INFO:tornado.access:200 GET /static/js/plotly-plotly.min.js?v=321426a3fa74680623478bd02a171587 (127.0.0.1) 4.36ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/layout_bin_packer?v=6c46683ed70fbb1443caf3531243836d (127.0.0.1) 0.92ms\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 2.62ms\r\n",
            "INFO:tornado.access:200 GET /static/js/main.js?v=883944086f3d7f2369c5c0a17e0b7268 (127.0.0.1) 1.69ms\r\n",
            "INFO:tornado.access:200 GET /static/css/style.css?v=7e45c3fff51fb67db56c3231b7614bc2 (127.0.0.1) 0.85ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/layout_bin_packer?v=6c46683ed70fbb1443caf3531243836d (127.0.0.1) 0.89ms\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 4.48ms\r\n",
            "INFO:tornado.access:200 GET /static/css/style.css?v=7e45c3fff51fb67db56c3231b7614bc2 (127.0.0.1) 0.90ms\r\n",
            "INFO:tornado.access:200 GET /static/js/main.js?v=883944086f3d7f2369c5c0a17e0b7268 (127.0.0.1) 1.82ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.61ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.29ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.24ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/glyphicons-halflings-regular.woff2 (127.0.0.1) 0.85ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathZoom.js?V=2.7.1 (127.0.0.1) 3.20ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathMenu.js?V=2.7.1 (127.0.0.1) 2.70ms\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.66ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.45ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.57ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.36ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.59ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.21ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.57ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.57ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.28ms\r\n",
            "INFO:root:from web client: {\"cmd\":\"close\",\"data\":\"my graph\",\"eid\":\"main\"}\r\n",
            "INFO:root:closing window my graph\r\n",
            "INFO:root:from web client: {\"cmd\":\"close\",\"data\":\"PR-curve\",\"eid\":\"main\"}\r\n",
            "INFO:root:closing window PR-curve\r\n",
            "INFO:root:from web client: {\"cmd\":\"close\",\"data\":\"ye raha curve\",\"eid\":\"main\"}\r\n",
            "INFO:root:closing window ye raha curve\r\n",
            "INFO:root:from web client: {\"cmd\":\"close\",\"data\":\"PR-->curve\",\"eid\":\"main\"}\r\n",
            "INFO:root:closing window PR-->curve\r\n",
            "INFO:root:from web client: {\"cmd\":\"close\",\"data\":\"PR curve\",\"eid\":\"main\"}\r\n",
            "INFO:root:closing window PR curve\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1159, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1155, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1150, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1088, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.72ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.54ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:tornado.access:200 GET / (127.0.0.1) 12.67ms\r\n",
            "INFO:tornado.access:200 GET /static/css/bootstrap.min.css?v=ec3bb52a00e176a7181d454dffaea219 (127.0.0.1) 3.37ms\r\n",
            "INFO:tornado.access:200 GET /static/js/bootstrap.min.js?v=5869c96cc8f19086aee625d670d741f9 (127.0.0.1) 0.91ms\r\n",
            "INFO:tornado.access:200 GET /static/js/jquery.min.js?v=e071abda8fe61194711cfc2ab99fe104 (127.0.0.1) 0.87ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-resizable-styles.css?v=9f91a8dbf4d8f7ef1399e625660405f4 (127.0.0.1) 0.75ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-dom.min.js?v=950495cc51ccb90612cf0fe0bb44f8f3 (127.0.0.1) 0.95ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-react.min.js?v=bca103da5b5404d93783ccf73e0e9d1e (127.0.0.1) 0.92ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-grid-layout-styles.css?v=7dc8934d2f9ac5303b8f0bb1148152a0 (127.0.0.1) 0.68ms\r\n",
            "INFO:tornado.access:200 GET /static/js/plotly-plotly.min.js?v=321426a3fa74680623478bd02a171587 (127.0.0.1) 4.37ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/layout_bin_packer?v=6c46683ed70fbb1443caf3531243836d (127.0.0.1) 0.92ms\r\n",
            "INFO:tornado.access:200 GET /static/js/mathjax-MathJax.js?v=49565b9ce89c64da075a5a39969b366e (127.0.0.1) 1.01ms\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 2.77ms\r\n",
            "INFO:tornado.access:200 GET /static/js/main.js?v=883944086f3d7f2369c5c0a17e0b7268 (127.0.0.1) 1.75ms\r\n",
            "INFO:tornado.access:200 GET /static/css/style.css?v=7e45c3fff51fb67db56c3231b7614bc2 (127.0.0.1) 0.88ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/layout_bin_packer?v=6c46683ed70fbb1443caf3531243836d (127.0.0.1) 0.93ms\r\n",
            "INFO:tornado.access:200 GET /static/css/style.css?v=7e45c3fff51fb67db56c3231b7614bc2 (127.0.0.1) 0.72ms\r\n",
            "INFO:tornado.access:200 GET /static/js/mathjax-MathJax.js?v=49565b9ce89c64da075a5a39969b366e (127.0.0.1) 0.70ms\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 2.40ms\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 1.67ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.96ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:tornado.access:200 GET /extensions/MathMenu.js?V=2.7.1 (127.0.0.1) 3.69ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathZoom.js?V=2.7.1 (127.0.0.1) 2.62ms\r\n",
            "INFO:tornado.access:304 GET / (127.0.0.1) 2.54ms\r\n",
            "INFO:tornado.access:200 GET /static/js/main.js?v=883944086f3d7f2369c5c0a17e0b7268 (127.0.0.1) 1.80ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/glyphicons-halflings-regular.woff2 (127.0.0.1) 1.03ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.73ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:304 GET /extensions/MathMenu.js?V=2.7.1 (127.0.0.1) 2.75ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 0.81ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 1.26ms\r\n",
            "INFO:tornado.access:304 GET /extensions/MathZoom.js?V=2.7.1 (127.0.0.1) 4.54ms\r\n",
            "WARNING:tornado.access:404 GET /favicon.ico (127.0.0.1) 10.85ms\r\n",
            "WARNING:tornado.access:404 GET /favicon.ico (127.0.0.1) 0.73ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.66ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.57ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.49ms\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1159, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1155, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1150, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1088, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.75ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.62ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.63ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.62ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.66ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.50ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.54ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.45ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.68ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.57ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.44ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.90ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.60ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.49ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.56ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.62ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.41ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.54ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.70ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.48ms\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1159, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1155, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1150, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1088, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.78ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.66ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1184, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1180, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1175, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1113, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.53ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.52ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:tornado.access:200 POST /events (::1) 13.71ms\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1184, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1180, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1175, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1113, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.58ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.47ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.68ms\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1184, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1180, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1175, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1113, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.55ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.38ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.65ms\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1184, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1180, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1175, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1113, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.90ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.60ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1184, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1180, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1175, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1113, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.70ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.43ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1184, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1180, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1175, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1113, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "/bin/bash: /usr/local/bin/python: No such file or directory\r\n",
            "/bin/bash: /usr/local/bin/python: No such file or directory\r\n",
            "/bin/bash: /usr/local/bin/python: No such file or directory\r\n",
            "/bin/bash: /usr/local/bin/python: No such file or directory\r\n",
            "/bin/bash: /usr/local/bin/python: No such file or directory\r\n",
            "/bin/bash: /: Is a directory\r\n",
            "/bin/bash: : command not found\r\n",
            "/bin/bash: drive/HAR1: No such file or directory\r\n",
            "/bin/bash: meow: command not found\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.73ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.53ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:tornado.access:200 GET / (127.0.0.1) 10.29ms\r\n",
            "INFO:tornado.access:200 GET /static/css/bootstrap.min.css?v=ec3bb52a00e176a7181d454dffaea219 (127.0.0.1) 3.59ms\r\n",
            "INFO:tornado.access:200 GET /static/js/main.js?v=a8b2ac5e05493fc00a903692a57a713f (127.0.0.1) 1.76ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/layout_bin_packer?v=6c46683ed70fbb1443caf3531243836d (127.0.0.1) 1.04ms\r\n",
            "INFO:tornado.access:200 GET /static/css/style.css?v=61ce84007d9040f654acf9a7be6c3ea8 (127.0.0.1) 0.65ms\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 2.34ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/layout_bin_packer?v=6c46683ed70fbb1443caf3531243836d (127.0.0.1) 0.66ms\r\n",
            "INFO:tornado.access:200 GET /favicon.png (127.0.0.1) 1.91ms\r\n",
            "INFO:tornado.access:200 GET /static/js/bootstrap.min.js?v=5869c96cc8f19086aee625d670d741f9 (127.0.0.1) 0.78ms\r\n",
            "INFO:tornado.access:200 GET /static/js/jquery.min.js?v=e071abda8fe61194711cfc2ab99fe104 (127.0.0.1) 1.33ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-resizable-styles.css?v=9f91a8dbf4d8f7ef1399e625660405f4 (127.0.0.1) 0.93ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-react.min.js?v=bca103da5b5404d93783ccf73e0e9d1e (127.0.0.1) 0.75ms\r\n",
            "INFO:tornado.access:200 GET /static/css/react-grid-layout-styles.css?v=7dc8934d2f9ac5303b8f0bb1148152a0 (127.0.0.1) 0.55ms\r\n",
            "INFO:tornado.access:200 GET /static/js/react-dom.min.js?v=950495cc51ccb90612cf0fe0bb44f8f3 (127.0.0.1) 0.68ms\r\n",
            "INFO:tornado.access:200 GET /static/js/mathjax-MathJax.js?v=49565b9ce89c64da075a5a39969b366e (127.0.0.1) 0.77ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 1.55ms\r\n",
            "INFO:tornado.access:200 GET /static/fonts/glyphicons-halflings-regular.woff2 (127.0.0.1) 1.07ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathMenu.js?V=2.7.1 (127.0.0.1) 2.66ms\r\n",
            "INFO:tornado.access:200 GET /extensions/MathZoom.js?V=2.7.1 (127.0.0.1) 2.53ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.72ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 0.97ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 0.87ms\r\n",
            "INFO:tornado.access:304 GET / (127.0.0.1) 2.42ms\r\n",
            "INFO:tornado.access:200 GET /static/js/plotly-plotly.min.js?v=f88e8e36dfb8b09f0a099de3ae72f815 (127.0.0.1) 4.76ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.73ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "WARNING:tornado.access:404 GET /favicon.ico (127.0.0.1) 0.61ms\r\n",
            "WARNING:tornado.access:404 GET /favicon.ico (127.0.0.1) 0.77ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 0.88ms\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 0.63ms\r\n",
            "INFO:tornado.access:304 GET /extensions/MathMenu.js?V=2.7.1 (127.0.0.1) 2.21ms\r\n",
            "INFO:tornado.access:304 GET /extensions/MathZoom.js?V=2.7.1 (127.0.0.1) 3.08ms\r\n",
            "INFO:tornado.access:101 GET /socket (127.0.0.1) 0.90ms\r\n",
            "INFO:root:Opened new socket from ip: 127.0.0.1\r\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 1.17ms\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 1.04ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.58ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.75ms\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.91ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.69ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.75ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.44ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.62ms\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1184, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1180, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1175, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1113, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.60ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.48ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1184, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1180, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1175, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1113, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 1.00ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.45ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.56ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.59ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.65ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.55ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.67ms\r\n",
            "INFO:tornado.access:200 POST /win_exists (::1) 0.43ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.56ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.60ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.55ms\r\n",
            "INFO:tornado.access:200 POST /win_exists (::1) 0.47ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.49ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.54ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.60ms\r\n",
            "INFO:tornado.access:200 POST /win_exists (::1) 0.47ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.55ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.57ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.62ms\r\n",
            "INFO:tornado.access:200 POST /win_exists (::1) 0.55ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.52ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.58ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.58ms\r\n",
            "INFO:tornado.access:200 POST /win_exists (::1) 0.43ms\r\n",
            "INFO:tornado.access:200 POST /update (::1) 0.43ms\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.69ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.84ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1184, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1180, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1175, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1113, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.48ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.43ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.70ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.61ms\r\n",
            "INFO:tornado.access:200 POST /events (::1) 0.59ms\r\n",
            "INFO:root:Application Started\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 1.22ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.86ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1184, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1180, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1175, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1113, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 1.35ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.50ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1184, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1180, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1175, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1113, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.65ms\r\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.47ms\r\n",
            "INFO:root:Opened visdom socket from ip: ::1\r\n",
            "Downloading scripts. It might take a while.\r\n",
            "It's Alive!\r\n",
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n",
            "    \"__main__\", fname, loader, pkg_name)\r\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n",
            "    exec code in run_globals\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1184, in <module>\r\n",
            "    download_scripts_and_run()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1180, in download_scripts_and_run\r\n",
            "    main()\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1175, in main\r\n",
            "    print_func=print_func, user_credential=user_credential)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1113, in start_server\r\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\r\n",
            "    server.listen(port, address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\r\n",
            "    sockets = bind_sockets(port, address=address)\r\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\r\n",
            "    sock.bind(sockaddr)\r\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\r\n",
            "    return getattr(self._sock,name)(*args)\r\n",
            "socket.error: [Errno 98] Address already in use\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C4HMgU0tcMmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3910
        },
        "outputId": "abc86d40-9dfc-4955-f1b2-118fe0f61fb2"
      },
      "cell_type": "code",
      "source": [
        "#import time\n",
        "#time.sleep(5)\n",
        "! cat url.txt"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "your url is: https://jolly-firefox-29.localtunnel.me\r\n",
            "/tools/node/lib/node_modules/localtunnel/bin/client:65\r\n",
            "        throw err;\r\n",
            "        ^\r\n",
            "\r\n",
            "Error: connection refused: localtunnel.me:37482 (check your firewall settings)\r\n",
            "    at Socket.<anonymous> (/tools/node/lib/node_modules/localtunnel/lib/TunnelCluster.js:47:32)\r\n",
            "    at emitOne (events.js:116:13)\r\n",
            "    at Socket.emit (events.js:211:7)\r\n",
            "    at emitErrorNT (internal/streams/destroy.js:64:8)\r\n",
            "    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n",
            "    at process._tickCallback (internal/process/next_tick.js:180:9)\r\n",
            "/tools/node/lib/node_modules/localtunnel/bin/client:65\r\n",
            "        throw err;\r\n",
            "        ^\r\n",
            "\r\n",
            "Error: connection refused: localtunnel.me:46453 (check your firewall settings)\r\n",
            "    at Socket.<anonymous> (/tools/node/lib/node_modules/localtunnel/lib/TunnelCluster.js:47:32)\r\n",
            "    at emitOne (events.js:116:13)\r\n",
            "    at Socket.emit (events.js:211:7)\r\n",
            "    at emitErrorNT (internal/streams/destroy.js:64:8)\r\n",
            "    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n",
            "    at process._tickCallback (internal/process/next_tick.js:180:9)\r\n",
            "/tools/node/lib/node_modules/localtunnel/bin/client:65\r\n",
            "        throw err;\r\n",
            "        ^\r\n",
            "\r\n",
            "Error: connection refused: localtunnel.me:34711 (check your firewall settings)\r\n",
            "    at Socket.<anonymous> (/tools/node/lib/node_modules/localtunnel/lib/TunnelCluster.js:47:32)\r\n",
            "    at emitOne (events.js:116:13)\r\n",
            "    at Socket.emit (events.js:211:7)\r\n",
            "    at emitErrorNT (internal/streams/destroy.js:64:8)\r\n",
            "    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n",
            "    at process._tickCallback (internal/process/next_tick.js:180:9)\r\n",
            "your url is: https://silly-horse-21.localtunnel.me\r\n",
            "/tools/node/lib/node_modules/localtunnel/bin/client:65\r\n",
            "        throw err;\r\n",
            "        ^\r\n",
            "\r\n",
            "Error: connection refused: localtunnel.me:46418 (check your firewall settings)\r\n",
            "    at Socket.<anonymous> (/tools/node/lib/node_modules/localtunnel/lib/TunnelCluster.js:47:32)\r\n",
            "    at emitOne (events.js:116:13)\r\n",
            "    at Socket.emit (events.js:211:7)\r\n",
            "    at emitErrorNT (internal/streams/destroy.js:64:8)\r\n",
            "    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n",
            "    at process._tickCallback (internal/process/next_tick.js:180:9)\r\n",
            "your url is: https://proud-deer-45.localtunnel.me\r\n",
            "your url is: https://nasty-fish-55.localtunnel.me\r\n",
            "/tools/node/lib/node_modules/localtunnel/bin/client:65\r\n",
            "        throw err;\r\n",
            "        ^\r\n",
            "\r\n",
            "Error: connection refused: localtunnel.me:43565 (check your firewall settings)\r\n",
            "    at Socket.<anonymous> (/tools/node/lib/node_modules/localtunnel/lib/TunnelCluster.js:47:32)\r\n",
            "    at emitOne (events.js:116:13)\r\n",
            "    at Socket.emit (events.js:211:7)\r\n",
            "    at emitErrorNT (internal/streams/destroy.js:64:8)\r\n",
            "    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n",
            "    at process._tickCallback (internal/process/next_tick.js:180:9)\r\n",
            "/tools/node/lib/node_modules/localtunnel/bin/client:65\r\n",
            "        throw err;\r\n",
            "        ^\r\n",
            "\r\n",
            "Error: connection refused: localtunnel.me:38386 (check your firewall settings)\r\n",
            "    at Socket.<anonymous> (/tools/node/lib/node_modules/localtunnel/lib/TunnelCluster.js:47:32)\r\n",
            "    at emitOne (events.js:116:13)\r\n",
            "    at Socket.emit (events.js:211:7)\r\n",
            "    at emitErrorNT (internal/streams/destroy.js:64:8)\r\n",
            "    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n",
            "    at process._tickCallback (internal/process/next_tick.js:180:9)\r\n",
            "your url is: https://rotten-bear-32.localtunnel.me\r\n",
            "your url is: https://terrible-mole-82.localtunnel.me\r\n",
            "your url is: https://good-hound-61.localtunnel.me\r\n",
            "/tools/node/lib/node_modules/localtunnel/bin/client:65\r\n",
            "        throw err;\r\n",
            "        ^\r\n",
            "\r\n",
            "Error: connection refused: localtunnel.me:45209 (check your firewall settings)\r\n",
            "    at Socket.<anonymous> (/tools/node/lib/node_modules/localtunnel/lib/TunnelCluster.js:47:32)\r\n",
            "    at emitOne (events.js:116:13)\r\n",
            "    at Socket.emit (events.js:211:7)\r\n",
            "    at emitErrorNT (internal/streams/destroy.js:64:8)\r\n",
            "    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n",
            "    at process._tickCallback (internal/process/next_tick.js:180:9)\r\n",
            "your url is: https://chatty-kangaroo-95.localtunnel.me\r\n",
            "/tools/node/lib/node_modules/localtunnel/bin/client:65\r\n",
            "        throw err;\r\n",
            "        ^\r\n",
            "\r\n",
            "Error: connection refused: localtunnel.me:38789 (check your firewall settings)\r\n",
            "    at Socket.<anonymous> (/tools/node/lib/node_modules/localtunnel/lib/TunnelCluster.js:47:32)\r\n",
            "    at emitOne (events.js:116:13)\r\n",
            "    at Socket.emit (events.js:211:7)\r\n",
            "    at emitErrorNT (internal/streams/destroy.js:64:8)\r\n",
            "    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n",
            "    at process._tickCallback (internal/process/next_tick.js:180:9)\r\n",
            "your url is: https://loud-turkey-39.localtunnel.me\r\n",
            "your url is: https://tough-fly-11.localtunnel.me\r\n",
            "your url is: https://happy-insect-51.localtunnel.me\r\n",
            "your url is: https://mighty-grasshopper-27.localtunnel.me\r\n",
            "your url is: https://spicy-goat-53.localtunnel.me\r\n",
            "your url is: https://horrible-skunk-96.localtunnel.me\r\n",
            "/tools/node/lib/node_modules/localtunnel/bin/client:65\r\n",
            "        throw err;\r\n",
            "        ^\r\n",
            "\r\n",
            "Error: connection refused: localtunnel.me:44017 (check your firewall settings)\r\n",
            "    at Socket.<anonymous> (/tools/node/lib/node_modules/localtunnel/lib/TunnelCluster.js:47:32)\r\n",
            "    at emitOne (events.js:116:13)\r\n",
            "    at Socket.emit (events.js:211:7)\r\n",
            "    at emitErrorNT (internal/streams/destroy.js:64:8)\r\n",
            "    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n",
            "    at process._tickCallback (internal/process/next_tick.js:180:9)\r\n",
            "your url is: https://bad-pug-18.localtunnel.me\r\n",
            "your url is: https://clever-dragon-81.localtunnel.me\r\n",
            "your url is: https://hard-tiger-41.localtunnel.me\r\n",
            "your url is: https://wonderful-bear-12.localtunnel.me\r\n",
            "your url is: https://polite-panda-95.localtunnel.me\r\n",
            "your url is: https://rude-mayfly-24.localtunnel.me\r\n",
            "your url is: https://evil-goat-12.localtunnel.me\r\n",
            "/tools/node/lib/node_modules/localtunnel/bin/client:65\r\n",
            "        throw err;\r\n",
            "        ^\r\n",
            "\r\n",
            "Error: connection refused: localtunnel.me:44644 (check your firewall settings)\r\n",
            "    at Socket.<anonymous> (/tools/node/lib/node_modules/localtunnel/lib/TunnelCluster.js:47:32)\r\n",
            "    at emitOne (events.js:116:13)\r\n",
            "    at Socket.emit (events.js:211:7)\r\n",
            "    at emitErrorNT (internal/streams/destroy.js:64:8)\r\n",
            "    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n",
            "    at process._tickCallback (internal/process/next_tick.js:180:9)\r\n",
            "your url is: https://chilly-pig-45.localtunnel.me\r\n",
            "/tools/node/lib/node_modules/localtunnel/bin/client:65\r\n",
            "        throw err;\r\n",
            "        ^\r\n",
            "\r\n",
            "Error: connection refused: localtunnel.me:36289 (check your firewall settings)\r\n",
            "    at Socket.<anonymous> (/tools/node/lib/node_modules/localtunnel/lib/TunnelCluster.js:47:32)\r\n",
            "    at emitOne (events.js:116:13)\r\n",
            "    at Socket.emit (events.js:211:7)\r\n",
            "    at emitErrorNT (internal/streams/destroy.js:64:8)\r\n",
            "    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n",
            "    at process._tickCallback (internal/process/next_tick.js:180:9)\r\n",
            "your url is: https://pink-seahorse-93.localtunnel.me\r\n",
            "your url is: https://fresh-cougar-44.localtunnel.me\r\n",
            "your url is: https://sharp-parrot-83.localtunnel.me\r\n",
            "your url is: https://foolish-otter-3.localtunnel.me\r\n",
            "your url is: https://tricky-bat-83.localtunnel.me\r\n",
            "your url is: https://dull-tiger-88.localtunnel.me\r\n",
            "your url is: https://fast-shrimp-46.localtunnel.me\r\n",
            "your url is: https://nasty-panda-36.localtunnel.me\r\n",
            "your url is: https://blue-insect-60.localtunnel.me\r\n",
            "/tools/node/lib/node_modules/localtunnel/bin/client:65\r\n",
            "        throw err;\r\n",
            "        ^\r\n",
            "\r\n",
            "Error: connection refused: localtunnel.me:32840 (check your firewall settings)\r\n",
            "    at Socket.<anonymous> (/tools/node/lib/node_modules/localtunnel/lib/TunnelCluster.js:47:32)\r\n",
            "    at emitOne (events.js:116:13)\r\n",
            "    at Socket.emit (events.js:211:7)\r\n",
            "    at emitErrorNT (internal/streams/destroy.js:64:8)\r\n",
            "    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n",
            "    at process._tickCallback (internal/process/next_tick.js:180:9)\r\n",
            "/tools/node/lib/node_modules/localtunnel/bin/client:65\r\n",
            "        throw err;\r\n",
            "        ^\r\n",
            "\r\n",
            "Error: connection refused: localtunnel.me:46511 (check your firewall settings)\r\n",
            "    at Socket.<anonymous> (/tools/node/lib/node_modules/localtunnel/lib/TunnelCluster.js:47:32)\r\n",
            "    at emitOne (events.js:116:13)\r\n",
            "    at Socket.emit (events.js:211:7)\r\n",
            "    at emitErrorNT (internal/streams/destroy.js:64:8)\r\n",
            "    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n",
            "    at process._tickCallback (internal/process/next_tick.js:180:9)\r\n",
            "/bin/bash: lt: command not found\r\n",
            "/bin/bash: lt: command not found\r\n",
            "/bin/bash: lt: command not found\r\n",
            "/bin/bash: lt: command not found\r\n",
            "/bin/bash: lt: command not found\r\n",
            "/bin/bash: lt: command not found\r\n",
            "/bin/bash: lt: command not found\r\n",
            "/bin/bash: lt: command not found\r\n",
            "/bin/bash: lt: command not found\r\n",
            "your url is: https://black-turtle-69.localtunnel.me\r\n",
            "your url is: https://tall-elephant-41.localtunnel.me\r\n",
            "your url is: https://strange-turtle-42.localtunnel.me\r\n",
            "your url is: https://lovely-badger-11.localtunnel.me\r\n",
            "your url is: https://sweet-ladybug-29.localtunnel.me\r\n",
            "your url is: https://selfish-elephant-14.localtunnel.me\r\n",
            "/tools/node/lib/node_modules/localtunnel/bin/client:65\r\n",
            "        throw err;\r\n",
            "        ^\r\n",
            "\r\n",
            "Error: connection refused: localtunnel.me:37945 (check your firewall settings)\r\n",
            "    at Socket.<anonymous> (/tools/node/lib/node_modules/localtunnel/lib/TunnelCluster.js:47:32)\r\n",
            "    at emitOne (events.js:116:13)\r\n",
            "    at Socket.emit (events.js:211:7)\r\n",
            "    at emitErrorNT (internal/streams/destroy.js:64:8)\r\n",
            "    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n",
            "    at process._tickCallback (internal/process/next_tick.js:180:9)\r\n",
            "your url is: https://thin-newt-91.localtunnel.me\r\n",
            "your url is: https://new-husky-82.localtunnel.me\r\n",
            "your url is: https://heavy-gecko-14.localtunnel.me\r\n",
            "your url is: https://swift-grasshopper-96.localtunnel.me\r\n",
            "your url is: https://strange-rattlesnake-63.localtunnel.me\r\n",
            "your url is: https://brave-donkey-15.localtunnel.me\r\n",
            "/tools/node/lib/node_modules/localtunnel/bin/client:65\r\n",
            "        throw err;\r\n",
            "        ^\r\n",
            "\r\n",
            "Error: connection refused: localtunnel.me:36243 (check your firewall settings)\r\n",
            "    at Socket.<anonymous> (/tools/node/lib/node_modules/localtunnel/lib/TunnelCluster.js:47:32)\r\n",
            "    at emitOne (events.js:116:13)\r\n",
            "    at Socket.emit (events.js:211:7)\r\n",
            "    at emitErrorNT (internal/streams/destroy.js:64:8)\r\n",
            "    at _combinedTickCallback (internal/process/next_tick.js:138:11)\r\n",
            "    at process._tickCallback (internal/process/next_tick.js:180:9)\r\n",
            "your url is: https://tough-turkey-4.localtunnel.me\r\n",
            "your url is: https://horrible-turkey-57.localtunnel.me\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TAlfMpM26Xzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "89905f10-59e0-4acb-d7f7-8648049a7c60"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t\t\t      run_logs\r\n",
            "datacombined.csv\t      runs\r\n",
            "ep200.h5\t\t      SimpleHTTPServerWithUpload.py\r\n",
            "meow\t\t\t      Temporal_CNN.ipynb\r\n",
            "model_best.pth.tar\t      tensorboard_run.ipynb\r\n",
            "ngrok\t\t\t      test\r\n",
            "ngrok-stable-linux-amd64.zip  test.csv\r\n",
            "node_modules\t\t      train\r\n",
            "output\t\t\t      train.csv\r\n",
            "package (45127004).json       two-stream-action-recognition-master\r\n",
            "package.json\t\t      url.txt\r\n",
            "run\t\t\t      visdomlog.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jbaZAp8f0dFK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vis = Visualizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q0PwrMW7lrtO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "4ab0a05b-1242-49e3-e535-b347b8f2a5f2"
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/pytorch/tnt.git@master\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/pytorch/tnt.git@master\r\n",
            "  Cloning https://github.com/pytorch/tnt.git (to revision master) to /tmp/pip-req-build-y7uhkzoc\n",
            "Requirement already satisfied (use --upgrade to upgrade): torchnet==0.0.4 from git+https://github.com/pytorch/tnt.git@master in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchnet==0.0.4) (0.3.0.post4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchnet==0.0.4) (1.11.0)\n",
            "Requirement already satisfied: visdom in /usr/local/lib/python3.6/dist-packages (from torchnet==0.0.4) (0.1.8.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchnet==0.0.4) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchnet==0.0.4) (1.14.5)\n",
            "Requirement already satisfied: torchfile in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4) (0.1.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4) (0.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4) (2.18.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4) (0.19.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4) (4.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4) (5.2.0)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4) (16.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4) (2018.8.13)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4) (3.0.4)\n",
            "Building wheels for collected packages: torchnet\n",
            "  Running setup.py bdist_wheel for torchnet ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-qc598kl5/wheels/17/05/ec/d05d051a225871af52bf504f5e8daf57704811b3c1850d0012\n",
            "Successfully built torchnet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k_Kyxrq6udte",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "6332fb9a-ad1a-49e1-fc5b-79a46176c899"
      },
      "cell_type": "code",
      "source": [
        "!ls \n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t\t\t      run_logs\r\n",
            "datacombined.csv\t      runs\r\n",
            "ep200.h5\t\t      SimpleHTTPServerWithUpload.py\r\n",
            "meow\t\t\t      Temporal_CNN.ipynb\r\n",
            "model_best.pth.tar\t      tensorboard_run.ipynb\r\n",
            "ngrok\t\t\t      test\r\n",
            "ngrok-stable-linux-amd64.zip  test.csv\r\n",
            "node_modules\t\t      train\r\n",
            "output\t\t\t      train.csv\r\n",
            "package (45127004).json       two-stream-action-recognition-master\r\n",
            "package.json\t\t      url.txt\r\n",
            "run\t\t\t      visdomlog.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XOIA-bLqn8bo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torchnet as tnt\n",
        "from torchnet.engine import Engine\n",
        "from torchnet.logger import VisdomPlotLogger, VisdomLogger"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Ipsg72jqAXw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1074
        },
        "outputId": "e06c854f-8edf-45b3-c82d-51999f8d92f0"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from torchnet.engine import Engine\n",
        "from torchnet.logger import VisdomPlotLogger, VisdomLogger\n",
        "import torchnet as tnt\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics import roc_curve,auc\n",
        "#from sklearn.metrix import confusion_matrix\n",
        "import numpy as np\n",
        "#from tensorboard_logger import configure, log_value\n",
        "\n",
        "confusion_matrix = tnt.meter.ConfusionMeter(7) #I have 7 classes here\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    \"\"\"Saves checkpoint to disk\"\"\"\n",
        "    directory = \"output/%s/\"%('checkpoint')\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    filename = directory + filename\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'output/%s/'%('checkpoint') + 'model_best1.pth.tar')\n",
        "        \n",
        "def main():\n",
        "    #global prec1\n",
        "    global best_prec1 \n",
        "    #prec1=0\n",
        "    #tensorboard = True\n",
        "    epochs=300\n",
        "    start_epoch=0\n",
        "    batch_size=64\n",
        "    lr=1e-1\n",
        "    momentum=0.9\n",
        "    weight_decay=1e-4\n",
        "    print_freq=10\n",
        "    layers=100\n",
        "    growth=12\n",
        "    droprate = 0.0\n",
        "    reduce=0.5\n",
        "    resume=\"\" #\"output/checkpoint/ccheckpoint (ecff0ae0).pth.tar\"\n",
        "    best_prec1 = 0 \n",
        "    print_freq = 10\n",
        "    global co\n",
        "    co = 0\n",
        "  \n",
        "    #name = 'temporal_cnn'\n",
        "    #global tensorboard,start_epoch\n",
        "    #global best_prec1,start_epoch\n",
        "    #configure(\"run_logs/%s\"%(name))\n",
        "    # create model\n",
        "    model = modelres\n",
        "\n",
        "    model = model.cuda()\n",
        "   \n",
        "    # optionally resume from a checkpoint\n",
        "    if resume:\n",
        "        if os.path.isfile(resume):\n",
        "            print(\"=> loading checkpoint '{}'\".format(resume))\n",
        "            checkpoint = torch.load(resume)\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            best_prec1 = checkpoint['best_prec1']\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "                  .format(resume, checkpoint['epoch']))\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(resume))\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    # define loss function (criterion) and pptimizer\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "                                  \n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        adjust_learning_rate(optimizer, epoch)\n",
        "        co = co + 1\n",
        "     \n",
        "        # train for one epoch\n",
        "      \n",
        "        start_time = time.time()\n",
        "\n",
        "\n",
        "        acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
        "\n",
        "        # evaluate on validation set\n",
        "        prec1 = validate(val_loader, model, criterion, epoch)\n",
        "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "        \n",
        "        model_accuracy = {'Train_Acc':acc_train,\n",
        "            'Val_Acc':prec1}\n",
        "        \n",
        "        vis.plot_combine(\"ACCURACY\",model_accuracy)\n",
        "\n",
        "        # remember best prec@1 and save checkpoint\n",
        "\n",
        "        is_best = prec1 > best_prec1\n",
        "        best_prec1 = max(prec1, best_prec1)\n",
        "        #print(best_prec1)\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_prec1': best_prec1,\n",
        "        }, is_best)\n",
        "   #print('Best accuracy: ', best_prec1)\n",
        "    \n",
        "      \n",
        "\n",
        "global predicted_label\n",
        "global actual_label\n",
        "predicted_label = []\n",
        "actual_label = []\n",
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    \"\"\"Train for one epoch on the training set\"\"\"\n",
        "\n",
        "    print_freq = 10\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    \n",
        "    num_elements = len(train_dataset)\n",
        "    num_batches = len(train_loader)\n",
        "    batch_size = train_loader.batch_size\n",
        "    predictions = torch.zeros(num_elements)\n",
        "    actual_label = torch.zeros(num_elements)\n",
        "    confusion_matrix.reset()\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):   \n",
        "        \n",
        "        target = target.cuda(async=True)\n",
        "        input = input.cuda()\n",
        "        input_var = torch.autograd.Variable(input)\n",
        "        target_var = torch.autograd.Variable(target)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)            \n",
        "\n",
        "        s = i*batch_size\n",
        "        e = s + batch_size\n",
        "        if i == num_batches - 1:\n",
        "            e = num_elements\n",
        "        _, preds = torch.max(output, dim=1)\n",
        "        #print(\":/\",preds)\n",
        "        predictions[s:e] = preds.data\n",
        "        actual_label[s:e] = target_var.data\n",
        "        \n",
        "        loss = criterion(output, target_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
        "        losses.update(loss.data[0], input.size(0))\n",
        "        top1.update(prec1[0], input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            #mlog.print_meter(\"Train\", epoch, i, len(train_loader))  \n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                      loss=losses, top1=top1))\n",
        "    #print(predictions)\n",
        "    #print(\"->\",predictions)\n",
        "    #print(list(np.asarray(predictions)))\n",
        "    #print(list(np.asarray(predictions)+1))#,list(np.asarray(actual_label)+1))\n",
        "    #print(np.array(list(np.asarray(predictions)+1)))\n",
        "    #p = (np.array(list(pr)))\n",
        "    #print(torch.from_numpy(p))\n",
        "    if co not in [1,2,3,4,5,6]:\n",
        "      vis.plot('Train_Loss',losses.avg)\n",
        "    #confusion_matrix.add(torch.from_numpy(np.array(list(np.asarray(predictions)+1))),torch.from_numpy(np.array(list(np.asarray(actual_label)+1))))\n",
        "    confusion_matrix.add(predictions,actual_label)\n",
        "    precision, recall, fscore, support = score(Variable(actual_label).data.numpy(),Variable(predictions).data.numpy())\n",
        "  \n",
        "    #fpr, tpr, threshold = roc_curve(y_test, preds)\n",
        "    #roc_auc = auc(fpr, tpr)\n",
        "    \n",
        "\n",
        "            \n",
        "    pr = {\n",
        "         'class-1':[precision[0],recall[0]],'class-2':[precision[1],recall[1]],'class-3':[precision[2],recall[2]],\n",
        "         'class-4':[precision[3],recall[3]],'class-5':[precision[4],recall[4]],'class-6':[precision[5],recall[5]],'class-7':[precision[6],recall[6]]\n",
        "         }\n",
        "  \n",
        "    #vis.plot_combine1('PR CURVE',pr)\n",
        "    \n",
        "    vis.heatmap(\n",
        "        X=np.flipud(confusion_matrix.value()),\n",
        "        opts=dict(\n",
        "            columnnames=['class-7', 'class-6', 'class-5', 'class-4', 'class-3', 'class-2', 'class-1'],\n",
        "            rownames=['class-7', 'class-6', 'class-5', 'class-4', 'class-3','class-2','class-1'],\n",
        "            colormap='Electric',\n",
        "        ),\n",
        "        win = 'conf_train',\n",
        "        env = 'main'\n",
        "    )\n",
        "   \n",
        "    predictions = torch.zeros(num_elements)\n",
        "    actual_label = torch.zeros(num_elements)\n",
        "  \n",
        "    return top1.avg\n",
        "\n",
        "  \n",
        "def validate(val_loader, model, criterion, epoch):\n",
        "    print_freq = 10\n",
        "    \"\"\"Perform validation on the validation set\"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    \n",
        "    num_elements = len(val_dataset)\n",
        "    num_batches = len(val_loader)\n",
        "    batch_size = val_loader.batch_size\n",
        "    predictions = torch.zeros(num_elements)\n",
        "    actual_label = torch.zeros(num_elements)\n",
        "    confusion_matrix.reset()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(val_loader):\n",
        "        \n",
        "        target = target.cuda(async=True)\n",
        "        input = input.cuda()\n",
        "        input_var = torch.autograd.Variable(input, volatile=True)\n",
        "        target_var = torch.autograd.Variable(target, volatile=True)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)\n",
        "        loss = criterion(output, target_var)\n",
        "        \n",
        "        s = i*batch_size\n",
        "        e = s + batch_size\n",
        "        if i == num_batches - 1:\n",
        "            e = num_elements\n",
        "        _, preds = torch.max(output, dim=1)\n",
        "        predictions[s:e] = preds.data\n",
        "        actual_label[s:e] = target_var.data\n",
        "                \n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
        "        losses.update(loss.data[0], input.size(0))\n",
        "        top1.update(prec1[0], input.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "        \n",
        "        if i % print_freq == 0:\n",
        "            print('Test: [{0}/{1}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                      i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                      top1=top1))\n",
        "    if co not in [1,2,3,4,5,6]:\n",
        "      vis.plot('Val_Loss',losses.avg)\n",
        "    \n",
        "    confusion_matrix.add(predictions,actual_label)\n",
        "    \n",
        "    precision, recall, fscore, support = score(Variable(actual_label).data.numpy(),Variable(predictions).data.numpy())\n",
        "  \n",
        "    #fpr, tpr, threshold = roc_curve(y_test, preds)\n",
        "    #roc_auc = auc(fpr, tpr)\n",
        "            \n",
        "    pr = {\n",
        "         'class-1':[precision[0],recall[0]],'class-2':[precision[1],recall[1]],'class-3':[precision[2],recall[2]],\n",
        "         'class-4':[precision[3],recall[3]],'class-5':[precision[4],recall[4]],'class-6':[precision[5],recall[5]],'class-7':[precision[6],recall[6]]\n",
        "         }\n",
        "\n",
        "    #vis.plot_combine1('ye raha curve',pr)\n",
        "    \n",
        "    vis.heatmap(\n",
        "        X=np.flipud(confusion_matrix.value()),\n",
        "        opts=dict(\n",
        "            columnnames=['class=7', 'class=6', 'class=5', 'class=4', 'class=3', 'class=2', 'class=1'],\n",
        "            rownames=['class=7', 'class=6', 'class=5', 'class=4', 'class=3','class=2','class=1'],\n",
        "            colormap='Electric',\n",
        "        ),\n",
        "        win = 'conf_val',\n",
        "        env = 'main'\n",
        "    )\n",
        "\n",
        "    \n",
        "    predictions = torch.zeros(num_elements)\n",
        "    actual_label = torch.zeros(num_elements)\n",
        "\n",
        "    # log to TensorBoard\n",
        "    \"\"\"if tensorboard:\n",
        "        log_value('val_loss', losses.avg, epoch)\n",
        "        log_value('val_acc', top1.avg, epoch)\"\"\"\n",
        "    return top1.avg\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    lr = 0.1\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 after 150 and 225 epochs\"\"\"\n",
        "    lr = lr * (0.1 ** (epoch // 150)) * (0.1 ** (epoch // 225))\n",
        "    # log to TensorBoard\n",
        "    \"\"\"if tensorboard:\n",
        "        log_value('learning_rate', lr, epoch)\"\"\"\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "  main()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-21e5875f94cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-116-21e5875f94cc>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-116-21e5875f94cc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-dac65084ef0d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_custom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 277\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 torch.backends.cudnn.deterministic, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight[64, 20, 7, 7], so expected input[64, 3, 216, 216] to have 20 channels, but got 3 channels instead"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "LSkBIJEu0vTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1198
        },
        "outputId": "6fecaaac-65ef-4a26-f3ac-9784ef579c0c"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchnet.engine import Engine\n",
        "from torchnet.logger import VisdomPlotLogger, VisdomLogger\n",
        "import torchnet as tnt\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics import roc_curve,auc\n",
        "#from sklearn.metrix import confusion_matrix\n",
        "import numpy as np\n",
        "#from tensorboard_logger import configure, log_value\n",
        "#from visdom import Visdom\n",
        "#plotter = VisdomLinePlotter(env_name=\"HAR_PLOT\")\n",
        "#mlog = MeterLogger(server=\"localhost\", port=\"6006\", nclass=7,title=\"har_ConvNet\")\n",
        "confusion_matrix = tnt.meter.ConfusionMeter(7) #I have 2 classes here\n",
        "\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint1.pth.tar'):\n",
        "    \"\"\"Saves checkpoint to disk\"\"\"\n",
        "    directory = \"output/%s/\"%('checkpoint')\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    filename = directory + filename\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'output/%s/'%('checkpoint') + 'model_best1.pth.tar')\n",
        "        \n",
        "def main():\n",
        "    #global prec1\n",
        "    global best_prec1 \n",
        "    #prec1=0\n",
        "    #tensorboard = True\n",
        "    epochs=2\n",
        "    start_epoch=0\n",
        "    batch_size=128\n",
        "    lr=1e-2\n",
        "    momentum=0.9\n",
        "    weight_decay=1e-4\n",
        "    print_freq=10\n",
        "    layers=100\n",
        "    growth=12\n",
        "    droprate = 0.0\n",
        "    reduce=0.5\n",
        "    resume=\"\" #\"output/checkpoint/ccheckpoint (ecff0ae0).pth.tar\"\n",
        "    best_prec1 = 0 \n",
        "    print_freq = 10\n",
        "  \n",
        "    #name = 'temporal_cnn'\n",
        "    #global tensorboard,start_epoch\n",
        "    #global best_prec1,start_epoch\n",
        "    #configure(\"run_logs/%s\"%(name))\n",
        "    # create model\n",
        "    model = modelres\n",
        "\n",
        "    model = model#.cuda()\n",
        "   \n",
        "    # optionally resume from a checkpoint\n",
        "    if resume:\n",
        "        if os.path.isfile(resume):\n",
        "            print(\"=> loading checkpoint '{}'\".format(resume))\n",
        "            checkpoint = torch.load(resume)\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            best_prec1 = checkpoint['best_prec1']\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "                  .format(resume, checkpoint['epoch']))\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(resume))\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    # define loss function (criterion) and pptimizer\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "                                  \n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        #adjust_learning_rate(optimizer, epoch)\n",
        "     \n",
        "        # train for one epoch\n",
        "        train(train_loader, model, criterion, optimizer, epoch)\n",
        "\n",
        "        # evaluate on validation set\n",
        "        prec1 = validate(val_loader, model, criterion, epoch)\n",
        "        #print(\"myprediction:\",prec1)\n",
        "        # remember best prec@1 and save checkpoint\n",
        "        #print(\"prec1:\",prec1)\n",
        "        #print(\"best_prec1:\",best_prec1)\n",
        "        is_best = prec1 > best_prec1\n",
        "        best_prec1 = max(prec1, best_prec1)\n",
        "        #print(best_prec1)\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_prec1': best_prec1,\n",
        "        }, is_best)\n",
        "   #print('Best accuracy: ', best_prec1)\n",
        "    \n",
        "      \n",
        "\n",
        "global predicted_label\n",
        "global actual_label\n",
        "predicted_label = []\n",
        "actual_label = []\n",
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    \"\"\"Train for one epoch on the training set\"\"\"\n",
        "\n",
        "    print_freq = 10\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    \n",
        "    num_elements = len(train_dataset)\n",
        "    num_batches = len(train_loader)\n",
        "    batch_size = train_loader.batch_size\n",
        "    predictions = torch.zeros(num_elements)\n",
        "    actual_label = torch.zeros(num_elements)\n",
        "    confusion_matrix.reset()\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):   \n",
        "        \n",
        "        target = target#.cuda(async=True)\n",
        "        input = input#.cuda()\n",
        "        input_var = torch.autograd.Variable(input)\n",
        "        target_var = torch.autograd.Variable(target)\n",
        "        # online ploter\n",
        "        #mlog.timer.reset()\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var) \n",
        "        #print(output.data)\n",
        "        #pred = output.data.max(1)[1] # get the index of the max log-probability\n",
        "        #print(pred)\n",
        "        #print(target_var.data)\n",
        "        #correct += pred.eq(target.data).cpu().sum()\n",
        "        #print(output.data)\n",
        "        #confusion_matrix.add(output.data.squeeze(), target.type(t.LongTensor))\n",
        "        #confusion_matrix.add(output.data, target_var.data)\n",
        "        #actual_label.append(target_var.data)\n",
        "        \n",
        "        #print(actual_label.append((output.data.max(1)[1]).cpu()))\n",
        "        #print((output.data.max(1)[1]))\n",
        "        #print(\"ye lo:\",torch.max(output, 1)[1])\n",
        "\n",
        "        s = i*batch_size\n",
        "        e = s + batch_size\n",
        "        if i == num_batches - 1:\n",
        "            e = num_elements\n",
        "        #preds = output.data.max(1)[1]\n",
        "        _, preds = torch.max(output, 1)\n",
        "        predictions[s:e] = preds\n",
        "        actual_label[s:e] = target_var.data\n",
        "        \n",
        "        loss = criterion(output, target_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
        "        losses.update(loss.data[0], input.size(0))\n",
        "        top1.update(prec1[0], input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # online ploter\n",
        "        #mlog.update_loss(loss, meter='loss')\n",
        "\t      #mlog.updateLoss(l1_loss, meter='l1_loss')\n",
        "        #mlog.update_meter(output, target_var, meters={'accuracy', 'map'})\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            #mlog.print_meter(\"Train\", epoch, i, len(train_loader))  \n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                      loss=losses, top1=top1))\n",
        "    loss = {'Train_Acc':top1.avg,\n",
        "            'Train_Loss':losses.avg}\n",
        "    vis.plot(\"Train_Acc\",top1.avg)\n",
        "    #vis.plot_combine(\"meow:\",loss)\n",
        "    #vis.plot_all(loss)\n",
        "    \n",
        "    \n",
        "    #vis.add_pr_curve(self, tag, labels, predictions, global_step=None, num_thresholds=127, weights=None):\n",
        "\n",
        "    #plotter.plot('acc', 'test', epoch, top1.avg)\n",
        "    #plotter.plot('loss', 'test', epoch, losses.avg)\n",
        "    # log to TensorBoard\n",
        "    \"\"\"if tensorboard:\n",
        "        log_value('train_loss', losses.avg, epoch)\n",
        "        log_value('train_acc', top1.avg, epoch)\"\"\"\n",
        "        # online ploter\n",
        "    #mlog.reset_meter(epoch, mode='Train')\n",
        "    #print(confusion_matrix.conf)\n",
        "    #print(predictions.size(0))\n",
        "    print(predictions)\n",
        "    confusion_matrix.add(predictions,actual_label)\n",
        "    #print(confusion_matrix.conf)\n",
        "    #print(actual_label)\n",
        "    #print(Variable(actual_label).data.numpy())\n",
        "    #compute_curve(Variable(actual_label).data.numpy(),Variable(predictions).data.numpy())\n",
        "    \n",
        "    precision, recall, fscore, support = score(Variable(actual_label).data.numpy(),Variable(predictions).data.numpy())\n",
        "    #print('precision: {}'.format(precision))\n",
        "    #print('recall: {}'.format(recall))\n",
        "    #print('fscore: {}'.format(fscore))\n",
        "    #print('support: {}'.format(support))   \n",
        "    #fpr, tpr, threshold = roc_curve(y_test, preds)\n",
        "    #roc_auc = auc(fpr, tpr)\n",
        "   \n",
        "    predictions = torch.zeros(num_elements)\n",
        "    actual_label = torch.zeros(num_elements)\n",
        "\n",
        "    \n",
        "    return top1.avg\n",
        "\n",
        "  \n",
        "def validate(val_loader, model, criterion, epoch):\n",
        "    print_freq = 10\n",
        "    \"\"\"Perform validation on the validation set\"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(val_loader):\n",
        "        \n",
        "        target = target#.cuda(async=True)\n",
        "        input = input#.cuda()\n",
        "        input_var = torch.autograd.Variable(input, volatile=True)\n",
        "        target_var = torch.autograd.Variable(target, volatile=True)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)\n",
        "        loss = criterion(output, target_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
        "        losses.update(loss.data[0], input.size(0))\n",
        "        top1.update(prec1[0], input.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "        \n",
        "        if i % print_freq == 0:\n",
        "            print('Test: [{0}/{1}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                      i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                      top1=top1))\n",
        "    \"\"\"loss = {'Val_Acc':top1.avg,\n",
        "            'Val_Loss':losses.avg}\n",
        "    vis.plot_all(loss)\"\"\"\n",
        "            \n",
        "    #print(' * Prec@1 {top1.avg:.3f}'.format(top1=top1))\n",
        "    #plotter.plot('acc', 'test', epoch, top1.avg)\n",
        "    #plotter.plot('loss', 'test', epoch, losses.avg)\n",
        "    # log to TensorBoard\n",
        "    \"\"\"if tensorboard:\n",
        "        log_value('val_loss', losses.avg, epoch)\n",
        "        log_value('val_acc', top1.avg, epoch)\"\"\"\n",
        "    return top1.avg\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    lr = 0.1\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 after 150 and 225 epochs\"\"\"\n",
        "    lr = lr * (0.1 ** (epoch // 150)) * (0.1 ** (epoch // 225))\n",
        "    # log to TensorBoard\n",
        "    \"\"\"if tensorboard:\n",
        "        log_value('learning_rate', lr, epoch)\"\"\"\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "  main()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-b4c8b09c59ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-b4c8b09c59ce>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-b4c8b09c59ce>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;31m#.cuda(async=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-e613d14164a9>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \"\"\"\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mhflip\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \"\"\"\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'img should be PIL Image. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLIP_LEFT_RIGHT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: img should be PIL Image. Got <class 'numpy.ndarray'>"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "MFH5Jm77bCR3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G0cem_j5bDlA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n9qJAeHRbDbT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b4e87749-2902-4613-d49f-fa288f45b423"
      },
      "cell_type": "code",
      "source": [
        "! npm install -g localtunnel\n",
        "get_ipython().system_raw('/usr/local/bin/python -m pip install visdom')\n",
        "get_ipython().system_raw('/usr/local/bin/python -m visdom.server -port 6006 >> visdomlog.txt 2>&1 &')\n",
        "get_ipython().system_raw('lt --port 6006 >> url.txt 2>&1 &')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/client\n",
            "+ localtunnel@1.9.0\n",
            "updated 1 package in 2.119s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Oo-NZ9H-bDTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "769d7d55-155c-4d06-b889-8fe175e06834"
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "time.sleep(5)\n",
        "! cat url.txt\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "your url is: https://black-falcon-21.localtunnel.me\r\n",
            "your url is: https://pretty-parrot-79.localtunnel.me\r\n",
            "your url is: https://fluffy-hound-97.localtunnel.me\r\n",
            "your url is: https://dull-insect-80.localtunnel.me\r\n",
            "your url is: https://swift-goat-11.localtunnel.me\r\n",
            "your url is: https://dangerous-snail-28.localtunnel.me\r\n",
            "your url is: https://great-treefrog-55.localtunnel.me\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wmfunFKmbCKk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1199
        },
        "outputId": "f5cee508-2cef-4c22-d811-430073967219"
      },
      "cell_type": "code",
      "source": [
        "import visdom\n",
        "time.sleep(5)\n",
        "vis = visdom.Visdom(port='6006')\n",
        "print(vis)\n",
        "time.sleep(3)\n",
        "! cat visdomlog.txt\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<visdom.Visdom object at 0x7f23ee3a5470>\n",
            "Downloading scripts. It might take a while.\n",
            "It's Alive!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
            "    \"__main__\", fname, loader, pkg_name)\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n",
            "    exec code in run_globals\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1159, in <module>\n",
            "    download_scripts_and_run()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1155, in download_scripts_and_run\n",
            "    main()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1150, in main\n",
            "    print_func=print_func, user_credential=user_credential)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1088, in start_server\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\n",
            "    server.listen(port, address)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\n",
            "    sockets = bind_sockets(port, address=address)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\n",
            "    sock.bind(sockaddr)\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\n",
            "    return getattr(self._sock,name)(*args)\n",
            "socket.error: [Errno 98] Address already in use\n",
            "INFO:root:Application Started\n",
            "Downloading scripts. It might take a while.\n",
            "It's Alive!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
            "    \"__main__\", fname, loader, pkg_name)\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n",
            "    exec code in run_globals\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1159, in <module>\n",
            "    download_scripts_and_run()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1155, in download_scripts_and_run\n",
            "    main()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1150, in main\n",
            "    print_func=print_func, user_credential=user_credential)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/visdom/server.py\", line 1088, in start_server\n",
            "    app.listen(port, max_buffer_size=1024 ** 3)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/web.py\", line 1944, in listen\n",
            "    server.listen(port, address)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/tcpserver.py\", line 142, in listen\n",
            "    sockets = bind_sockets(port, address=address)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/netutil.py\", line 197, in bind_sockets\n",
            "    sock.bind(sockaddr)\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\n",
            "    return getattr(self._sock,name)(*args)\n",
            "socket.error: [Errno 98] Address already in use\n",
            "INFO:tornado.access:200 POST /env/main (::1) 1.30ms\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.45ms\n",
            "INFO:root:Opened visdom socket from ip: ::1\n",
            "INFO:root:Application Started\n",
            "INFO:tornado.access:200 POST /env/main (::1) 3.08ms\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.43ms\n",
            "INFO:root:Opened visdom socket from ip: ::1\n",
            "INFO:root:Application Started\n",
            "INFO:root:Application Started\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.96ms\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.56ms\n",
            "INFO:root:Opened visdom socket from ip: ::1\n",
            "INFO:tornado.access:200 POST /env/main (::1) 0.66ms\n",
            "INFO:tornado.access:101 GET /vis_socket (::1) 0.47ms\n",
            "INFO:root:Opened visdom socket from ip: ::1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DDpfZaPWtszF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "ab04803d-89cd-46f7-c69b-6f78676c235f"
      },
      "cell_type": "code",
      "source": [
        "loss = {'Train_Acc':top1.avg,\n",
        "            'Train_Loss':losses.avg}\n",
        "vis.plot_combine('kuch bhi',loss)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-e1f048ec5afe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m loss = {'Train_Acc':top1.avg,\n\u001b[0m\u001b[1;32m      2\u001b[0m             'Train_Loss':losses.avg}\n\u001b[1;32m      3\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_combine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kuch bhi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'top1' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "pVEifCz_uRI2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = [{\n",
        "                'x':[1],\n",
        "                'y':[4],\n",
        "                \n",
        "},{\n",
        "                'x': [1],\n",
        "                'y': [4],\n",
        "                \n",
        "}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AUp4oHeSbCAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "365c42ef-8015-4ed4-aa96-d6094a6bedfa"
      },
      "cell_type": "code",
      "source": [
        "data = [{\n",
        "                'x':[1,2,3],\n",
        "                'y':[4,5,6],\n",
        "                'marker':{\n",
        "                        'color': 'red',\n",
        "                        'symbol': 104,\n",
        "                        'size': \"10\"},\n",
        "                'mode':\"markers+lines\",\n",
        "                'text':[\"one\",\"two\",\"three\"],\n",
        "                'name':'1st Trace',\n",
        "                'type':'line',\n",
        "},{\n",
        "                'x': [1,2,3],\n",
        "                'y': [4,5,6],\n",
        "                'type': 'scatter',\n",
        "                'mode': 'markers',\n",
        "}]\n",
        "\n",
        "win = 'mytestwin'\n",
        "env = 'main'\n",
        "\n",
        "layout= {\n",
        "                'title':\"Test Plot\",\n",
        "                'xaxis':{'title':'x1'},\n",
        "                'yaxis':{'title':'x2'}\n",
        "}\n",
        "opts = {}\n",
        "\n",
        "vis._send({'data': data, 'win': win, 'eid': env, 'layout': layout, 'opts': opts})\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mytestwin'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "dNCsfZFlbB5q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "98598f24-b61c-4f1b-ad19-85ad80d2a6da"
      },
      "cell_type": "code",
      "source": [
        "        import matplotlib.pyplot as plt\n",
        "        plt.plot([1, 23, 2, 4])\n",
        "        plt.title(\"yolo\")\n",
        "        plt.ylabel('some numbers')\n",
        "        vis.matplot(plt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'window_36752079cdba5a'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEHCAYAAABCwJb2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIcLI/weh5LiTxSHmZQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5e3f7bab38>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rKq5s_9lbBvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "81e2bc30-4f59-42b5-a8e1-71376beb67a3"
      },
      "cell_type": "code",
      "source": [
        "    vis.heatmap(\n",
        "        X=confusion_matrix.value(),\n",
        "        opts=dict(\n",
        "            columnnames=['a', 'b', 'c', 'd', 'e', 'f', 'g'],\n",
        "            rownames=['y1', 'y2', 'y3', 'y4', 'y5','y6','y7'],\n",
        "            colormap='Electric',\n",
        "        )\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'window_3674858fd3abf2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "7ZmEHBPnlTSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "8435bcf3-2ca4-4852-d231-0eefe45920d5"
      },
      "cell_type": "code",
      "source": [
        "print(confusion_matrix.value())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 9  0  0  9 12  0  5]\n",
            " [10  0  0 11 11  0  3]\n",
            " [ 8  0  0 11 11  1  6]\n",
            " [10  0  0 12  6  0  8]\n",
            " [12  0  0 10  6  0  7]\n",
            " [ 9  0  0 13  6  0  6]\n",
            " [18  0  0 15  8  0  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ye3plN_9bBny",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in [1,2,3,4,5,6]:\n",
        "  vis.plot(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VcsGKk3z3i9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "72794f41-044d-45b6-c21a-2680e9b97ea4"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t\t    run\t\t\t   test.csv\r\n",
            "datacombined.csv    run_logs\t\t   train\r\n",
            "ep200.h5\t    runs\t\t   train.csv\r\n",
            "model_best.pth.tar  Temporal_CNN.ipynb\t   two-stream-action-recognition-master\r\n",
            "ngrok\t\t    tensorboard_run.ipynb  url.txt\r\n",
            "output\t\t    test\t\t   visdomlog.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TQAZ5JIXGBW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1225
        },
        "outputId": "611c0a6a-d7d9-4b54-e984-7a93dd19397f"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorboard_logger import configure, log_value\n",
        "def main():\n",
        "\n",
        "    tensorboard = True\n",
        "    epochs=300\n",
        "    start_epoch=0\n",
        "    batch_size=64\n",
        "    lr=0.1\n",
        "    momentum=0.9\n",
        "    weight_decay=1e-4\n",
        "    print_freq=10\n",
        "    layers=100\n",
        "    growth=12\n",
        "    droprate = 0.0\n",
        "    reduce=0.5\n",
        "    resume=''\n",
        "    best_prec1 = 0  \n",
        "  \n",
        "    #name = 'temporal_cnn'\n",
        "    #global tensorboard,start_epoch\n",
        "    #global best_prec1,start_epoch\n",
        "    #configure(\"run_logs/%s\"%(name))\n",
        "    # create model\n",
        "    model = modelres\n",
        "\n",
        "    model = model.cuda()\n",
        "\n",
        "    # optionally resume from a checkpoint\n",
        "    if resume:\n",
        "        if os.path.isfile(resume):\n",
        "            print(\"=> loading checkpoint '{}'\".format(resume))\n",
        "            checkpoint = torch.load(resume)\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            best_prec1 = checkpoint['best_prec1']\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "                  .format(resume, checkpoint['epoch']))\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(resume))\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    # define loss function (criterion) and pptimizer\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr,\n",
        "                                )\n",
        "    \n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        adjust_learning_rate(optimizer, epoch)\n",
        "        prec1 = 0\n",
        "        # train for one epoch\n",
        "        train(train_loader, model, criterion, optimizer, epoch)\n",
        "\n",
        "        # evaluate on validation set\n",
        "        prec1 = validate(val_loader, model, criterion, epoch)\n",
        "\n",
        "        # remember best prec@1 and save checkpoint\n",
        "        #print(\"prec1:\",prec1)\n",
        "        #print(\"best_prec1:\",best_prec1)\n",
        "        is_best = prec1 > best_prec1\n",
        "        best_prec1 = max(prec1, best_prec1)\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_prec1': best_prec1,\n",
        "        }, is_best)\n",
        "    #print('Best accuracy: ', best_prec1)\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    \"\"\"Train for one epoch on the training set\"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        target = target.cuda(async=True)\n",
        "        input = input.cuda()\n",
        "        input_var = torch.autograd.Variable(input)\n",
        "        target_var = torch.autograd.Variable(target)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)\n",
        "        loss = criterion(output, target_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
        "        losses.update(loss.data[0], input.size(0))\n",
        "        top1.update(prec1[0], input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                      loss=losses, top1=top1))\n",
        "    # log to TensorBoard\n",
        "    \"\"\"if tensorboard:\n",
        "        log_value('train_loss', losses.avg, epoch)\n",
        "        log_value('train_acc', top1.avg, epoch)\"\"\"\n",
        "\n",
        "def validate(val_loader, model, criterion, epoch):\n",
        "    \"\"\"Perform validation on the validation set\"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(val_loader):\n",
        "        target = target.cuda(async=True)\n",
        "        input = input.cuda()\n",
        "        input_var = torch.autograd.Variable(input, volatile=True)\n",
        "        target_var = torch.autograd.Variable(target, volatile=True)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)\n",
        "        loss = criterion(output, target_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
        "        losses.update(loss.data[0], input.size(0))\n",
        "        top1.update(prec1[0], input.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            print('Test: [{0}/{1}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                      i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                      top1=top1))\n",
        "\n",
        "    print(' * Prec@1 {top1.avg:.3f}'.format(top1=top1))\n",
        "    # log to TensorBoard\n",
        "    \"\"\"if tensorboard:\n",
        "        log_value('val_loss', losses.avg, epoch)\n",
        "        log_value('val_acc', top1.avg, epoch)\"\"\"\n",
        "    return top1.avg\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    \"\"\"Saves checkpoint to disk\"\"\"\n",
        "    directory = \"run_logs/%s/\"%('checkpoint')\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    filename = directory + filename\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'run_logs/%s/'%('checkpoint') + 'model_best.pth.tar')\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    lr = 0.1\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 after 150 and 225 epochs\"\"\"\n",
        "    lr = lr * (0.1 ** (epoch // 150)) * (0.1 ** (epoch // 225))\n",
        "    # log to TensorBoard\n",
        "    if tensorboard:\n",
        "        log_value('learning_rate', lr, epoch)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "  main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-3960ce980505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-111-3960ce980505>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# optionally resume from a checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \"\"\"\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;31m# Variables stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \"\"\"\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qXCqs2UeGCGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d85943b0-4289-4b63-afc1-de85be5c00f3"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "xfghLNnuGB60",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uKKLeyMSGB2A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UnvghaW8GBw4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I2sS4zRFGBPY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0p7UJT30GBIJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9C2MKgmwGBBF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b-Cal60OGA6e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "um9hk1i5GA1E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T3KRJrYoGAwR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lswKAOh-GArk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3k0zayP9GAnJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cVcVpzgjGAiP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JYWgL2cVGAbl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2FAE5eLRGAWJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5raDkZtoGARB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h2bwYVcD-Xko",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os \n",
        "import shutil \n",
        "import time\n",
        "\n",
        "import torch \n",
        "from tensorboard_logger import log_value\n",
        "#model, train, valid, optimizer, criterion, epochs=1, scheduler=None\n",
        "\n",
        "def train(train_dataset, train_loader, model, criterion, optimizer, val_loader, checkpoint_directory, scheduler=None):\n",
        "    \"\"\"Train for one epoch on the training set\"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "    optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        if scheduler is not None:\n",
        "            scheduler.batch_step()\n",
        "        target = target.cuda(async=True)\n",
        "        input = input.cuda()\n",
        "        input_var = torch.autograd.Variable(input)\n",
        "        target_var = torch.autograd.Variable(target)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)\n",
        "        loss = criterion(output, target_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
        "        losses.update(loss.data[0], input.size(0))\n",
        "        top1.update(prec1[0], input.size(0))\n",
        "        samples += input.size(0)\n",
        "\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % args.print_freq == 0:\n",
        "            print('Epoch: {0:.4f}\\t'\n",
        "                  'Step: {1}/{2}\\t'\n",
        "                  'Samples: [{samples}]\\t'\n",
        "                  'LR: {lr}\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Samples/s {samples_per_sec:.0f}\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                samples / len(train_dataset), i, len(train_loader), samples=samples, batch_time=batch_time,\n",
        "                samples_per_sec=input.size(0)/batch_time.avg,\n",
        "                lr=get_learning_rate(optimizer)[0],# *iter_accum ???\n",
        "            loss=losses, top1=top1))\n",
        "\n",
        "        if i % save_steps_freq == 0:\n",
        "            if i>0:\n",
        "                # evaluate on validation set\n",
        "                prec1 = validate(val_loader, model, criterion, samples, args)\n",
        "\n",
        "                # remember best prec@1 and save checkpoint\n",
        "                print('Checkpoint')\n",
        "                is_best = prec1 > best_prec1\n",
        "                best_prec1 = max(prec1, best_prec1)\n",
        "                is_best_train = top1.avg > best_train_prec1\n",
        "                best_train_prec1 = max(top1.avg, best_train_prec1)\n",
        "                save_checkpoint({\n",
        "                    'samples': samples,\n",
        "                    'state_dict': model.state_dict(),\n",
        "                    'best_prec1': best_prec1,\n",
        "                    'best_train_prec1': best_train_prec1,\n",
        "                    'train_prec1': top1.avg,\n",
        "                }, is_best, is_best_train,\n",
        "                    directory=checkpoint_directory\n",
        "                )\n",
        "\n",
        "                # log to TensorBoard\n",
        "                log_value('train_loss', losses.avg, samples)\n",
        "                log_value('train_acc', top1.avg, samples)\n",
        "                log_value('learning_rate', get_learning_rate(optimizer)[0], samples)\n",
        "                log_value('batch_size', input.size(0), samples)\n",
        "                log_value('effective_batch_size', input.size(0)*args.accum, samples)\n",
        "                log_value('accum', args.accum, samples)\n",
        "\n",
        "            batch_time.reset()\n",
        "            losses.reset()\n",
        "            top1.reset()\n",
        "    return best_prec1, best_train_prec1, samples\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion, samples, args):\n",
        "    \"\"\"Perform validation on the validation set\"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(val_loader):\n",
        "        # print(\"input={}\", input.size())\n",
        "        target = target.cuda(async=True)\n",
        "        input = input.cuda()\n",
        "        input_var = torch.autograd.Variable(input, volatile=True)\n",
        "        target_var = torch.autograd.Variable(target, volatile=True)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)\n",
        "        # print(\"validate vars input={} target={} output={}\".format(input_var.size(), target_var.size(), output.size()))\n",
        "        loss = criterion(output, target_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
        "        losses.update(loss.data[0], input.size(0))\n",
        "        top1.update(prec1[0], input.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % args.print_freq == 0:\n",
        "            print('Test: [{0}/{1}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                top1=top1))\n",
        "\n",
        "    print(' * Prec@1 {top1.avg:.3f}'.format(top1=top1))\n",
        "\n",
        "    # log to TensorBoard\n",
        "    log_value('val_loss', losses.avg, samples)\n",
        "    log_value('val_acc', top1.avg, samples)\n",
        "\n",
        "    return top1.avg\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, is_best_train, directory, filename='checkpoint.pth.tar'):\n",
        "    \"\"\"Saves checkpoint to disk\"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    filename = directory + filename\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, directory + 'model_best.pth.tar')\n",
        "    if is_best_train:\n",
        "        shutil.copyfile(filename, directory + 'model_best_train.pth.tar')\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, lr):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 after 150 and 225 epochs\"\"\"\n",
        "    lr = lr * (0.1 ** (epoch // 150)) * (0.1 ** (epoch // 225))\n",
        "    # log to TensorBoard\n",
        "    log_value('learning_rate', lr, epoch)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yRrnfaCf-YHe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(model, train_loader, val_loader, optimizer, criterion, epochs=10) #, scheduler=scheduler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5UnwWe7Q-YCs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zw4cTEAI3RYv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, train, valid, optimizer, criterion, epochs=1, scheduler=None):\n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch ', epoch + 1, '/', epochs)\n",
        "        \n",
        "        running_loss = 0.\n",
        "        running_corrects = 0.\n",
        "        running_batches = 0.\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "            \n",
        "\n",
        "            \n",
        "        model = model.cuda()\n",
        "    \n",
        "        model.train()\n",
        "        for i, (input, target) in enumerate(train):\n",
        "            input = input.cuda()\n",
        "            target = target.cuda()\n",
        "            input_var = torch.autograd.Variable(input)\n",
        "            target_var = torch.autograd.Variable(target)#.type(torch.LongTensor).cuda()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # compute output\n",
        "            output = model(input_var)\n",
        "            #print('output : ',output)\n",
        "            #print('target:',target_var)\n",
        "            _, preds = torch.max(output.data, 1)\n",
        "            loss = criterion(output, target_var)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.data[0]\n",
        "            running_corrects += torch.sum(preds == target)\n",
        "            running_batches += 1.\n",
        "\n",
        "            print('\\r', 'Batch', i, 'Loss', loss.data[0], end='')\n",
        "            \n",
        "        train_loss = running_loss / running_batches\n",
        "        train_acc = running_corrects / len(train.dataset.labels)\n",
        "        print('\\r', \"Train Loss\", train_loss, \"Train Accuracy\", train_acc)\n",
        "            \n",
        "        running_loss = 0.\n",
        "        running_corrects = 0.\n",
        "        running_batches = 0.\n",
        "\n",
        "        model.eval()\n",
        "        for i, (input, target) in enumerate(valid):\n",
        "            input = input.cuda()\n",
        "            target = target.cuda()\n",
        "            input_var = torch.autograd.Variable(input, volatile=True)\n",
        "            target_var = torch.autograd.Variable(target, volatile=True)\n",
        "\n",
        "            output = model(input_var)\n",
        "            _, preds = torch.max(output.data, 1)\n",
        "            loss = criterion(output, target_var)\n",
        "\n",
        "            running_loss += loss.data[0]\n",
        "            running_corrects += torch.sum(preds == target)\n",
        "            running_batches += 1.\n",
        "\n",
        "        valid_loss = running_loss / running_batches\n",
        "        valid_acc = running_corrects / len(valid.dataset.labels)\n",
        "        #print()\n",
        "        print('\\r', \"Val Loss\", valid_loss, \"Val Accuracy\", valid_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y1Sgp2uI3CiB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle,os\n",
        "from PIL import Image\n",
        "import scipy.io\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from random import randint\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# other util\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint, model_best):\n",
        "    torch.save(state, checkpoint)\n",
        "    if is_best:\n",
        "        shutil.copyfile(checkpoint, model_best)\n",
        "\n",
        "def record_info(info,filename,mode):\n",
        "\n",
        "    if mode =='train':\n",
        "\n",
        "        result = (\n",
        "              'Time {batch_time} '\n",
        "              'Data {data_time} \\n'\n",
        "              'Loss {loss} '\n",
        "              'Prec@1 {top1} '\n",
        "              'Prec@5 {top5}\\n'\n",
        "              'LR {lr}\\n'.format(batch_time=info['Batch Time'],\n",
        "               data_time=info['Data Time'], loss=info['Loss'], top1=info['Prec@1'], top5=info['Prec@5'],lr=info['lr']))      \n",
        "        print(result)\n",
        "\n",
        "        df = pd.DataFrame.from_dict(info)\n",
        "        column_names = ['Epoch','Batch Time','Data Time','Loss','Prec@1','Prec@5','lr']\n",
        "        \n",
        "    if mode =='test':\n",
        "        result = (\n",
        "              'Time {batch_time} \\n'\n",
        "              'Loss {loss} '\n",
        "              'Prec@1 {top1} '\n",
        "              'Prec@5 {top5} \\n'.format( batch_time=info['Batch Time'],\n",
        "               loss=info['Loss'], top1=info['Prec@1'], top5=info['Prec@5']))      \n",
        "        print(result)\n",
        "        df = pd.DataFrame.from_dict(info)\n",
        "        column_names = ['Epoch','Batch Time','Loss','Prec@1','Prec@5']\n",
        "    \n",
        "    if not os.path.isfile(filename):\n",
        "        df.to_csv(filename,index=False,columns=column_names)\n",
        "    else: # else it exists so append without writing the header\n",
        "        df.to_csv(filename,mode = 'a',header=False,index=False,columns=column_names)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LEQVNzPm3RhS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Motion_CNN():\n",
        "    def __init__(self, nb_epochs, lr, batch_size, resume, start_epoch, train_loader, test_loader, channel):\n",
        "        self.nb_epochs=nb_epochs\n",
        "        self.lr=lr\n",
        "        self.batch_size=batch_size\n",
        "        self.resume=resume\n",
        "        self.start_epoch=start_epoch\n",
        "        #self.evaluate=evaluate\n",
        "        self.train_loader=train_loader\n",
        "        self.test_loader=test_loader\n",
        "        self.best_prec1=0\n",
        "        self.channel=channel\n",
        "        #self.test_video=test_video\n",
        "\n",
        "    def build_model(self):\n",
        "        print ('==> Build model and setup loss and optimizer')\n",
        "        #build model\n",
        "        self.model = modelres.cuda()\n",
        "        #print self.model\n",
        "        #Loss function and optimizer\n",
        "        self.criterion = nn.CrossEntropyLoss().cuda()\n",
        "        self.optimizer = torch.optim.SGD(self.model.parameters(), self.lr, momentum=0.9)\n",
        "        self.scheduler = ReduceLROnPlateau(self.optimizer, 'min', patience=1,verbose=True)\n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "    def resume_and_evaluate(self):\n",
        "        if self.resume:\n",
        "            if os.path.isfile(self.resume):\n",
        "                print(\"==> loading checkpoint '{}'\".format(self.resume))\n",
        "                checkpoint = torch.load(self.resume)\n",
        "                self.start_epoch = checkpoint['epoch']\n",
        "                self.best_prec1 = checkpoint['best_prec1']\n",
        "                self.model.load_state_dict(checkpoint['state_dict'])\n",
        "                self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "                print(\"==> loaded checkpoint '{}' (epoch {}) (best_prec1 {})\"\n",
        "                  .format(self.resume, checkpoint['epoch'], self.best_prec1))\n",
        "            else:\n",
        "                print(\"==> no checkpoint found at '{}'\".format(self.resume))\n",
        "\n",
        "    \n",
        "    def run(self):\n",
        "        self.build_model()\n",
        "        self.resume_and_evaluate()\n",
        "        cudnn.benchmark = True\n",
        "        \n",
        "        for self.epoch in range(self.start_epoch, self.nb_epochs):\n",
        "            self.train_1epoch()\n",
        "            prec1, val_loss = self.validate_1epoch()\n",
        "            is_best = prec1 > self.best_prec1\n",
        "            #lr_scheduler\n",
        "            self.scheduler.step(val_loss)\n",
        "            # save model\n",
        "            if is_best:\n",
        "                self.best_prec1 = prec1\n",
        "                with open('motion_video_preds.pickle','wb') as f:\n",
        "                    pickle.dump(self.dic_video_level_preds,f)\n",
        "                f.close() \n",
        "            \n",
        "            save_checkpoint({\n",
        "                'epoch': self.epoch,\n",
        "                'state_dict': self.model.state_dict(),\n",
        "                'best_prec1': self.best_prec1,\n",
        "                'optimizer' : self.optimizer.state_dict()\n",
        "            },is_best,'checkpoint.pth.tar','model_best.pth.tar')\n",
        "\n",
        "    def train_1epoch(self):\n",
        "        print('==> Epoch:[{0}/{1}][training stage]'.format(self.epoch, self.nb_epochs))\n",
        "\n",
        "        batch_time = AverageMeter()\n",
        "        data_time = AverageMeter()\n",
        "        losses = AverageMeter()\n",
        "        top1 = AverageMeter()\n",
        "        top5 = AverageMeter()\n",
        "        #switch to train mode\n",
        "        self.model.train()    \n",
        "        end = time.time()\n",
        "        # mini-batch training\n",
        "        progress = tqdm(self.train_loader)\n",
        "        for i, (data,label) in enumerate(progress):\n",
        "\n",
        "            # measure data loading time\n",
        "            data_time.update(time.time() - end)\n",
        "            \n",
        "            label = label.cuda(async=True)\n",
        "            input_var = Variable(data).cuda()\n",
        "            target_var = Variable(label).cuda()\n",
        "\n",
        "            # compute output\n",
        "            output = self.model(input_var)\n",
        "            loss = self.criterion(output, target_var)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            prec1, prec5 = accuracy(output.data, label, topk=(1, 5))\n",
        "            losses.update(loss.data[0], data.size(0))\n",
        "            top1.update(prec1[0], data.size(0))\n",
        "            top5.update(prec5[0], data.size(0))\n",
        "\n",
        "            # compute gradient and do SGD step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "        \n",
        "        info = {'Epoch':[self.epoch],\n",
        "                'Batch Time':[round(batch_time.avg,3)],\n",
        "                'Data Time':[round(data_time.avg,3)],\n",
        "                'Loss':[round(losses.avg,5)],\n",
        "                'Prec@1':[round(top1.avg,4)],\n",
        "                'Prec@5':[round(top5.avg,4)],\n",
        "                'lr': self.optimizer.param_groups[0]['lr']\n",
        "                }\n",
        "        record_info(info, 'opf_train.csv','train')\n",
        "\n",
        "    def validate_1epoch(self):\n",
        "        print('==> Epoch:[{0}/{1}][validation stage]'.format(self.epoch, self.nb_epochs))\n",
        "\n",
        "        batch_time = AverageMeter()\n",
        "        losses = AverageMeter()\n",
        "        top1 = AverageMeter()\n",
        "        top5 = AverageMeter()\n",
        "        # switch to evaluate mode\n",
        "        self.model.eval()\n",
        "        self.dic_video_level_preds={}\n",
        "        end = time.time()\n",
        "        progress = tqdm(self.test_loader)\n",
        "        for i, (keys,data,label) in enumerate(progress):\n",
        "            \n",
        "            #data = data.sub_(127.353346189).div_(14.971742063)\n",
        "            label = label.cuda(async=True)\n",
        "            data_var = Variable(data, volatile=True).cuda(async=True)\n",
        "            label_var = Variable(label, volatile=True).cuda(async=True)\n",
        "\n",
        "            # compute output\n",
        "            output = self.model(data_var)\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "            #Calculate video level prediction\n",
        "            preds = output.data.cpu().numpy()\n",
        "            nb_data = preds.shape[0]\n",
        "            for j in range(nb_data):\n",
        "                videoName = keys[j] # ApplyMakeup_g01_c01\n",
        "                if videoName not in self.dic_video_level_preds.keys():\n",
        "                    self.dic_video_level_preds[videoName] = preds[j,:]\n",
        "                else:\n",
        "                    self.dic_video_level_preds[videoName] += preds[j,:]\n",
        "                    \n",
        "        #Frame to video level accuracy\n",
        "        video_top1, video_top5, video_loss = self.frame2_video_level_accuracy()\n",
        "        info = {'Epoch':[self.epoch],\n",
        "                'Batch Time':[round(batch_time.avg,3)],\n",
        "                'Loss':[round(video_loss,5)],\n",
        "                'Prec@1':[round(video_top1,3)],\n",
        "                'Prec@5':[round(video_top5,3)]\n",
        "                }\n",
        "        record_info(info, 'opf_test.csv','test')\n",
        "        return video_top1, video_loss\n",
        "\n",
        "    def frame2_video_level_accuracy(self):\n",
        "     \n",
        "        correct = 0\n",
        "        video_level_preds = np.zeros((len(self.dic_video_level_preds),101))\n",
        "        video_level_labels = np.zeros(len(self.dic_video_level_preds))\n",
        "        ii=0\n",
        "        for key in sorted(self.dic_video_level_preds.keys()):\n",
        "            name = key\n",
        "\n",
        "            preds = self.dic_video_level_preds[name]\n",
        "            label = int(self.test_video[name])-1\n",
        "                \n",
        "            video_level_preds[ii,:] = preds\n",
        "            video_level_labels[ii] = label\n",
        "            ii+=1         \n",
        "            if np.argmax(preds) == (label):\n",
        "                correct+=1\n",
        "\n",
        "        #top1 top5\n",
        "        video_level_labels = torch.from_numpy(video_level_labels).long()\n",
        "        video_level_preds = torch.from_numpy(video_level_preds).float()\n",
        "\n",
        "        loss = self.criterion(Variable(video_level_preds).cuda(), Variable(video_level_labels).cuda())    \n",
        "        top1,top5 = accuracy(video_level_preds, video_level_labels, topk=(1,5))     \n",
        "                            \n",
        "        top1 = float(top1.numpy())\n",
        "        top5 = float(top5.numpy())\n",
        "            \n",
        "        return top1,top5,loss.data.cpu().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nrCL5Plw3RdN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1285
        },
        "outputId": "99364e83-45ac-448c-b03f-bf0daf142e06"
      },
      "cell_type": "code",
      "source": [
        "    model = Motion_CNN(\n",
        "                        # Data Loader\n",
        "                        train_loader=train_loader,\n",
        "                        test_loader=val_loader,\n",
        "                        # Utility\n",
        "                        start_epoch=start_epoch,\n",
        "                        resume=resume,\n",
        "                        #evaluate=arg.evaluate,\n",
        "                        # Hyper-parameter\n",
        "                        nb_epochs=epochs,\n",
        "                        lr=lr,\n",
        "                        batch_size=batch_size,\n",
        "                        channel = 10*2,\n",
        "                        #test_video=test_video\n",
        "                        )\n",
        "    #Training\n",
        "    model.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Build model and setup loss and optimizer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-2bf094540579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                     )\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-801ed6a411a8>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-801ed6a411a8>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'==> Build model and setup loss and optimizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#build model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m#print self.model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#Loss function and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \"\"\"\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;31m# Variables stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \"\"\"\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "vHttek5s3RTU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W_y4bc8W3Can",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JI-kGHPf3CVw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HdwJb6MX3COm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GBYr0s2c3CIO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RXzdhR3X3CDh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KXTI6eA83B-Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lpEy24vb3B5h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jyTXSU8p3B0v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wz-EyaN-3Bv8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KK2f3phK3BqU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r09Krxdfu4cv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4bf56ddb-a329-410a-c05d-d364fdefff88"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1 / 10\n",
            " Train Loss 2.168302968144417 Train Accuracy 0.2047244094488189\n",
            " Val Loss 101.63469123840332 Val Accuracy 0.20909090909090908\n",
            "Epoch  2 / 10\n",
            " Batch 3 Loss 2.1980788707733154"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tk2dufB79g-u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IpZXnYBVu4Ys",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = activityDataset('data', train_labels, transform)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size//2,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    activityDataset('data', valid_labels, transform),\n",
        "    batch_size=batch_size//2,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LjqrjQHbu4Oi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fm2x_71vu4Jl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KpLysXNjhdgG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "train = pd.read_csv(\"train.csv\",index_col = 0)\n",
        "test =  pd.read_csv(\"test.csv\",index_col=0)\n",
        "#print (train.shape)\n",
        "#print (test.shape)\n",
        "train.reset_index()\n",
        "test.reset_index()\n",
        "train.index = range(train.shape[0])\n",
        "test.index = range(test.shape[0])\n",
        "\n",
        "#print(train.shape[0])   \n",
        "target = train['label']\n",
        "features = train.drop('label',axis=1)\n",
        "X_data = features['id']\n",
        "y_data = target\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qyfzw8EutvWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        },
        "outputId": "7b8cdbd3-7871-41e6-fbde-ae3a194ca5b6"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sit - stand up_Man4_002.npy</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hand-wave_Woman1_005.npy</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sit - stand up_Man6_002.npy</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jump-in-place_Woman2_001.npy</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bend_Man4_006.npy</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Hand-wave_Man1_005.npy</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Jump-in-place_Man2_003.npy</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Pull_Man6_001.npy</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Walk_Woman1_004.npy</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Hand-wave_Man6_007.npy</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Sit - stand up_Man1_001.npy</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Run_Man1_003.npy</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Pull_Man6_004.npy</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Jump-in-place_Man3_003.npy</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Walk_Man2_007.npy</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Hand-wave_Man3_000.npy</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Pull_Man4_002.npy</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Hand-wave_Man4_003.npy</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Walk_Man2_003.npy</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Hand-wave_Man1_004.npy</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Hand-wave_Man1_000.npy</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Sit - stand up_Man1_003.npy</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Bend_Man3_004.npy</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Walk_Man2_006.npy</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Pull_Woman2_002.npy</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Run_Man6_001.npy</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Pull_Man3_001.npy</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Walk_Man6_002.npy</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Run_Man2_007.npy</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Sit - stand up_Man4_005.npy</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>Bend_Man6_007.npy</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>Pull_Man3_000.npy</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>336</th>\n",
              "      <td>Sit - stand up_Man6_005.npy</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>Sit - stand up_Man5_002.npy</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>Run_Man5_001.npy</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>Jump-in-place_Man1_007.npy</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>Walk_Man5_005.npy</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>Bend_Man1_005.npy</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>Pull_Man4_003.npy</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>Hand-wave_Man2_005.npy</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>Run_Man2_006.npy</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>Walk_Man3_006.npy</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>Sit - stand up_Woman1_003.npy</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>Jump-in-place_Man3_007.npy</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>Pull_Man4_001.npy</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>Hand-wave_Man6_003.npy</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>Walk_Woman1_001.npy</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>Bend_Woman2_000.npy</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>Run_Man6_002.npy</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>Jump-in-place_Man1_000.npy</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>Sit - stand up_Man5_007.npy</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>Hand-wave_Man4_002.npy</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>Run_Man3_000.npy</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>Bend_Man3_002.npy</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>Jump-in-place_Woman2_006.npy</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>Pull_Man2_005.npy</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>Sit - stand up_Man3_001.npy</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>Hand-wave_Man4_007.npy</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>Pull_Man5_005.npy</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>Walk_Woman1_007.npy</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>364 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                id  label\n",
              "0      Sit - stand up_Man4_002.npy    5.0\n",
              "1         Hand-wave_Woman1_005.npy    1.0\n",
              "2      Sit - stand up_Man6_002.npy    5.0\n",
              "3     Jump-in-place_Woman2_001.npy    2.0\n",
              "4                Bend_Man4_006.npy    0.0\n",
              "5           Hand-wave_Man1_005.npy    1.0\n",
              "6       Jump-in-place_Man2_003.npy    2.0\n",
              "7                Pull_Man6_001.npy    3.0\n",
              "8              Walk_Woman1_004.npy    6.0\n",
              "9           Hand-wave_Man6_007.npy    1.0\n",
              "10     Sit - stand up_Man1_001.npy    5.0\n",
              "11                Run_Man1_003.npy    4.0\n",
              "12               Pull_Man6_004.npy    3.0\n",
              "13      Jump-in-place_Man3_003.npy    2.0\n",
              "14               Walk_Man2_007.npy    6.0\n",
              "15          Hand-wave_Man3_000.npy    1.0\n",
              "16               Pull_Man4_002.npy    3.0\n",
              "17          Hand-wave_Man4_003.npy    1.0\n",
              "18               Walk_Man2_003.npy    6.0\n",
              "19          Hand-wave_Man1_004.npy    1.0\n",
              "20          Hand-wave_Man1_000.npy    1.0\n",
              "21     Sit - stand up_Man1_003.npy    5.0\n",
              "22               Bend_Man3_004.npy    0.0\n",
              "23               Walk_Man2_006.npy    6.0\n",
              "24             Pull_Woman2_002.npy    3.0\n",
              "25                Run_Man6_001.npy    4.0\n",
              "26               Pull_Man3_001.npy    3.0\n",
              "27               Walk_Man6_002.npy    6.0\n",
              "28                Run_Man2_007.npy    4.0\n",
              "29     Sit - stand up_Man4_005.npy    5.0\n",
              "..                             ...    ...\n",
              "334              Bend_Man6_007.npy    0.0\n",
              "335              Pull_Man3_000.npy    3.0\n",
              "336    Sit - stand up_Man6_005.npy    5.0\n",
              "337    Sit - stand up_Man5_002.npy    5.0\n",
              "338               Run_Man5_001.npy    4.0\n",
              "339     Jump-in-place_Man1_007.npy    2.0\n",
              "340              Walk_Man5_005.npy    6.0\n",
              "341              Bend_Man1_005.npy    0.0\n",
              "342              Pull_Man4_003.npy    3.0\n",
              "343         Hand-wave_Man2_005.npy    1.0\n",
              "344               Run_Man2_006.npy    4.0\n",
              "345              Walk_Man3_006.npy    6.0\n",
              "346  Sit - stand up_Woman1_003.npy    5.0\n",
              "347     Jump-in-place_Man3_007.npy    2.0\n",
              "348              Pull_Man4_001.npy    3.0\n",
              "349         Hand-wave_Man6_003.npy    1.0\n",
              "350            Walk_Woman1_001.npy    6.0\n",
              "351            Bend_Woman2_000.npy    0.0\n",
              "352               Run_Man6_002.npy    4.0\n",
              "353     Jump-in-place_Man1_000.npy    2.0\n",
              "354    Sit - stand up_Man5_007.npy    5.0\n",
              "355         Hand-wave_Man4_002.npy    1.0\n",
              "356               Run_Man3_000.npy    4.0\n",
              "357              Bend_Man3_002.npy    0.0\n",
              "358   Jump-in-place_Woman2_006.npy    2.0\n",
              "359              Pull_Man2_005.npy    3.0\n",
              "360    Sit - stand up_Man3_001.npy    5.0\n",
              "361         Hand-wave_Man4_007.npy    1.0\n",
              "362              Pull_Man5_005.npy    3.0\n",
              "363            Walk_Woman1_007.npy    6.0\n",
              "\n",
              "[364 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "hRGsQmKahddo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dim = (216,216)\n",
        "batch_size = X_data.shape[0]\n",
        "n_classes = 7\n",
        "n_channels = 20\n",
        "shuffle = True\n",
        "    \n",
        "def data_generation(list_IDs_temp,labels):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((batch_size, *dim, n_channels))\n",
        "        y = np.empty((batch_size), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            #print(i,ID)\n",
        "            # Store sample\n",
        "            X[i,] = np.load('data/' + ID )\n",
        "\n",
        "            # Store class\n",
        "            y[i] = labels[i]\n",
        "\n",
        "        return X , keras.utils.to_categorical(y, num_classes=n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lZEYEHRuhdab",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Datasets\n",
        "partition = X_data\n",
        "labels =  y_data\n",
        "#keras.utils.to_categorical(y, num_classes=n_classes)\n",
        "# Generators\n",
        "xData,yData = data_generation(partition,labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cbnKiQmchdVw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d7878b23-a6b4-4a84-e965-7dc32e4c03bd"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cross_validation import train_test_split\n",
        "random_seed = 2\n",
        "trainData, testData = train_test_split(xData, test_size=0.2,random_state=random_seed)\n",
        "trainLabels, testLabels = train_test_split(labels, test_size=0.2,random_state=random_seed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kq65l_JDHXrl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "images_batch = torch.from_numpy(trainData).float()\n",
        "#images_batch = torch.from_numpy(numpy.array(trainData))\n",
        "#images_batch = torch.stack([torch.Tensor(i) for i in trainData])\n",
        "labels_batch = torch.from_numpy(numpy.array(trainLabels))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B3TjlOrAJmCi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "images_batch_val = torch.from_numpy(testData).float()\n",
        "#images_batch_val = torch.from_numpy(numpy.array(testData))\n",
        "#images_batch_val = torch.stack([torch.Tensor(i) for i in testData])\n",
        "labels_batch_val = torch.from_numpy(numpy.array(testLabels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VCvCmNT2suH3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "7fd50b2d-8d24-43b3-df56-3c7f087fc0d8"
      },
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7ff06faf56a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "bAkCeKvpJSzK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = images_batch,trainLabels\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "val_dataset = images_batch_val , testLabels\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "434T32iAM3gC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "US4WfaxsXlvA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "outputId": "c2002a33-317d-4aa5-a32d-2c3a54ce668c"
      },
      "cell_type": "code",
      "source": [
        "loader = iter(train_loader)\n",
        "next(loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-efd722f95de1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-b798576e6bae>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#print(item['id'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m#print(image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0m_ZIP_PREFIX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb'PK\\x03\\x04'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAGIC_PREFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mmagic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;31m# If the file size is less than N, we need to make sure not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;31m# to seek past the beginning of the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Qklftlp7F6WX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aXpsS8RWP7NB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        },
        "outputId": "77f43219-9581-483c-b57d-5cde7d05e2dd"
      },
      "cell_type": "code",
      "source": [
        "train(model, train_loader, val_loader, optimizer, criterion, epochs=5) #, scheduler=scheduler)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-8167fe3d97ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, scheduler=scheduler)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-2ff9a4dfefd3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train, valid, optimizer, criterion, epochs, scheduler)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-59a0b3738898>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_custom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 277\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 torch.backends.cudnn.deterministic, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (CUDALongTensor) and weight type (CUDAFloatTensor) should be the same"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "G7jwzCsT2Ice",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, train, valid, optimizer, criterion, epochs=1, scheduler=None):\n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch ', epoch + 1, '/', epochs)\n",
        "        \n",
        "        running_loss = 0.\n",
        "        running_corrects = 0.\n",
        "        running_batches = 0.\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "            \n",
        "        model.train()\n",
        "        for i, (input, target) in enumerate(train):\n",
        "            input = input.cuda()\n",
        "            target = target.cuda()\n",
        "            input_var = torch.autograd.Variable(input)\n",
        "            target_var = torch.autograd.Variable(target)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # compute output\n",
        "            output = model(input_var)\n",
        "            _, preds = torch.max(output.data, 1)\n",
        "            loss = criterion(output, target_var)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.data[0]\n",
        "            running_corrects += torch.sum(preds == target)\n",
        "            running_batches += 1.\n",
        "\n",
        "            print('\\r', 'Batch', i, 'Loss', loss.data[0], end='')\n",
        "            \n",
        "        train_loss = running_loss / running_batches\n",
        "        train_acc = running_corrects / len(train.dataset.labels)\n",
        "        print('\\r', \"Train Loss\", train_loss, \"Train Accuracy\", train_acc)\n",
        "            \n",
        "        running_loss = 0.\n",
        "        running_corrects = 0.\n",
        "        running_batches = 0.\n",
        "\n",
        "        model.eval()\n",
        "        for i, (input, target) in enumerate(valid):\n",
        "            input = input.cuda()\n",
        "            target = target.cuda()\n",
        "            input_var = torch.autograd.Variable(input, volatile=True)\n",
        "            target_var = torch.autograd.Variable(target, volatile=True)\n",
        "\n",
        "            output = model(input_var)\n",
        "            _, preds = torch.max(output.data, 1)\n",
        "            loss = criterion(output, target_var)\n",
        "\n",
        "            running_loss += loss.data[0]\n",
        "            running_corrects += torch.sum(preds == target)\n",
        "            running_batches += 1.\n",
        "\n",
        "        valid_loss = running_loss / running_batches\n",
        "        valid_acc = running_corrects / len(valid.dataset.labels)\n",
        "        #print()\n",
        "        print('\\r', \"Val Loss\", valid_loss, \"Val Accuracy\", valid_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CdfhcVyb2cHg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vMW9_cJP2EKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "0f646ac8-6bdb-4e42-8c06-5ac351a0962a"
      },
      "cell_type": "code",
      "source": [
        "#model = models.resnet34(pretrained= True, channel=10*2).cuda()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "model = model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = torch.optim.Adam(model.classifier.parameters()) #torch.optim.SGD(model.classifier.parameters(), lr=0.001, momentum=0.9)\n",
        "#scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-b1cf60a1a469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnum_ftrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 366\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ResNet' object has no attribute 'classifier'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "TxqKx1h-2EGz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(model, train_loader, val_loader, optimizer, criterion, epochs=5) #, scheduler=scheduler)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lm7y3Uz32ECY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HieoF4-hqXlN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "outputId": "4d73e1e2-ad87-46c9-8a43-28d2f9563c65"
      },
      "cell_type": "code",
      "source": [
        "loader = iter(train_loader)\n",
        "next(loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-efd722f95de1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(sequence, dim, out)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3614\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'unsqueeze'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "tDCcNL17PdDc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZJD4cTbEawnQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle,os\n",
        "from PIL import Image\n",
        "import scipy.io\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from random import randint\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# other util\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint, model_best):\n",
        "    torch.save(state, checkpoint)\n",
        "    if is_best:\n",
        "        shutil.copyfile(checkpoint, model_best)\n",
        "\n",
        "def record_info(info,filename,mode):\n",
        "\n",
        "    if mode =='train':\n",
        "\n",
        "        result = (\n",
        "              'Time {batch_time} '\n",
        "              'Data {data_time} \\n'\n",
        "              'Loss {loss} '\n",
        "              'Prec@1 {top1} '\n",
        "              'Prec@5 {top5}\\n'\n",
        "              'LR {lr}\\n'.format(batch_time=info['Batch Time'],\n",
        "               data_time=info['Data Time'], loss=info['Loss'], top1=info['Prec@1'], top5=info['Prec@5'],lr=info['lr']))      \n",
        "        print(result)\n",
        "\n",
        "        df = pd.DataFrame.from_dict(info)\n",
        "        column_names = ['Epoch','Batch Time','Data Time','Loss','Prec@1','Prec@5','lr']\n",
        "        \n",
        "    if mode =='test':\n",
        "        result = (\n",
        "              'Time {batch_time} \\n'\n",
        "              'Loss {loss} '\n",
        "              'Prec@1 {top1} '\n",
        "              'Prec@5 {top5} \\n'.format( batch_time=info['Batch Time'],\n",
        "               loss=info['Loss'], top1=info['Prec@1'], top5=info['Prec@5']))      \n",
        "        print(result)\n",
        "        df = pd.DataFrame.from_dict(info)\n",
        "        column_names = ['Epoch','Batch Time','Loss','Prec@1','Prec@5']\n",
        "    \n",
        "    if not os.path.isfile(filename):\n",
        "        df.to_csv(filename,index=False,columns=column_names)\n",
        "    else: # else it exists so append without writing the header\n",
        "        df.to_csv(filename,mode = 'a',header=False,index=False,columns=column_names)   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wf5ieEl6w1yh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Motion_CNN():\n",
        "    def __init__(self, nb_epochs, lr, batch_size, resume, start_epoch, train_loader, test_loader, channel):\n",
        "        self.nb_epochs=nb_epochs\n",
        "        self.lr=lr\n",
        "        self.batch_size=batch_size\n",
        "        self.resume=resume\n",
        "        self.start_epoch=start_epoch\n",
        "        #self.evaluate=evaluate\n",
        "        self.train_loader=train_loader\n",
        "        self.test_loader=test_loader\n",
        "        self.best_prec1=0\n",
        "        self.channel=channel\n",
        "        #self.test_video=test_video\n",
        "\n",
        "    def build_model(self):\n",
        "        print ('==> Build model and setup loss and optimizer')\n",
        "        #build model\n",
        "        self.model = resnet34(pretrained= True, channel=self.channel).cuda()\n",
        "        #print self.model\n",
        "        #Loss function and optimizer\n",
        "        self.criterion = nn.CrossEntropyLoss().cuda()\n",
        "        self.optimizer = torch.optim.SGD(self.model.parameters(), self.lr, momentum=0.9)\n",
        "        self.scheduler = ReduceLROnPlateau(self.optimizer, 'min', patience=1,verbose=True)\n",
        "    '''def resume_and_evaluate(self):\n",
        "        if self.resume:\n",
        "            if os.path.isfile(self.resume):\n",
        "                print(\"==> loading checkpoint '{}'\".format(self.resume))\n",
        "                checkpoint = torch.load(self.resume)\n",
        "                self.start_epoch = checkpoint['epoch']\n",
        "                self.best_prec1 = checkpoint['best_prec1']\n",
        "                self.model.load_state_dict(checkpoint['state_dict'])\n",
        "                self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "                print(\"==> loaded checkpoint '{}' (epoch {}) (best_prec1 {})\"\n",
        "                  .format(self.resume, checkpoint['epoch'], self.best_prec1))\n",
        "            else:\n",
        "                print(\"==> no checkpoint found at '{}'\".format(self.resume))\n",
        "        \"\"\"if self.evaluate:\n",
        "            self.epoch=0\n",
        "            prec1, val_loss = self.validate_1epoch()\n",
        "            return\"\"\"'''\n",
        "          \n",
        "    def run(self):\n",
        "        self.build_model()\n",
        "        #self.resume_and_evaluate()\n",
        "        cudnn.benchmark = True\n",
        "        \n",
        "        for self.epoch in range(self.start_epoch, self.nb_epochs):\n",
        "            self.train_1epoch()\n",
        "            prec1, val_loss = self.validate_1epoch()\n",
        "            is_best = prec1 > self.best_prec1\n",
        "            #lr_scheduler\n",
        "            self.scheduler.step(val_loss)\n",
        "            # save model\n",
        "            if is_best:\n",
        "                self.best_prec1 = prec1\n",
        "                with open('best_weight.pickle','wb') as f:\n",
        "                    pickle.dump(self.dic_video_level_preds,f)\n",
        "                f.close() \n",
        "            \n",
        "            save_checkpoint({\n",
        "                'epoch': self.epoch,\n",
        "                'state_dict': self.model.state_dict(),\n",
        "                'best_prec1': self.best_prec1,\n",
        "                'optimizer' : self.optimizer.state_dict()\n",
        "            },is_best,'checkpoint.pth.tar','model_best.pth.tar')\n",
        "\n",
        "    def train_1epoch(self):\n",
        "        print('==> Epoch:[{0}/{1}][training stage]'.format(self.epoch, self.nb_epochs))\n",
        "\n",
        "        batch_time = AverageMeter()\n",
        "        data_time = AverageMeter()\n",
        "        losses = AverageMeter()\n",
        "        top1 = AverageMeter()\n",
        "        top5 = AverageMeter()\n",
        "        #switch to train mode\n",
        "        self.model.train()    \n",
        "        end = time.time()\n",
        "        # mini-batch training\n",
        "        progress = tqdm(self.train_loader)\n",
        "        print(progress)\n",
        "        for i, (data,label) in enumerate(progress):\n",
        "\n",
        "            # measure data loading time\n",
        "            data_time.update(time.time() - end)\n",
        "            \n",
        "            label = label.cuda(async=True)\n",
        "            input_var = Variable(data).cuda()\n",
        "            target_var = Variable(label).cuda()\n",
        "\n",
        "            # compute output\n",
        "            output = self.model(input_var)\n",
        "            loss = self.criterion(output, target_var)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            prec1, prec5 = accuracy(output.data, label, topk=(1, 5))\n",
        "            losses.update(loss.data[0], data.size(0))\n",
        "            top1.update(prec1[0], data.size(0))\n",
        "            top5.update(prec5[0], data.size(0))\n",
        "\n",
        "            # compute gradient and do SGD step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "        \n",
        "        info = {'Epoch':[self.epoch],\n",
        "                'Batch Time':[round(batch_time.avg,3)],\n",
        "                'Data Time':[round(data_time.avg,3)],\n",
        "                'Loss':[round(losses.avg,5)],\n",
        "                'Prec@1':[round(top1.avg,4)],\n",
        "                'Prec@5':[round(top5.avg,4)],\n",
        "                'lr': self.optimizer.param_groups[0]['lr']\n",
        "                }\n",
        "        record_info(info, 'opf_train.csv','train')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ImSXFXPMeMy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "outputId": "82581b4c-6833-4d33-b9fd-f0d110b66107"
      },
      "cell_type": "code",
      "source": [
        "    model = Motion_CNN(\n",
        "                        # Data Loader\n",
        "                        train_loader=train_loader,\n",
        "                        test_loader=val_loader,\n",
        "                        # Utility\n",
        "                        start_epoch=start_epoch,\n",
        "                        resume=resume,\n",
        "                        #evaluate=evaluate,\n",
        "                        # Hyper-parameter\n",
        "                        nb_epochs=epochs,\n",
        "                        lr=lr,\n",
        "                        batch_size=batch_size,\n",
        "                        channel = 10*2,\n",
        "                        #test_video=test_video\n",
        "                        )\n",
        "    #Training\n",
        "    model.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Build model and setup loss and optimizer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==> Epoch:[0/500][training stage]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-bd6dd84c4e67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                     )\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-cad723abea39>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_1epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mprec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_1epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mis_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprec1\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_prec1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-cad723abea39>\u001b[0m in \u001b[0;36mtrain_1epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m# measure data loading time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    928\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(sequence, dim, out)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor sizes at /pytorch/torch/lib/TH/generic/THTensorMath.c:2864"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ueRv2XSMZjmO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b53e9e30-0ff3-486b-95cb-904c9996b13c"
      },
      "cell_type": "code",
      "source": [
        "print(train_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7fadd3117358>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D-C60MV4RTY1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self, i=1, precision=3):\n",
        "        self.meters = i\n",
        "        self.precision = precision\n",
        "        self.reset(self.meters)\n",
        "\n",
        "    def reset(self, i):\n",
        "        self.val = [0]*i\n",
        "        self.avg = [0]*i\n",
        "        self.sum = [0]*i\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        if not isinstance(val, list):\n",
        "            val = [val]\n",
        "        assert(len(val) == self.meters)\n",
        "        self.count += n\n",
        "        for i,v in enumerate(val):\n",
        "            self.val[i] = v\n",
        "            self.sum[i] += v * n\n",
        "            self.avg[i] = self.sum[i] / self.count\n",
        "\n",
        "    def __repr__(self):\n",
        "        val = ' '.join(['{:.{}f}'.format(v, self.precision) for v in self.val])\n",
        "        avg = ' '.join(['{:.{}f}'.format(a, self.precision) for a in self.avg])\n",
        "        return '{} ({})'.format(val, avg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "axN29v-ehdQF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "    def validate_1epoch(self):\n",
        "        print('==> Epoch:[{0}/{1}][validation stage]'.format(self.epoch, self.nb_epochs))\n",
        "\n",
        "        batch_time = AverageMeter()\n",
        "        losses = AverageMeter()\n",
        "        top1 = AverageMeter()\n",
        "        top5 = AverageMeter()\n",
        "        # switch to evaluate mode\n",
        "        self.model.eval()\n",
        "        self.dic_video_level_preds={}\n",
        "        end = time.time()\n",
        "        progress = tqdm(self.test_loader)\n",
        "        for i, (keys,data,label) in enumerate(progress):\n",
        "            \n",
        "            #data = data.sub_(127.353346189).div_(14.971742063)\n",
        "            label = label.cuda(async=True)\n",
        "            data_var = Variable(data, volatile=True).cuda(async=True)\n",
        "            label_var = Variable(label, volatile=True).cuda(async=True)\n",
        "\n",
        "            # compute output\n",
        "            output = self.model(data_var)\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "            #Calculate video level prediction\n",
        "            preds = output.data.cpu().numpy()\n",
        "            nb_data = preds.shape[0]\n",
        "            for j in range(nb_data):\n",
        "                videoName = keys[j].split('-',1)[0] # ApplyMakeup_g01_c01\n",
        "                if videoName not in self.dic_video_level_preds.keys():\n",
        "                    self.dic_video_level_preds[videoName] = preds[j,:]\n",
        "                else:\n",
        "                    self.dic_video_level_preds[videoName] += preds[j,:]\n",
        "                    \n",
        "        #Frame to video level accuracy\n",
        "        video_top1, video_top5, video_loss = self.frame2_video_level_accuracy()\n",
        "        info = {'Epoch':[self.epoch],\n",
        "                'Batch Time':[round(batch_time.avg,3)],\n",
        "                'Loss':[round(video_loss,5)],\n",
        "                'Prec@1':[round(video_top1,3)],\n",
        "                'Prec@5':[round(video_top5,3)]\n",
        "                }\n",
        "        record_info(info, 'opf_test.csv','test')\n",
        "        return video_top1, video_loss\n",
        "\n",
        "    def frame2_video_level_accuracy(self):\n",
        "     \n",
        "        correct = 0\n",
        "        video_level_preds = np.zeros((len(self.dic_video_level_preds),101))\n",
        "        video_level_labels = np.zeros(len(self.dic_video_level_preds))\n",
        "        ii=0\n",
        "        for key in sorted(self.dic_video_level_preds.keys()):\n",
        "            name = key.split('-',1)[0]\n",
        "\n",
        "            preds = self.dic_video_level_preds[name]\n",
        "            label = int(self.test_video[name])-1\n",
        "                \n",
        "            video_level_preds[ii,:] = preds\n",
        "            video_level_labels[ii] = label\n",
        "            ii+=1         \n",
        "            if np.argmax(preds) == (label):\n",
        "                correct+=1\n",
        "\n",
        "        #top1 top5\n",
        "        video_level_labels = torch.from_numpy(video_level_labels).long()\n",
        "        video_level_preds = torch.from_numpy(video_level_preds).float()\n",
        "\n",
        "        loss = self.criterion(Variable(video_level_preds).cuda(), Variable(video_level_labels).cuda())    \n",
        "        top1,top5 = accuracy(video_level_preds, video_level_labels, topk=(1,5))     \n",
        "                            \n",
        "        top1 = float(top1.numpy())\n",
        "        top5 = float(top5.numpy())\n",
        "            \n",
        "        return top1,top5,loss.data.cpu().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBR1w9g0hdMh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LzehzjNjhdJi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RkeA95SzhdGD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aOl4BVCZhdC4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "axAQcpiBhc_7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kxhcq-bBhc82",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "svHKKl3hhc51",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IQ_yCxBDhc2v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FH2shZM9DQTK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "00d95b23-6118-4823-f1a2-a12a4115a8d1"
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/wookayin/tensorflow-plot.git@master"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/wookayin/tensorflow-plot.git@master\r\n",
            "  Cloning https://github.com/wookayin/tensorflow-plot.git (to revision master) to /tmp/pip-req-build-9hwb4vo3\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tfplot==0.2.0.dev0) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tfplot==0.2.0.dev0) (1.14.5)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tfplot==0.2.0.dev0) (2.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->tfplot==0.2.0.dev0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->tfplot==0.2.0.dev0) (2.5.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->tfplot==0.2.0.dev0) (2018.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->tfplot==0.2.0.dev0) (2.2.0)\n",
            "Building wheels for collected packages: tfplot\n",
            "  Running setup.py bdist_wheel for tfplot ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-dit9qetu/wheels/7a/90/54/0b41b5bd299f0d30f1d7eea21304d05ba171a4dfde98edd53e\n",
            "Successfully built tfplot\n",
            "Installing collected packages: tfplot\n",
            "Successfully installed tfplot-0.2.0.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "77RTww7FBQse",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.models import Model\n",
        "import os\n",
        "from PIL import Image\n",
        "from keras import optimizers\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "from textwrap import wrap\n",
        "import itertools\n",
        "import matplotlib\n",
        "#import tfplot\n",
        "import re\n",
        "from keras.callbacks import Callback\n",
        "run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
        "\n",
        "from keras import backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xAgZcGUCBQsy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, load_model\n",
        "\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dyDSPWmLBQs5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def temporal_CNN(input_shape, classes, weights_dir, include_top=True):\n",
        "        model = Sequential()\n",
        "\n",
        "\n",
        "\n",
        "        #conv1\n",
        "\n",
        "        model.add(Conv2D(128, (5, 5), strides=2, padding='same', input_shape=input_shape))\n",
        "\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(Activation('relu'))\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "\n",
        "        #conv2\n",
        "\n",
        "        model.add(Conv2D(256, (5, 5), strides=2, padding='same'))\n",
        "\n",
        "        model.add(Activation('relu'))\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "\n",
        "        #conv3\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), strides=1, activation='relu', padding='same'))\n",
        "\n",
        "\n",
        "\n",
        "        #conv4\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), strides=1, activation='relu', padding='same'))\n",
        "\n",
        "\n",
        "\n",
        "        #conv5\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), strides=1, activation='relu', padding='same'))\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "\n",
        "        #full6\n",
        "\n",
        "        model.add(Flatten())\n",
        "\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "\n",
        "        model.add(Dropout(0.9))\n",
        "\n",
        "\n",
        "\n",
        "        #full7\n",
        "\n",
        "        model.add(Dense(2048, activation='relu'))\n",
        "\n",
        "        model.add(Dropout(0.9))\n",
        "\n",
        "\n",
        "\n",
        "        #softmax\n",
        "\n",
        "        model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MgpuYn0OD2vc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f11b2dd0-8134-4c62-82f8-e1b6eb1494af"
      },
      "cell_type": "code",
      "source": [
        "%cd HAR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/HAR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EN3QXBATYN9J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c24ae3fe-d5c7-437d-c260-2887fba2eb17"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t\t  ngrok-stable-linux-amd64.zip\t  test.csv\t   url.txt\r\n",
            "datacombined.csv  ngrok-stable-linux-amd64.zip.5  train\r\n",
            "logs\t\t  Temporal_CNN.ipynb\t\t  train.csv\r\n",
            "ngrok\t\t  test\t\t\t\t  Untitled0.ipynb\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7_HDGxCCcRzv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = 'logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LIAH4g9p0zWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d3c3acf-d0aa-4f9d-cf7b-74c445d47a46"
      },
      "cell_type": "code",
      "source": [
        "! curl http://localhost:6006"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "curl: (7) Failed to connect to localhost port 6006: Connection refused\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ljlvuNeSdqWH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b0e8478-dc87-4752-e88b-32444ab4d06c"
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1\n",
        "! unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "^C\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LOGe2Xa7dqdU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "je47LzATdqat",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2fc9beb6-9ece-49e8-d08e-6f2e2fcb4997"
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\r\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.6/json/__init__.py\", line 299, in load\n",
            "    parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
            "  File \"/usr/lib/python3.6/json/__init__.py\", line 354, in loads\n",
            "    return _default_decoder.decode(s)\n",
            "  File \"/usr/lib/python3.6/json/decoder.py\", line 339, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/usr/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pVnqqqf0BQst",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def temporal_CNN(input_shape, classes, weights_dir, include_top=True):\n",
        "    '''\n",
        "    The CNN for optical flow input.\n",
        "    Since optical flow is not a common image, we cannot finetune pre-trained ResNet (The weights trained on imagenet is\n",
        "    for images and thus is meaningless for optical flow)\n",
        "    :param input_shape: the shape of optical flow input\n",
        "    :param classes: number of classes\n",
        "    :return:\n",
        "    '''\n",
        "    optical_flow_input = Input(shape=input_shape)\n",
        "\n",
        "    x = Convolution2D(96, kernel_size=(7, 7), strides=(2, 2), padding='same', name='tmp_conv1')(optical_flow_input)\n",
        "    x = BatchNormalization(axis=3)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = Convolution2D(256, kernel_size=(5, 5), strides=(2, 2), padding='same', name='tmp_conv2')(x)\n",
        "    x = BatchNormalization(axis=3)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = Convolution2D(512, kernel_size=(3, 3), strides=(2, 2), padding='same', name='tmp_conv3')(x)\n",
        "    x = BatchNormalization(axis=3)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(512, kernel_size=(3, 3), strides=(1, 1), padding='same', name='tmp_conv4')(x)\n",
        "    x = BatchNormalization(axis=3)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(512, kernel_size=(3, 3), strides=(1, 1), padding='same', name='tmp_conv5')(x)\n",
        "    x = BatchNormalization(axis=3)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(2048, activation='relu', name='tmp_fc6')(x)\n",
        "    x = Dropout(0.9)(x)\n",
        "\n",
        "    x = Dense(4096, activation='relu', name='tmp_fc7')(x)\n",
        "    x = Dropout(0.9)(x)\n",
        "   \n",
        "    if include_top:\n",
        "        x = Dense(classes, activation='softmax', name='tmp_fc101')(x)\n",
        "\n",
        "    model = Model(inputs=optical_flow_input, outputs=x, name='temporal_CNN')\n",
        "    \n",
        "    if os.path.exists(weights_dir):\n",
        "        \n",
        "        model.load_weights(weights_dir, by_name=True)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tuXDRs87WgdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1003
        },
        "outputId": "8487c808-2abd-4179-beae-2528efdd53e3"
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    input_shape = (216, 216, 20)\n",
        "    N_CLASSES = 7\n",
        "    model = temporal_CNN(input_shape, N_CLASSES, weights_dir='')\n",
        "    print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 216, 216, 20)      0         \n",
            "_________________________________________________________________\n",
            "tmp_conv1 (Conv2D)           (None, 108, 108, 96)      94176     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 108, 108, 96)      384       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 108, 108, 96)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 96)        0         \n",
            "_________________________________________________________________\n",
            "tmp_conv2 (Conv2D)           (None, 27, 27, 256)       614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 27, 27, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 27, 27, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 256)       0         \n",
            "_________________________________________________________________\n",
            "tmp_conv3 (Conv2D)           (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "tmp_conv4 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "tmp_conv5 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "tmp_fc6 (Dense)              (None, 2048)              9439232   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "tmp_fc7 (Dense)              (None, 4096)              8392704   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "tmp_fc101 (Dense)            (None, 7)                 28679     \n",
            "=================================================================\n",
            "Total params: 24,476,775\n",
            "Trainable params: 24,472,999\n",
            "Non-trainable params: 3,776\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B1fCXeq0BQtF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "lr = 0.001\n",
        "beta_1 = 0.9\n",
        "beta_2 = 0.999\n",
        "epsilon = 10 ** (-8)\n",
        "optimizer = optimizers.Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'],options = run_opts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JlrJBnVjBQtN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "train = pd.read_csv(\"train.csv\",index_col = 0)\n",
        "test =  pd.read_csv(\"test.csv\",index_col=0)\n",
        "#print (train.shape)\n",
        "#print (test.shape)\n",
        "train.reset_index()\n",
        "test.reset_index()\n",
        "train.index = range(train.shape[0])\n",
        "test.index = range(test.shape[0])\n",
        "\n",
        "#print(train.shape[0])   \n",
        "target = train['label']\n",
        "features = train.drop('label',axis=1)\n",
        "X_data = features['id']\n",
        "y_data = target\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JqaiFrsNBQtT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dim = (216,216)\n",
        "batch_size = X_data.shape[0]\n",
        "n_classes = 7\n",
        "n_channels = 20\n",
        "shuffle = True\n",
        "    \n",
        "def data_generation(list_IDs_temp,labels):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((batch_size, *dim, n_channels))\n",
        "        y = np.empty((batch_size), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            #print(i,ID)\n",
        "            # Store sample\n",
        "            X[i,] = np.load('data/' + ID )\n",
        "\n",
        "            # Store class\n",
        "            y[i] = labels[i]\n",
        "\n",
        "        return X , keras.utils.to_categorical(y, num_classes=n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t_0_Pu1xU6s_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "316c4b2c-0a01-43cb-c825-7ef25193e7fa"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t\t  ngrok-stable-linux-amd64.zip\t  test\t     Untitled0.ipynb\r\n",
            "datacombined.csv  ngrok-stable-linux-amd64.zip.1  test.csv   url.txt\r\n",
            "logs\t\t  ngrok-stable-linux-amd64.zip.5  train\r\n",
            "ngrok\t\t  Temporal_CNN.ipynb\t\t  train.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Nwy94ZE5BQtb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Datasets\n",
        "partition = X_data\n",
        "labels =  y_data\n",
        "#keras.utils.to_categorical(y, num_classes=n_classes)\n",
        "# Generators\n",
        "xData,yData = data_generation(partition,labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AtbcuYlqBQtr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "random_seed = 2\n",
        "trainData, testData = train_test_split(xData, test_size=0.2,random_state=random_seed)\n",
        "trainLabels, testLabels = train_test_split(yData, test_size=0.2,random_state=random_seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DHN9dqbfBQt0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7a805d0-d97b-4175-91cb-bbfcecd9375d"
      },
      "cell_type": "code",
      "source": [
        "trainData.shape,testData.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((291, 216, 216, 20), (73, 216, 216, 20))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "4HiI1IAuBQuw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SensitivitySpecificityCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      \n",
        "        normalize=False\n",
        "        title='Confusion matrix'\n",
        "        tensor_name = 'image'\n",
        "        session=tf.Session()   \n",
        "        img_d_summary_dir = os.path.join('logs', \"image\")\n",
        "        img_d_summary_writer = tf.summary.FileWriter(img_d_summary_dir, session.graph)\n",
        "        x_test = self.validation_data[0]\n",
        "        y_test = self.validation_data[1]\n",
        "        #print(y_test)\n",
        "        # x_test, y_test = self.validation_data\n",
        "        predictions = self.model.predict(x_test)\n",
        "        #print(predictions)\n",
        "        y_test = np.argmax(y_test, axis=-1)\n",
        "        predictions = np.argmax(predictions, axis=-1)\n",
        "        #c = confusion_matrix(y_test, predictions)\n",
        "        correct_labels = y_test\n",
        "        predict_labels = predictions\n",
        "        conf = tf.contrib.metrics.confusion_matrix(correct_labels, predict_labels)\n",
        "\n",
        "        cm=session.run(conf)\n",
        "        if normalize:\n",
        "            cm = cm.astype('float')*10 / cm.sum(axis=1)[:, np.newaxis]\n",
        "            cm = np.nan_to_num(cm, copy=True)\n",
        "            cm = cm.astype('int')\n",
        "\n",
        "        np.set_printoptions(precision=2)\n",
        "\n",
        "        fig = matplotlib.figure.Figure(figsize=(7, 7), dpi=320, facecolor='w', edgecolor='k')\n",
        "        ax = fig.add_subplot(1, 1, 1)\n",
        "        im = ax.imshow(cm, cmap='Oranges')\n",
        "\n",
        "        #classes = [re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ', x) for x in labels]\n",
        "        #classes = ['\\n'.join(wrap(l, 40)) for l in classes]\n",
        "        classes = ['Bend','Hand-wave','Jump-in-place','Pull','Run','Sit-stand-up','Run']\n",
        "        tick_marks = np.arange(len(classes))\n",
        "\n",
        "        ax.set_xlabel('Predicted', fontsize=7)\n",
        "        ax.set_xticks(tick_marks)\n",
        "        c = ax.set_xticklabels(classes, fontsize=10, rotation=-90,  ha='center')\n",
        "        ax.xaxis.set_label_position('bottom')\n",
        "        ax.xaxis.tick_bottom()\n",
        "\n",
        "        ax.set_ylabel('True Label', fontsize=7)\n",
        "        ax.set_yticks(tick_marks)\n",
        "        ax.set_yticklabels(classes, fontsize=10, va ='center')\n",
        "        ax.yaxis.set_label_position('left')\n",
        "        ax.yaxis.tick_left()\n",
        "\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            ax.text(j, i, format(cm[i, j], 'd') if cm[i,j]!=0 else '.', horizontalalignment=\"center\", fontsize=6, verticalalignment='center', color= \"black\")\n",
        "\n",
        "        fig.set_tight_layout(True)\n",
        "        summary = tfplot.figure.to_summary(fig, tag=tensor_name)\n",
        "        img_d_summary_writer.add_summary(summary)\n",
        "        img_d_summary_writer.flush()\n",
        "        img_d_summary_writer.close()\n",
        "        #return summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JANIGxvjBQut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TrainValTensorBoard(TensorBoard):\n",
        "    def __init__(self, log_dir='./logs', **kwargs):\n",
        "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
        "        training_log_dir = os.path.join(log_dir, 'training')\n",
        "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
        "        \n",
        "        # Log the validation metrics to a separate subdirectory\n",
        "        self.val_log_dir = os.path.join(log_dir, 'validation')\n",
        "        #self.img_d_summary_dir = os.path.join(log_dir, \"image\")\n",
        "\n",
        "    def set_model(self, model):\n",
        "        # Setup writer for validation metrics\n",
        "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
        "        #self.img_d_summary_writer = tf.summary.FileWriter(self.img_d_summary_dir)\n",
        "        super(TrainValTensorBoard, self).set_model(model)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Pop the validation logs and handle them separately with\n",
        "        # `self.val_writer`. Also rename the keys so that they can\n",
        "        # be plotted on the same figure with the training metrics\n",
        "        #img_d_summary =  TrainValTensorBoard.plot_confusion_matrix(correct_labels, predict_labels, labels, tensor_name='image')\n",
        "        logs = logs or {}\n",
        "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
        "        for name, value in val_logs.items():\n",
        "            summary = tf.Summary()\n",
        "            summary_value = summary.value.add()\n",
        "            summary_value.simple_value = value.item()\n",
        "            summary_value.tag = name\n",
        "            self.val_writer.add_summary(summary, epoch)\n",
        "            #self.img_d_summary_writer.add_summary(img_d_summary, epoch)\n",
        "        self.val_writer.flush()\n",
        "        #self.img_d_summary_writer.flush()\n",
        "        \n",
        "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
        "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
        "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
        "        self.val_writer.close()\n",
        "        \n",
        "\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fa2Rw6sASK9P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hist = model.fit(trainData,trainLabels, validation_data=(testData,testLabels),batch_size=32, epochs=100, callbacks=[SensitivitySpecificityCallback(),TrainValTensorBoard(write_graph=False)])#ConfusionMatrixPlotter])#TrainValTensorBoard(write_graph=False)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yQynCJDdNSSG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "92a256b7-31d4-4336-fd9b-b30591bf6c70"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  \n",
        "history = hist\n",
        "print(history.history.keys())  \n",
        "   \n",
        "plt.figure(1)  \n",
        "   \n",
        "# summarize history for accuracy  \n",
        "   \n",
        "plt.subplot(211)  \n",
        "plt.plot(history.history['acc'])  \n",
        "plt.plot(history.history['val_acc'])  \n",
        "plt.title('model accuracy')  \n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'test'], loc='upper left')  \n",
        "   \n",
        "# summarize history for loss  \n",
        "   \n",
        "plt.subplot(212)  \n",
        "plt.plot(history.history['loss'])  \n",
        "plt.plot(history.history['val_loss'])  \n",
        "plt.title('model loss')  \n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'test'], loc='upper left')  \n",
        "plt.show()  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIjJKLxFRERM5hfjsOiHSneHoQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa5c1c475f8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "w39-37uhalV_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "dce6ee50-0fb1-41ad-ee98-cf303eba07c8"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  \n",
        "history = hist\n",
        "print(history.history.keys())  \n",
        "   \n",
        "plt.figure(1)  \n",
        "   \n",
        "# summarize history for accuracy  \n",
        "   \n",
        "plt.subplot(211)  \n",
        "plt.plot(history.history['acc'])  \n",
        "plt.plot(history.history['val_acc'])  \n",
        "plt.title('model accuracy')  \n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'test'], loc='upper left')  \n",
        "   \n",
        "# summarize history for loss  \n",
        "   \n",
        "plt.subplot(212)  \n",
        "plt.plot(history.history['loss'])  \n",
        "plt.plot(history.history['val_loss'])  \n",
        "plt.title('model loss')  \n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'test'], loc='upper left')  \n",
        "plt.show()  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYQQwkFIUhdCCCEcxP8DGQ66cJruRpsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa422f84588>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TB0O8GwwIQnZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save_weights('ep200.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hrLTa6cEBQu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3454
        },
        "outputId": "9a8bab22-607a-49a8-a347-0ede67c530eb"
      },
      "cell_type": "code",
      "source": [
        "hist = model.fit(trainData,trainLabels, validation_data=(testData,testLabels),batch_size=32, epochs=100, callbacks=[SensitivitySpecificityCallback(),TrainValTensorBoard(write_graph=False)])#ConfusionMatrixPlotter])#TrainValTensorBoard(write_graph=False)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 291 samples, validate on 73 samples\n",
            "Epoch 1/100\n",
            "291/291 [==============================] - 9s 29ms/step - loss: 10.9813 - acc: 0.1684 - val_loss: 13.2477 - val_acc: 0.1781\n",
            "Epoch 2/100\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 12.4076 - acc: 0.1375 - val_loss: 11.8468 - val_acc: 0.2192\n",
            "Epoch 3/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 11.1891 - acc: 0.1478 - val_loss: 11.9106 - val_acc: 0.2192\n",
            "Epoch 4/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 7.9948 - acc: 0.1718 - val_loss: 9.8856 - val_acc: 0.1233\n",
            "Epoch 5/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 6.3144 - acc: 0.1237 - val_loss: 5.8113 - val_acc: 0.0411\n",
            "Epoch 6/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 4.6348 - acc: 0.1443 - val_loss: 5.9209 - val_acc: 0.0274\n",
            "Epoch 7/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 4.7102 - acc: 0.1478 - val_loss: 6.7595 - val_acc: 0.0137\n",
            "Epoch 8/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 4.1427 - acc: 0.1959 - val_loss: 6.0733 - val_acc: 0.1644\n",
            "Epoch 9/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 4.0827 - acc: 0.1959 - val_loss: 7.1143 - val_acc: 0.1781\n",
            "Epoch 10/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 4.0357 - acc: 0.2027 - val_loss: 3.9601 - val_acc: 0.2466\n",
            "Epoch 11/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.7583 - acc: 0.1924 - val_loss: 3.5667 - val_acc: 0.1644\n",
            "Epoch 12/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "291/291 [==============================] - 5s 17ms/step - loss: 3.8723 - acc: 0.1718 - val_loss: 3.6595 - val_acc: 0.1507\n",
            "Epoch 13/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.6289 - acc: 0.2199 - val_loss: 3.9077 - val_acc: 0.1644\n",
            "Epoch 14/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.4175 - acc: 0.2509 - val_loss: 5.3502 - val_acc: 0.1370\n",
            "Epoch 15/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.7728 - acc: 0.2405 - val_loss: 11.4870 - val_acc: 0.1370\n",
            "Epoch 16/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.5137 - acc: 0.2096 - val_loss: 11.3701 - val_acc: 0.1507\n",
            "Epoch 17/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.1684 - acc: 0.2749 - val_loss: 13.9530 - val_acc: 0.0822\n",
            "Epoch 18/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.5581 - acc: 0.2234 - val_loss: 13.4687 - val_acc: 0.1096\n",
            "Epoch 19/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.2759 - acc: 0.2577 - val_loss: 11.2115 - val_acc: 0.1096\n",
            "Epoch 20/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.3179 - acc: 0.2577 - val_loss: 8.0875 - val_acc: 0.1918\n",
            "Epoch 21/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.2544 - acc: 0.2405 - val_loss: 5.9775 - val_acc: 0.2192\n",
            "Epoch 22/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.7198 - acc: 0.2784 - val_loss: 4.6491 - val_acc: 0.2192\n",
            "Epoch 23/100\n",
            "128/291 [============>.................] - ETA: 2s - loss: 3.2384 - acc: 0.2891"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "291/291 [==============================] - 5s 17ms/step - loss: 2.9368 - acc: 0.2784 - val_loss: 4.0723 - val_acc: 0.2603\n",
            "Epoch 24/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.3428 - acc: 0.2440 - val_loss: 2.4592 - val_acc: 0.3288\n",
            "Epoch 25/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.7789 - acc: 0.2818 - val_loss: 2.3431 - val_acc: 0.3288\n",
            "Epoch 26/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.8152 - acc: 0.3058 - val_loss: 2.6971 - val_acc: 0.2740\n",
            "Epoch 27/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.6986 - acc: 0.2646 - val_loss: 3.3632 - val_acc: 0.3014\n",
            "Epoch 28/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.9077 - acc: 0.3058 - val_loss: 2.4248 - val_acc: 0.2740\n",
            "Epoch 29/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.2916 - acc: 0.2921 - val_loss: 2.0695 - val_acc: 0.2329\n",
            "Epoch 30/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.6955 - acc: 0.3368 - val_loss: 1.9506 - val_acc: 0.2603\n",
            "Epoch 31/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.7709 - acc: 0.3024 - val_loss: 1.6824 - val_acc: 0.2466\n",
            "Epoch 32/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.7924 - acc: 0.3196 - val_loss: 1.6691 - val_acc: 0.2740\n",
            "Epoch 33/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.8370 - acc: 0.2990 - val_loss: 1.6760 - val_acc: 0.2192\n",
            "Epoch 34/100\n",
            "160/291 [===============>..............] - ETA: 1s - loss: 2.5404 - acc: 0.3750"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "291/291 [==============================] - 5s 17ms/step - loss: 2.5706 - acc: 0.3608 - val_loss: 1.7812 - val_acc: 0.2603\n",
            "Epoch 35/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.4173 - acc: 0.3677 - val_loss: 3.6269 - val_acc: 0.2329\n",
            "Epoch 36/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.3797 - acc: 0.3368 - val_loss: 4.8061 - val_acc: 0.2329\n",
            "Epoch 37/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.5628 - acc: 0.3162 - val_loss: 4.0169 - val_acc: 0.2877\n",
            "Epoch 38/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.7401 - acc: 0.3471 - val_loss: 5.4365 - val_acc: 0.2192\n",
            "Epoch 39/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.7433 - acc: 0.3162 - val_loss: 5.4435 - val_acc: 0.2055\n",
            "Epoch 40/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.6627 - acc: 0.3814 - val_loss: 4.8304 - val_acc: 0.2329\n",
            "Epoch 41/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.4500 - acc: 0.3814 - val_loss: 7.8347 - val_acc: 0.2055\n",
            "Epoch 42/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.3927 - acc: 0.3505 - val_loss: 9.2181 - val_acc: 0.1644\n",
            "Epoch 43/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.3204 - acc: 0.4055 - val_loss: 8.3677 - val_acc: 0.1918\n",
            "Epoch 44/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.3796 - acc: 0.4124 - val_loss: 5.5916 - val_acc: 0.2055\n",
            "Epoch 45/100\n",
            "160/291 [===============>..............] - ETA: 2s - loss: 2.2671 - acc: 0.4500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "291/291 [==============================] - 5s 17ms/step - loss: 2.2654 - acc: 0.4399 - val_loss: 4.3514 - val_acc: 0.2603\n",
            "Epoch 46/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.0656 - acc: 0.4089 - val_loss: 4.5544 - val_acc: 0.2192\n",
            "Epoch 47/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.1794 - acc: 0.4502 - val_loss: 5.3414 - val_acc: 0.2329\n",
            "Epoch 48/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.5278 - acc: 0.3849 - val_loss: 5.1192 - val_acc: 0.2055\n",
            "Epoch 49/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.3763 - acc: 0.4021 - val_loss: 3.1261 - val_acc: 0.2603\n",
            "Epoch 50/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.2556 - acc: 0.4433 - val_loss: 6.7368 - val_acc: 0.1918\n",
            "Epoch 51/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.1956 - acc: 0.4021 - val_loss: 10.3754 - val_acc: 0.1096\n",
            "Epoch 52/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.3893 - acc: 0.3505 - val_loss: 13.8408 - val_acc: 0.0822\n",
            "Epoch 53/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.6623 - acc: 0.3814 - val_loss: 14.8186 - val_acc: 0.0685\n",
            "Epoch 54/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.8963 - acc: 0.3436 - val_loss: 14.7961 - val_acc: 0.0822\n",
            "Epoch 55/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.9783 - acc: 0.3608 - val_loss: 14.7941 - val_acc: 0.0822\n",
            "Epoch 56/100\n",
            "160/291 [===============>..............] - ETA: 2s - loss: 3.2092 - acc: 0.3937"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "291/291 [==============================] - 5s 17ms/step - loss: 3.3176 - acc: 0.3849 - val_loss: 14.7948 - val_acc: 0.0822\n",
            "Epoch 57/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.2436 - acc: 0.3746 - val_loss: 14.8019 - val_acc: 0.0822\n",
            "Epoch 58/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.0128 - acc: 0.3849 - val_loss: 14.7946 - val_acc: 0.0822\n",
            "Epoch 59/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.8879 - acc: 0.4261 - val_loss: 14.7935 - val_acc: 0.0822\n",
            "Epoch 60/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.2668 - acc: 0.4192 - val_loss: 14.7934 - val_acc: 0.0822\n",
            "Epoch 61/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.0134 - acc: 0.4433 - val_loss: 14.7938 - val_acc: 0.0822\n",
            "Epoch 62/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 3.2203 - acc: 0.4330 - val_loss: 14.7939 - val_acc: 0.0822\n",
            "Epoch 63/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.8478 - acc: 0.4467 - val_loss: 14.7934 - val_acc: 0.0822\n",
            "Epoch 64/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.4020 - acc: 0.5086 - val_loss: 13.0541 - val_acc: 0.1233\n",
            "Epoch 65/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.3032 - acc: 0.4914 - val_loss: 11.5072 - val_acc: 0.2329\n",
            "Epoch 66/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.7722 - acc: 0.4742 - val_loss: 10.6918 - val_acc: 0.1918\n",
            "Epoch 67/100\n",
            "128/291 [============>.................] - ETA: 2s - loss: 2.4918 - acc: 0.5625"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "291/291 [==============================] - 5s 18ms/step - loss: 2.6960 - acc: 0.4983 - val_loss: 11.4595 - val_acc: 0.1781\n",
            "Epoch 68/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.4227 - acc: 0.5155 - val_loss: 11.0647 - val_acc: 0.1781\n",
            "Epoch 69/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.4432 - acc: 0.5636 - val_loss: 10.7830 - val_acc: 0.1781\n",
            "Epoch 70/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.4487 - acc: 0.5670 - val_loss: 10.7866 - val_acc: 0.1918\n",
            "Epoch 71/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.2531 - acc: 0.6082 - val_loss: 8.3350 - val_acc: 0.2466\n",
            "Epoch 72/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.5820 - acc: 0.4948 - val_loss: 6.4407 - val_acc: 0.2877\n",
            "Epoch 73/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 1.8624 - acc: 0.5808 - val_loss: 3.3768 - val_acc: 0.3425\n",
            "Epoch 74/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 1.9249 - acc: 0.5911 - val_loss: 3.1945 - val_acc: 0.3014\n",
            "Epoch 75/100\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 1.5778 - acc: 0.5945 - val_loss: 3.0891 - val_acc: 0.3562\n",
            "Epoch 76/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 1.7883 - acc: 0.5911 - val_loss: 3.0877 - val_acc: 0.3699\n",
            "Epoch 77/100\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 2.0510 - acc: 0.5601 - val_loss: 3.3079 - val_acc: 0.3425\n",
            "Epoch 78/100\n",
            "128/291 [============>.................] - ETA: 2s - loss: 2.0589 - acc: 0.5859"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "291/291 [==============================] - 5s 17ms/step - loss: 1.8790 - acc: 0.5911 - val_loss: 3.3464 - val_acc: 0.3699\n",
            "Epoch 79/100\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 2.2456 - acc: 0.5361 - val_loss: 3.5708 - val_acc: 0.2740\n",
            "Epoch 80/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.1524 - acc: 0.5292 - val_loss: 3.5226 - val_acc: 0.3014\n",
            "Epoch 81/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.2325 - acc: 0.4914 - val_loss: 3.4183 - val_acc: 0.2603\n",
            "Epoch 82/100\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 1.7903 - acc: 0.5808 - val_loss: 3.3017 - val_acc: 0.3151\n",
            "Epoch 83/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.0238 - acc: 0.6220 - val_loss: 3.0483 - val_acc: 0.2877\n",
            "Epoch 84/100\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 1.7480 - acc: 0.6289 - val_loss: 3.2459 - val_acc: 0.3699\n",
            "Epoch 85/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 1.8425 - acc: 0.5773 - val_loss: 3.2860 - val_acc: 0.3836\n",
            "Epoch 86/100\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 2.0673 - acc: 0.5430 - val_loss: 2.4437 - val_acc: 0.2603\n",
            "Epoch 87/100\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 2.1041 - acc: 0.5155 - val_loss: 2.6893 - val_acc: 0.3699\n",
            "Epoch 88/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.0650 - acc: 0.5773 - val_loss: 2.5909 - val_acc: 0.3973\n",
            "Epoch 89/100\n",
            "160/291 [===============>..............] - ETA: 2s - loss: 2.3961 - acc: 0.5813"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "291/291 [==============================] - 5s 18ms/step - loss: 2.4259 - acc: 0.5670 - val_loss: 2.0792 - val_acc: 0.4247\n",
            "Epoch 90/100\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 1.9091 - acc: 0.6014 - val_loss: 2.2350 - val_acc: 0.3562\n",
            "Epoch 91/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.1613 - acc: 0.4914 - val_loss: 2.0653 - val_acc: 0.4384\n",
            "Epoch 92/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 1.9742 - acc: 0.5361 - val_loss: 1.9767 - val_acc: 0.3836\n",
            "Epoch 93/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 2.1106 - acc: 0.6117 - val_loss: 1.7178 - val_acc: 0.3699\n",
            "Epoch 94/100\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 1.8978 - acc: 0.6357 - val_loss: 1.5590 - val_acc: 0.4658\n",
            "Epoch 95/100\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 1.5721 - acc: 0.6873 - val_loss: 1.6524 - val_acc: 0.4247\n",
            "Epoch 96/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 1.8109 - acc: 0.6289 - val_loss: 2.2998 - val_acc: 0.5068\n",
            "Epoch 97/100\n",
            "291/291 [==============================] - 5s 17ms/step - loss: 1.2489 - acc: 0.6804 - val_loss: 2.1852 - val_acc: 0.4795\n",
            "Epoch 98/100\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 2.0302 - acc: 0.6632 - val_loss: 2.3792 - val_acc: 0.4932\n",
            "Epoch 99/100\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 2.0330 - acc: 0.6976 - val_loss: 4.6037 - val_acc: 0.3836\n",
            "Epoch 100/100\n",
            "160/291 [===============>..............] - ETA: 2s - loss: 2.0800 - acc: 0.6750"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "291/291 [==============================] - 5s 17ms/step - loss: 2.2574 - acc: 0.6598 - val_loss: 4.9826 - val_acc: 0.3699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a9RSQywJBQt-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "93669684-b995-4671-aa46-5d27b5912f2b"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 32\n",
        "gen = ImageDataGenerator(\n",
        "        \n",
        "        horizontal_flip= True\n",
        ")\n",
        "\n",
        "train_gen = gen.flow(trainData, trainLabels, batch_size=batch_size)\n",
        "test_gen = gen.flow(testData, testLabels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py:1144: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (291, 216, 216, 20) (20 channels).\n",
            "  ' (' + str(self.x.shape[channels_axis]) + ' channels).')\n",
            "/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py:1144: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (73, 216, 216, 20) (20 channels).\n",
            "  ' (' + str(self.x.shape[channels_axis]) + ' channels).')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "t-JDH3L9BQuo",
        "colab_type": "code",
        "colab": {},
        "outputId": "7990e4bf-61e4-4201-8f94-88fd5ee90ffb"
      },
      "cell_type": "code",
      "source": [
        "hist = model.fit(trainData,trainLabels, validation_data=(testData,testLabels),batch_size=32, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 730 samples, validate on 82 samples\n",
            "Epoch 1/100\n",
            "730/730 [==============================] - 651s 891ms/step - loss: 0.8679 - acc: 0.6055 - val_loss: 1.0272 - val_acc: 0.6220\n",
            "Epoch 2/100\n",
            "730/730 [==============================] - 642s 879ms/step - loss: 0.8700 - acc: 0.6082 - val_loss: 0.9927 - val_acc: 0.6341\n",
            "Epoch 3/100\n",
            "730/730 [==============================] - 634s 869ms/step - loss: 0.8667 - acc: 0.6110 - val_loss: 0.9532 - val_acc: 0.6951\n",
            "Epoch 4/100\n",
            "730/730 [==============================] - 596s 816ms/step - loss: 0.8475 - acc: 0.5986 - val_loss: 1.0203 - val_acc: 0.7317\n",
            "Epoch 5/100\n",
            "730/730 [==============================] - 609s 834ms/step - loss: 0.8393 - acc: 0.6205 - val_loss: 1.0272 - val_acc: 0.7073\n",
            "Epoch 6/100\n",
            "730/730 [==============================] - 648s 887ms/step - loss: 0.8435 - acc: 0.6260 - val_loss: 1.0669 - val_acc: 0.7073\n",
            "Epoch 7/100\n",
            "730/730 [==============================] - 664s 910ms/step - loss: 0.8337 - acc: 0.6315 - val_loss: 1.0840 - val_acc: 0.7073\n",
            "Epoch 8/100\n",
            "730/730 [==============================] - 625s 855ms/step - loss: 0.8325 - acc: 0.6356 - val_loss: 1.0709 - val_acc: 0.6829\n",
            "Epoch 9/100\n",
            " 96/730 [==>...........................] - ETA: 7:22 - loss: 0.8526 - acc: 0.6771"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-216-18d673bbfd60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainLabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1219\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m                             \u001b[1;31m# Do not slice the training phase flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m                             \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m                             \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "mrnS4LRDBQuJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dim = (216,216)\n",
        "batch_size = test.shape[0]\n",
        "n_classes = 7\n",
        "n_channels = 20\n",
        "shuffle = True\n",
        "    \n",
        "def data_generation_test(list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((batch_size, *dim, n_channels))\n",
        "        y = np.empty((batch_size), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            #print(i,ID)\n",
        "            # Store sample\n",
        "            X[i,] = np.load('F://data/' + ID)\n",
        "\n",
        "           \n",
        "\n",
        "        return X "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jq69mhnZBQuO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1523
        },
        "outputId": "e34fb91e-00b4-4a1f-955c-d3926abdefd1"
      },
      "cell_type": "code",
      "source": [
        "test_data = test['id']\n",
        "print(test)\n",
        "#test_data.shape\n",
        "testData = data_generation_test(test_data)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                               id\n",
            "0               Walk_Man1_003.npy\n",
            "1      Jump-in-place_Man3_005.npy\n",
            "2               Pull_Man4_004.npy\n",
            "3     Sit - stand up_Man6_006.npy\n",
            "4             Pull_Woman1_004.npy\n",
            "5      Jump-in-place_Man4_007.npy\n",
            "6      Jump-in-place_Man3_006.npy\n",
            "7             Walk_Woman2_005.npy\n",
            "8                Run_Man4_007.npy\n",
            "9   Sit - stand up_Woman2_007.npy\n",
            "10     Jump-in-place_Man5_000.npy\n",
            "11         Hand-wave_Man3_002.npy\n",
            "12    Sit - stand up_Man4_006.npy\n",
            "13               Run_Man2_001.npy\n",
            "14            Pull_Woman1_006.npy\n",
            "15              Bend_Man6_000.npy\n",
            "16       Hand-wave_Woman1_002.npy\n",
            "17             Run_Woman1_002.npy\n",
            "18               Run_Man5_006.npy\n",
            "19              Walk_Man3_004.npy\n",
            "20            Walk_Woman2_007.npy\n",
            "21    Sit - stand up_Man2_004.npy\n",
            "22    Sit - stand up_Man1_004.npy\n",
            "23    Sit - stand up_Man2_006.npy\n",
            "24             Run_Woman1_000.npy\n",
            "25            Bend_Woman1_005.npy\n",
            "26         Hand-wave_Man1_001.npy\n",
            "27     Jump-in-place_Man1_002.npy\n",
            "28  Sit - stand up_Woman1_000.npy\n",
            "29         Hand-wave_Man4_001.npy\n",
            "..                            ...\n",
            "54              Bend_Man2_002.npy\n",
            "55       Hand-wave_Woman1_004.npy\n",
            "56              Bend_Man3_006.npy\n",
            "57     Jump-in-place_Man6_005.npy\n",
            "58         Hand-wave_Man4_000.npy\n",
            "59              Bend_Man4_001.npy\n",
            "60     Jump-in-place_Man4_004.npy\n",
            "61    Sit - stand up_Man6_003.npy\n",
            "62              Pull_Man1_000.npy\n",
            "63   Jump-in-place_Woman1_007.npy\n",
            "64       Hand-wave_Woman1_006.npy\n",
            "65            Bend_Woman1_000.npy\n",
            "66              Bend_Man4_005.npy\n",
            "67         Hand-wave_Man5_003.npy\n",
            "68              Walk_Man2_000.npy\n",
            "69              Pull_Man5_006.npy\n",
            "70              Bend_Man6_004.npy\n",
            "71              Bend_Man2_004.npy\n",
            "72               Run_Man4_002.npy\n",
            "73               Run_Man4_006.npy\n",
            "74              Walk_Man6_001.npy\n",
            "75              Pull_Man4_000.npy\n",
            "76              Bend_Man6_001.npy\n",
            "77               Run_Man6_003.npy\n",
            "78              Walk_Man1_004.npy\n",
            "79              Walk_Man6_007.npy\n",
            "80            Pull_Woman1_007.npy\n",
            "81              Pull_Man5_003.npy\n",
            "82         Hand-wave_Man5_006.npy\n",
            "83  Sit - stand up_Woman2_000.npy\n",
            "\n",
            "[84 rows x 1 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-53b9686932d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#test_data.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtestData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_generation_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-489588d247f3>\u001b[0m in \u001b[0;36mdata_generation_test\u001b[0;34m(list_IDs_temp)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m#print(i,ID)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# Store sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F://data/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'F://data/Walk_Man1_003.npy'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3yLciw2UBQuR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(trainData , trainLabels, validation_data=(testData , testLabels),batch_size=32, epochs=100) # ,callbacks=callbacks_list, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b-aZIaLmBQug",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "#callbacks_list = [checkpoint]\n",
        "# Fit the model\n",
        "model.fit(train_gen, validation_data=(test_gen),batch_size=32, epochs=100) # ,callbacks=callbacks_list, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BiNw48NVBQu1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save_weights(\"ep300over.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KedCDooHBQu_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(trainData,trainLabels, validation_data=(testData,testLabels),batch_size=32, epochs=100, callbacks=[SensitivitySpecificityCallback(),TrainValTensorBoard(write_graph=False)])#ConfusionMatrixPlotter])#TrainValTensorBoard(write_graph=False)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GzSE8LcrBQvG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(trainData,trainLabels, validation_data=(testData,testLabels),batch_size=32, epochs=100, callbacks=[SensitivitySpecificityCallback(),TrainValTensorBoard(write_graph=False)])#ConfusionMatrixPlotter])#TrainValTensorBoard(write_graph=False)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LL4mcfFyBQvL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(trainData,trainLabels, validation_data=(testData,testLabels),batch_size=32, epochs=100, callbacks=[SensitivitySpecificityCallback(),TrainValTensorBoard(write_graph=False)])#ConfusionMatrixPlotter])#TrainValTensorBoard(write_graph=False)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "56V6w8FQBQvP",
        "colab_type": "code",
        "colab": {},
        "outputId": "7d4f1eac-0dc0-419e-abf8-427af77dfe8d"
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(train_gen, steps_per_epoch=train_gen.n, epochs=100, validation_data=test_gen,validation_steps=test_gen.n,callbacks=[TrainValTensorBoard(write_graph=False)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "291/291 [==============================] - 3009s 10s/step - loss: 13.7087 - acc: 0.1495 - val_loss: 14.3473 - val_acc: 0.1099\n",
            "Epoch 2/100\n",
            " 14/291 [>.............................] - ETA: 4:04:55 - loss: 13.7436 - acc: 0.1473"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EfW6rz5cBQvY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dj4k2JlzBQvf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_JiPO00BQvm",
        "colab_type": "code",
        "colab": {},
        "outputId": "a0deb7ac-e6aa-491c-e638-a875a2b1eb96"
      },
      "cell_type": "code",
      "source": [
        "hist.history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_loss': [16.11809539794922, 16.11809539794922],\n",
              " 'val_acc': [0.0, 0.0],\n",
              " 'loss': [12.08857157826424, 12.08857157826424],\n",
              " 'acc': [0.25, 0.25]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "oQhOCia-BQvs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save_weights('ep108.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zadim11PBQvx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict_classes(testData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A0gy2Z5rBQv6",
        "colab_type": "code",
        "colab": {},
        "outputId": "bd38d90f-dba4-42e6-dcfd-5b87b8f05701"
      },
      "cell_type": "code",
      "source": [
        "for i in pred:\n",
        "    print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GTCnTWffBQwB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FtFeRWgfBQwH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PzSR0JafBQwN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VE3h1f9uBQwV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bFXCz23ZBQwZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XNz2ZlFdBQwg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7vXXwN99BQwq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rs9O-1nj2I-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LCxs7ozxHTSp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c1F_Ts492JDG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}